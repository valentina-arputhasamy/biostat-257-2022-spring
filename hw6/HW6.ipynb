{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f9c170-c4be-4289-a160-7d89a697e248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Biostat 257 Homework 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3779796-3128-41fc-8d0d-a5b278925a7e",
   "metadata": {},
   "source": [
    "**Due June 10 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60b03c9-bda8-4969-a1d1-b8e7fcece384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, Revise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617f4fc-b328-4dfb-a4e1-10f38816c9c4",
   "metadata": {},
   "source": [
    "### **Q1. (10 pts) Refresher on normal-normal model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032f870-670f-4abb-bc4c-b44f54def65c",
   "metadata": {},
   "source": [
    "$$f(\\gamma \\vert y) \\propto f(y \\vert \\gamma) \\times f(\\gamma) \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big(y - ( X\\beta + Z\\gamma)\\big)^{T}\\sigma^{-2}I \\big(y - (X\\beta + Z\\gamma)\\big)\\big\\} \n",
    "\\times \\exp \\{-\\frac{1}{2} \\gamma^{T} \\Sigma^{-1} \\gamma \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big [ (y-(X\\beta + Z\\gamma))^{T} \\sigma^{-2}I(y-(X\\beta + Z\\gamma)) + \\gamma^{T}\\Sigma^{-1}\\big ]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big [ (y^{T}\\sigma^{-2}I - \\beta^{T}X^{T}\\sigma^{-2}I - \\gamma^{T}Z^{T}\\sigma^{-2}I) \\times (y-X\\beta-Z\\gamma) + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big \\}\\\\\n",
    "\\propto \\exp \\big \\{-\\frac{1}{2} \\big [-y^{T}\\sigma^{-2}Z\\gamma + \\beta^{T}X^{T}Z\\gamma - \\gamma Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "\\exp \\big \\{-\\frac{1}{2} \\big [ -\\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big (-\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) - \\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big) \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\}\n",
    "$$ \n",
    "\n",
    "By multivariate completion of square, we know that:\n",
    "\n",
    "$$ \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma -2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) \\propto \\\\\n",
    "(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1} \\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\sigma^{-2}Z^{T}(y-X\\beta))$$\n",
    "\n",
    "Which means:\n",
    "\n",
    "$$\\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\} \\propto \\\\\n",
    "\\exp \\big \\{ -\\frac{1}{2} \\big [ (\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))\\big]\\big\\}$$\n",
    "\n",
    "Which is the kernel of a Multivariate Normal Density with:\n",
    "\n",
    "- **Mean** : $\\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta)$\n",
    "- **Covariance**: $(\\sigma^{-2}Z_i^{T}Z + \\Sigma^{-1})^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc25a92-3b48-4d6e-8814-e0e924cfacb4",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Derive EM algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4e18-de6e-49b4-a2af-03a7754b13d0",
   "metadata": {},
   "source": [
    "**1. Write Down the Complete Log-Likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81e232-5e5e-4387-adf4-42eae6d405c3",
   "metadata": {},
   "source": [
    "$$ \\ell(\\beta, \\Sigma, \\sigma^2) = \\sum_{i = 1}^{m}-\\frac{1}{2}\\log \\det(2\\pi\\sigma^2I) - \\frac{1}{2}(y_i - (X_i\\beta + Z\\gamma_i))^{T}(\\sigma^2I)(y_i - (X_i\\beta + Z\\gamma_i)) - \\frac{1}{2} \\log \\det(2\\pi\\Sigma) -\\frac{1}{2} \\gamma_i\\Sigma^{-1}\\gamma_i\\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i + \\gamma_i^{T}Z_i^{T}Z_i\\gamma_i] - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}\\sigma^{-2}Z_i^{T}Z_i\\gamma_i - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492016a4-3abb-4eb1-9520-06a0ecbcefb1",
   "metadata": {},
   "source": [
    "**2. Derive the $Q$ function (E-step).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42b40e-af00-4fdb-96c6-7c92dd33d2bf",
   "metadata": {},
   "source": [
    "- Recall from the first problem: \n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i) = \\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta) = \\mu_{\\gamma \\mid y} \\\\\n",
    "\\mathrm{Var}(\\gamma_i \\mid y_i) =  (\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1} = \\Sigma_{\\gamma \\mid y}$\n",
    "- Recall the following property regarding quadratic forms from 250A: \\\n",
    "If $x \\sim N_q(\\mu, \\Sigma)$ then $\\mathbb{E}(x^{T}Ax) = \\mathrm{tr}(A\\Sigma) + \\mu^{T}A\\mu$ \n",
    "- Putting these two together, we see that: \\\n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) = \\sigma^{-2(t)}(\\sigma^{-2(t)}Z_i^{T}Z_i + \\Sigma^{-1(t)})^{-1}Z_i^{T}(y_i-X_i\\beta^{(t)}) = \\mu^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathrm{Var}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) =  (\\sigma^{-2}Z_i^{T}Z_i + (\\Sigma^{(t)})^{-1})^{-1} = \\Sigma^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathbb{E}(\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i) = \\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y}] + \\mu^{T(t)}_{\\gamma \\mid y}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}$ \n",
    "\n",
    "- Using these results we see that the conditional expectation evaluates to:\n",
    "$$\\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2} \\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[\\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...})]\n",
    "$$\n",
    "\n",
    "- Which leaves us with:\n",
    "$$ Q = \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...})]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325e9f1-1a9f-4e60-8c98-2ccb72be1c9c",
   "metadata": {},
   "source": [
    "**2. Derive the EM (or ECM) update of $\\mathbf{\\beta, \\sigma^2, \\Sigma}$ .**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d1bb8-8c33-49a7-a160-454e5f25b4ab",
   "metadata": {},
   "source": [
    "- **Gradient with respect to $\\beta$:** \n",
    "$\\nabla_{\\beta} = \\frac{d}{d\\beta}[\\sum_{i=1}^{m} -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "=\\frac{d}{d\\beta}[\\sum_{i=1}^{m}-\\frac{1}{2\\sigma^2}(y^{T}_iy_i - 2\\beta^{T}X^{T}_iy_i + \\beta^{T}X^{T}_iX_i\\beta) - 2y_iZ_i\\mu_{\\gamma \\mid y ...} + 2\\beta^{T}X^{T}_iZ_i\\mu_{\\gamma \\mid y ...}]\\\\\n",
    "= \\sum_{i=1}^{m} X^{T}_iy_i - X^{T}_iX_i\\beta - X^{T}_iZ_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i=1}^{m} X_i^{T}(y_i - X_i\\beta) + X_iZ_i\\mu_{\\gamma \\mid y ...}\n",
    "$\n",
    "\n",
    "- **Gradient with respect to $\\sigma^2$:** \\\n",
    "$\\nabla_{\\sigma^2} = -\\frac{n_i}{2} \\log(\\sigma^2) -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) + \\frac{1}{\\sigma^2}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)T}_{\\gamma \\mid y ...})] \\\\\n",
    "=-\\frac{n_i}{\\sigma^2} + \\frac{1}{2\\sigma^4}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - \\frac{1}{\\sigma^4}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2\\sigma^4}\\mathrm{tr}[Z_i^{T}Z_i(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)T}_{\\gamma \\mid y ...})]\n",
    "$\n",
    "\n",
    "- **Gradient with respect to $\\Sigma$:** \\\n",
    "$\\nabla_{\\Sigma} = m - \\sum_{i=1}{m} \\Sigma^{-1}\\Sigma^{(t)}_{\\gamma \\mid y ...} \\Sigma^{-1} - \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)T}_{\\gamma \\mid y ...}\\Sigma^{-1}$\n",
    "\n",
    "- **Next: To get (t+1) iterated value of $\\mathbf{\\beta, \\sigma^2}$ and $\\mathbf{\\Sigma}$ we set all of the gradients equal to zero and solve for the variable of interest. This gives us:**\n",
    " 1. $\\beta^{(t + 1)} = (\\sum_{i=1}^{m} X_i^{T}X_i)^{-1}(\\sum_{i=1}^{m} X_i^{T}y_i - X_i^{T}Z_i\\mu^{(t)}_{\\gamma \\mid y ...})$\n",
    " 2. $\\sigma^{2(t+1)} = \\frac{\\sum_{i=1}^{m}(y_i-X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)Z_i\\mu^{(t)}_{\\gamma \\mid y ...} + \\mathrm{tr}[Z_i^{T}Z_i(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)}_{\\gamma \\mid y}]}{n}$\n",
    " 3. $\\Sigma^{(t+1)} = \\frac{1}{m} \\sum_{i=1}^{m} \\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)T}_{\\gamma \\mid y ...}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec69cc-f4be-4328-8d56-202eeb563678",
   "metadata": {},
   "source": [
    "### **Q3. (20 pts) Objective of a single datum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7110e-1913-4daf-8aef-5ca4f1aff096",
   "metadata": {},
   "source": [
    "We modify the code from HW5 to evaluate the objective, the conditional mean of  ùú∏ , and the conditional variance of  ùú∏ . Start-up code is provided below. You do not have to use this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8de9f26-ea2e-4793-9058-da6b127752d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # posterior mean and variance of random effects Œ≥\n",
    "    ŒºŒ≥         :: Vector{T} # posterior mean of random effects\n",
    "    ŒΩŒ≥         :: Matrix{T} # posterior variance of random effects\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    rtr        :: Vector{T}\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    ztr        :: Vector{T}\n",
    "    ltztr      :: Vector{T}\n",
    "    xtr        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    ltztzl     :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "    storage_qq3:: Matrix{T}\n",
    "    storage_qq4:: Matrix{T}\n",
    "    storage_qq5:: Matrix{T}\n",
    "    storage_qq6:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "    y::Vector{T}, \n",
    "    X::Matrix{T}, \n",
    "    Z::Matrix{T}) where T <: AbstractFloat\n",
    "    n, p, q = size(X, 1), size(X, 2), size(Z, 2)\n",
    "    ŒºŒ≥         = Vector{T}(undef, q)\n",
    "    ŒΩŒ≥         = Matrix{T}(undef, q, q)\n",
    "    yty        = abs2(norm(y))\n",
    "    rtr        = Vector{T}(undef, 1)\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y\n",
    "    ztr        = similar(zty)\n",
    "    ltztr      = similar(zty)\n",
    "    xtr        = Vector{T}(undef, p)\n",
    "    storage_p  = similar(xtr)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    ltztzl     = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz)\n",
    "    storage_qq3= similar(ztz)\n",
    "    storage_qq4= similar(ztz)\n",
    "    storage_qq5= similar(ztz)\n",
    "    storage_qq6=similar(ztz)\n",
    "    LmmObs(y, X, Z, ŒºŒ≥, ŒΩŒ≥, \n",
    "        yty, rtr, xty, zty, ztr, ltztr, xtr,\n",
    "        storage_p, storage_q, \n",
    "        xtx, ztx, ztz, ltztzl, storage_qq, storage_qq2, storage_qq3, storage_qq4, storage_qq5, storage_qq6)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, Œ≤, Œ£, L, œÉ¬≤, updater = false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `Œ≤`, `Œ£`, \n",
    "and `œÉ¬≤`. The lower triangular Cholesky factor `L` of `Œ£` must be supplied too.\n",
    "The fields `obs.ŒºŒ≥` and `obs.ŒΩŒ≥` are overwritten by the posterior mean and \n",
    "posterior variance of random effects. If `updater==true`, fields `obs.ztr`, \n",
    "`obs.xtr`, and `obs.rtr` are updated according to input parameter values. \n",
    "Otherwise, it assumes these three fields are pre-computed. \n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs     :: LmmObs{T}, \n",
    "        Œ≤       :: Vector{T}, \n",
    "        Œ£       :: Matrix{T},\n",
    "        L       :: Matrix{T},\n",
    "        œÉ¬≤      :: T,\n",
    "        updater :: Bool = false\n",
    "        ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    œÉ¬≤inv   = inv(œÉ¬≤)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################\n",
    "    # form the q-by-q matrix: Lt Zt Z L\n",
    "    copy!(obs.ltztzl, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.ltztzl) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.ltztzl) # O(q^3)        \n",
    "    # form the q-by-q matrix: M = œÉ¬≤ I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ltztzl)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += œÉ¬≤\n",
    "    end\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # Zt * res\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), copy!(obs.ztr, obs.zty)) # O(pq)\n",
    "    # Lt * (Zt * res)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, copy!(obs.ltztr, obs.ztr))    # O(q^2)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, copy!(obs.storage_q, obs.ltztr)) # O(q^3)\n",
    "    # Xt * res = Xt * y - Xt * X * Œ≤\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.xtx, Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "    # l2 norm of residual vector\n",
    "    updater && (obs.rtr[1] = obs.yty - dot(obs.xty, Œ≤) - dot(obs.xtr, Œ≤))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2œÄ) + (n - q) * log(œÉ¬≤) # constant term\n",
    "    @inbounds for j in 1:q # log det term\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (obs.rtr[1] - qf) * œÉ¬≤inv \n",
    "    logl /= -2\n",
    "    ######################################\n",
    "    # TODO: Evaluate posterior mean and variance\n",
    "    \n",
    "    ### posterior variance (ŒΩŒ≥) ###\n",
    "    \n",
    "    copy!(obs.storage_qq2, obs.ztz)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq2) \n",
    "    # ztzL\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "    # L'ztzL\n",
    "    LAPACK.potrs!('U', obs.storage_qq, obs.storage_qq2)\n",
    "    # (V'V)^{-1} L'ztzL\n",
    "    \n",
    "    mul!(obs.storage_qq3, obs.ztz, L) \n",
    "    copy!(obs.storage_qq4, obs.storage_qq3)\n",
    "    BLAS.gemm!('N', 'N', T(1/œÉ¬≤), obs.storage_qq3, obs.storage_qq2, \n",
    "            T(-1/œÉ¬≤), obs.storage_qq4)\n",
    "    # 1/œÉ¬≤*ztzL*(V'V)^{-1} L'ztzL - 1/œÉ¬≤*ztzL \n",
    "        \n",
    "    # // note: (V'V)^{-1} L'ztzL computed previously, \n",
    "    # stored in obs.storage_qq2\n",
    "    \n",
    "    ### all code prior to this (in this section) was\n",
    "    ### taken from my work from HW5 as it was almost the same formula\n",
    "    \n",
    "    mul!(obs.storage_qq5, L, transpose(L))\n",
    "    copy!(obs.storage_qq6, L)\n",
    "    BLAS.gemm!('N', 'N',  T(1), obs.storage_qq5, obs.storage_qq4, T(1), obs.storage_qq6)\n",
    "    mul!(obs.ŒΩŒ≥, obs.storage_qq6, transpose(L))\n",
    "    \n",
    "    \n",
    "    ### posterior mean (ŒºŒ≥) ###\n",
    "    \n",
    "    BLAS.gemm!('N','N', T(1), obs.ŒΩŒ≥, obs.ztr, T(0), obs.ŒºŒ≥)\n",
    "    obs.ŒºŒ≥ ./= œÉ¬≤\n",
    "    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58531ef-68d0-4dda-a7ef-c288c2aa1143",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/posterior mean/var evaluator here. It's the same test datum in HW3 and HW5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807b7f0d-8be8-4eb4-9d74-1a4ae0f14c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "Z = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Œ£)).L)\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69dba2-b323-45e1-8ead-02d064c723df",
   "metadata": {},
   "source": [
    "#### **3.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b8ee1f-221c-48e3-a965-daf2c9cd7a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true) = -3256.1793358058258\n",
      "obs.ŒºŒ≥ = [0.10608689298645836, -0.251041906089828, -1.4653979410591285]\n",
      "obs.ŒΩŒ≥ = [0.0007494356395767454 -1.2183420378162024e-6 -2.1767836705487566e-6; -1.21834204662441e-6 0.0007542331466978082 2.1553464636468693e-5; -2.1767836415192976e-6 2.15534646046981e-5 0.0007465271345336]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true)\n",
    "@show obs.ŒºŒ≥\n",
    "@show obs.ŒΩŒ≥;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7253f72-0ddc-4e01-8090-3971c187fe38",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws AssertionError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37920311-d839-46ea-9d73-83a24e540612",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.ŒºŒ≥ - [0.10608689301333621, \n",
    "        -0.25104190602577225, -1.4653979409855415]) < 1e-4\n",
    "@assert norm(obs.ŒΩŒ≥ - [\n",
    "        0.0007494356395909563 -1.2183420093769967e-6 -2.176783643112221e-6; \n",
    "        -1.2183420282298223e-6 0.0007542331467601107 2.1553464632686345e-5; \n",
    "        -2.1767836636008638e-6 2.1553464641863096e-5 0.0007465271342535443\n",
    "        ]) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c4ef2-8f00-46f0-a88b-75cdb18df818",
   "metadata": {},
   "source": [
    "#### **3.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae8d8c-2543-4232-8d90-1ca3e48b44a5",
   "metadata": {},
   "source": [
    "Benchmark for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37873522-e1ae-4a25-88f8-bc411e3c48b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.054 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 18.968 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.197 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.385 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m544.252 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[34m‚ñà\u001b[39m\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[32m \u001b[39m\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñá\u001b[39m\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñá\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m \u001b[39m‚ñà\n",
       "  2.05 Œºs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      4.51 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj = @benchmark logl!($obs, $Œ≤, $Œ£, $L, $œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2733e-5709-4d42-880a-329809bab0df",
   "metadata": {},
   "source": [
    "My median run time is 1.8Œºs. You will get full credit if the median run time is within 10Œºs. The points you will get are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee62b6b5-ecdf-4eac-b52a-82f56b75f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_obj).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24965a1f-a8c3-471a-994c-a2a239d06647",
   "metadata": {},
   "source": [
    "### **Q4. LmmModel type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19faefc-df2d-4600-a600-71a62457d729",
   "metadata": {},
   "source": [
    "We modify the LmmModel type in HW4 to hold all data points, model parameters, and intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06720c97-cb80-4415-8666-eac9bc0832b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmModel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat}\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    Œ≤      :: Vector{T}\n",
    "    Œ£      :: Matrix{T}\n",
    "    L      :: Matrix{T}\n",
    "    œÉ¬≤     :: Vector{T}    \n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty    :: Vector{T}\n",
    "    xtr    :: Vector{T}\n",
    "    ztr2   :: Vector{T}\n",
    "    xtxinv :: Matrix{T}\n",
    "    ztz2   :: Matrix{T}\n",
    "    storage_p:: Vector{T}\n",
    "    storage_p2:: Vector{T}\n",
    "    storage_p3:: Vector{T}\n",
    "    storage_q:: Vector{T}\n",
    "    storage_q2:: Vector{T}\n",
    "    storage_pq :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    p      = size(obsvec[1].X, 2)\n",
    "    q      = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    Œ≤      = Vector{T}(undef, p)\n",
    "    Œ£      = Matrix{T}(undef, q, q)\n",
    "    L      = Matrix{T}(undef, q, q)\n",
    "    œÉ¬≤     = Vector{T}(undef, 1)    \n",
    "    # intermediate arrays\n",
    "    xty    = zeros(T, p)\n",
    "    xtr    = similar(xty)\n",
    "    ztr2   = Vector{T}(undef, abs2(q))\n",
    "    xtxinv = zeros(T, p, p)\n",
    "    storage_p = zeros(T, p)\n",
    "    storage_p2 = zeros(T, p)\n",
    "    storage_p3 = zeros(T, p)\n",
    "    storage_q = zeros(T, q)\n",
    "    storage_q2 = zeros(T, q)\n",
    "    storage_pq = zeros(T, p, q)\n",
    "    storage_qq = zeros(T, q, q)\n",
    "    storage_qq2 = zeros(T, q, q)\n",
    "    # pre-calculate \\sum_i Xi^T Xi and \\sum_i Xi^T y_i\n",
    "    @inbounds for i in eachindex(obsvec)\n",
    "        obs = obsvec[i]\n",
    "        BLAS.axpy!(T(1), obs.xtx, xtxinv)\n",
    "        BLAS.axpy!(T(1), obs.xty, xty)\n",
    "    end\n",
    "    # invert X'X\n",
    "    LAPACK.potrf!('U', xtxinv)\n",
    "    LAPACK.potri!('U', xtxinv)\n",
    "    LinearAlgebra.copytri!(xtxinv, 'U')\n",
    "    ztz2   = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    LmmModel(obsvec, Œ≤, Œ£, L, œÉ¬≤, xty, xtr, ztr2, xtxinv, ztz2, storage_p, storage_p2, storage_p3, storage_q, \n",
    "        storage_q2, storage_pq, storage_qq, storage_qq2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fb0cc-9479-4f0a-a39d-0c71ef889712",
   "metadata": {},
   "source": [
    "### **Q5. Implement EM update**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc647c4-3f57-438b-a6ba-65c2c502070d",
   "metadata": {},
   "source": [
    "Let's write the key function `update_em!` that performs one iteration of EM update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d5a347-4bfa-4dd7-bea7-804e87a475b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_em!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_em!(m::LmmModel, updater::Bool = false)\n",
    "\n",
    "Perform one iteration of EM update. It returns the log-likelihood calculated \n",
    "from input `m.Œ≤`, `m.Œ£`, `m.L`, and `m.œÉ¬≤`. These fields are then overwritten \n",
    "by the next EM iterate. The fields `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` are updated according to the resultant `m.Œ≤`. If `updater==true`, \n",
    "the function first updates `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` according to `m.Œ≤`. If `updater==false`, it assumes these fields \n",
    "are pre-computed.\n",
    "\"\"\"\n",
    "function update_em!(m::LmmModel{T}, updater::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    \n",
    "    # Do E step (evaluate conditional likelihood (Q function))\n",
    "    for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.Œ≤, m.Œ£, m.L, m.œÉ¬≤[1], updater)\n",
    "    end\n",
    "    \n",
    "    # TODO: update m.Œ≤\n",
    "    \n",
    "    # summing up xtz*mu_gamma|y...\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_p, transpose(obs.ztx), obs.ŒºŒ≥)\n",
    "        # xtz*mu_gamma|y..\n",
    "        BLAS.axpy!(T(1), m.storage_p, m.storage_p2) \n",
    "        # sum of xtz*mu_gamma|y...\n",
    "    end\n",
    "    \n",
    "    copy!(m.storage_p3, m.xty) \n",
    "    BLAS.axpy!(T(-1), m.storage_p2, m.storage_p3) \n",
    "    # sum xty - xtz*mu_gamma|y..\n",
    "    mul!(m.Œ≤, m.xtxinv, m.storage_p3) \n",
    "    # done updating Œ≤\n",
    "    \n",
    "    # TODO: update m.data[i].ztr, m.data[i].xtr, m.data[i].rtr\n",
    "    \n",
    "    total_n = 0\n",
    "    \n",
    "    for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        total_n += size(obs.X, 1)\n",
    "        # need this for updated œÉ¬≤\n",
    "        \n",
    "        ### update m.data[i].rtr ###\n",
    "        \n",
    "        copy!(obs.storage_p, obs.xty)\n",
    "        obs.rtr[1]  = obs.yty + dot(m.Œ≤, BLAS.gemv!('N', T(1), obs.xtx, m.Œ≤, T(-2), obs.storage_p))\n",
    "        # rtr formula from last hw (above 2 lines)\n",
    "        \n",
    "        ### update m.data[i].ztr ###\n",
    "        \n",
    "        mul!(m.storage_q, obs.ztx, m.Œ≤)\n",
    "        copy!(obs.ztr, obs.zty)\n",
    "        axpy!(T(-1), m.storage_q, obs.ztr)\n",
    "        # last line serves as a summation\n",
    "        # zty - ztxŒ≤\n",
    "    \n",
    "        ### m.data[i].xtr ###\n",
    "        \n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, m.Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "        # taken from dr.zhou's code above\n",
    "        \n",
    "    end \n",
    "        \n",
    "        # TODO: update m.œÉ¬≤\n",
    "    for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_qq, obs.ztz, obs.ŒΩŒ≥)\n",
    "        mul!(m.storage_q2, obs.ztz, obs.ŒºŒ≥)\n",
    "        m.œÉ¬≤[1] += obs.rtr[1] - 2*dot(obs.ŒºŒ≥, obs.ztr) - tr(m.storage_qq) + dot(obs.ŒºŒ≥, m.storage_q2)\n",
    "        # this last line serves as a summation\n",
    "    end \n",
    "    m.œÉ¬≤[1] /= total_n\n",
    "    \n",
    "     fill!(m.Œ£, 0)\n",
    "     for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_qq2, obs.ŒºŒ≥, transpose(obs.ŒºŒ≥))\n",
    "        axpy!(T(1), obs.ŒΩŒ≥ , m.storage_qq2)\n",
    "        axpy!(T(1), m.storage_qq2, m.Œ£) # store the m values of m.storage_qq2 into m.Œ£\n",
    "        # basically serves as a loop/summation\n",
    "    end\n",
    "    \n",
    "    m.Œ£ ./= length(m.data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # update m.Œ£ and m.L\n",
    "    # return log-likelihood at input parameter values\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301509f-f360-4959-83e3-c5961c3264ef",
   "metadata": {},
   "source": [
    "### **Q6. (30 pts) Test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbc074-9a40-406c-98d5-055bf28fe6e7",
   "metadata": {},
   "source": [
    "Let's generate a fake longitudinal data set (same as HW3) to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc1acbf-5077-486a-88be-88d966d78b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "Œ≤true  = [0.1; 6.5; -3.5; 1.0; 5]\n",
    "œÉ¬≤true = 1.5\n",
    "œÉtrue  = sqrt(œÉ¬≤true)\n",
    "Œ£true  = Matrix(Diagonal([2.0; 1.2; 1.0]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Œ£true)).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * Œ≤true .+ Z * (Ltrue * randn(q)) .+ œÉtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7aeb5c-bce8-4390-8b4d-bf02eb1e169e",
   "metadata": {},
   "source": [
    "#### **6.1  Correctness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ed5c0-65a7-490c-a83b-920d00987948",
   "metadata": {},
   "source": [
    "Evaluate log-likelihood and gradient at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "969eef81-d9b3-4705-8a08-73356c3b1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj1 = update_em!(lmm, true) = -2.840068438369969e6\n",
      "lmm.Œ≤ = [0.10003613677198955, 6.500382871080708, -3.499864634212745, 0.999712465761216, 4.9992308514638095]\n",
      "lmm.Œ£ = [1.9903882756209161 0.06862095706500466 0.05347290178448214; 0.06862095706500496 1.2813220460869357 -0.09044913325236677; 0.05347290178448159 -0.09044913325236685 0.9435400745494044]\n",
      "lmm.L = [1.4142135623730951 0.0 0.0; 0.0 1.0954451150103321 0.0; 0.0 0.0 1.0]\n",
      "lmm.œÉ¬≤ = [1.4935834029224386]\n",
      "\n",
      "obj2 = update_em!(lmm, false) = -2.8400728055298985e6\n",
      "lmm.Œ≤ = [0.018028063420458634, 6.500285666799762, -3.5018182413141696, 0.9983111589821287, 4.998208408425209]\n",
      "lmm.Œ£ = [1.9903886795162635 0.06862250198586728 0.053474240738842646; 0.06862250198586695 1.2813264848810928 -0.09044982016319844; 0.05347424073884229 -0.09044982016319872 0.9435424134813042]\n",
      "lmm.L = [1.4142135623730951 0.0 0.0; 0.0 1.0954451150103321 0.0; 0.0 0.0 1.0]\n",
      "lmm.œÉ¬≤ = [1.5003325753380132]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 1.5003325753380132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy!(lmm.Œ≤, Œ≤true)\n",
    "copy!(lmm.Œ£, Œ£true)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.œÉ¬≤[1] = œÉ¬≤true\n",
    "@show obj1 = update_em!(lmm, true)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.Œ£\n",
    "@show lmm.L\n",
    "@show lmm.œÉ¬≤\n",
    "println()\n",
    "@show obj2 = update_em!(lmm, false)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.Œ£\n",
    "@show lmm.L\n",
    "@show lmm.œÉ¬≤ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac032f8-52a8-4541-9558-db273c25d679",
   "metadata": {},
   "source": [
    "Test correctness. You will loss all 30 points if following code throws AssertError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878167f-fff4-47e1-8591-52c2093a98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(obj1 - (-2.840068438369969e6)) < 1e-4\n",
    "@assert abs(obj2 - (-2.84006046054206e6)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "725beca6-357f-4fb5-9821-91dd9566d835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
