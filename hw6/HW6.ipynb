{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f9c170-c4be-4289-a160-7d89a697e248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Biostat 257 Homework 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3779796-3128-41fc-8d0d-a5b278925a7e",
   "metadata": {},
   "source": [
    "**Due June 10 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c60b03c9-bda8-4969-a1d1-b8e7fcece384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, Revise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617f4fc-b328-4dfb-a4e1-10f38816c9c4",
   "metadata": {},
   "source": [
    "### **Q1. (10 pts) Refresher on normal-normal model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032f870-670f-4abb-bc4c-b44f54def65c",
   "metadata": {},
   "source": [
    "$$f(\\gamma \\vert y) \\propto f(y \\vert \\gamma) \\times f(\\gamma) \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big(y - ( X\\beta + Z\\gamma)\\big)^{T}\\sigma^{-2}I \\big(y - (X\\beta + Z\\gamma)\\big)\\big\\} \n",
    "\\times \\exp \\{-\\frac{1}{2} \\gamma^{T} \\Sigma^{-1} \\gamma \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big [ (y-(X\\beta + Z\\gamma))^{T} \\sigma^{-2}I(y-(X\\beta + Z\\gamma)) + \\gamma^{T}\\Sigma^{-1}\\big ]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big [ (y^{T}\\sigma^{-2}I - \\beta^{T}X^{T}\\sigma^{-2}I - \\gamma^{T}Z^{T}\\sigma^{-2}I) \\times (y-X\\beta-Z\\gamma) + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big \\}\\\\\n",
    "\\propto \\exp \\big \\{-\\frac{1}{2} \\big [-y^{T}\\sigma^{-2}Z\\gamma + \\beta^{T}X^{T}Z\\gamma - \\gamma Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "\\exp \\big \\{-\\frac{1}{2} \\big [ -\\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big (-\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) - \\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big) \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\}\n",
    "$$ \n",
    "\n",
    "By multivariate completion of square, we know that:\n",
    "\n",
    "$$ \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma -2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) \\propto \\\\\n",
    "(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1} \\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\sigma^{-2}Z^{T}(y-X\\beta))$$\n",
    "\n",
    "Which means:\n",
    "\n",
    "$$\\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\} \\propto \\\\\n",
    "\\exp \\big \\{ -\\frac{1}{2} \\big [ (\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))\\big]\\big\\}$$\n",
    "\n",
    "Which is the kernel of a Multivariate Normal Density with:\n",
    "\n",
    "- **Mean** : $\\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta)$\n",
    "- **Covariance**: $(\\sigma^{-2}Z_i^{T}Z + \\Sigma^{-1})^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc25a92-3b48-4d6e-8814-e0e924cfacb4",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Derive EM algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4e18-de6e-49b4-a2af-03a7754b13d0",
   "metadata": {},
   "source": [
    "**1. Write Down the Complete Log-Likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81e232-5e5e-4387-adf4-42eae6d405c3",
   "metadata": {},
   "source": [
    "$$ \\ell(\\beta, \\Sigma, \\sigma^2) = \\sum_{i = 1}^{m}-\\frac{1}{2}\\log \\det(2\\pi\\sigma^2I) - \\frac{1}{2}(y_i - (X_i\\beta + Z\\gamma_i))^{T}(\\sigma^2I)(y_i - (X_i\\beta + Z\\gamma_i)) - \\frac{1}{2} \\log \\det(2\\pi\\Sigma) -\\frac{1}{2} \\gamma_i\\Sigma^{-1}\\gamma_i\\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i + \\gamma_i^{T}Z_i^{T}Z_i\\gamma_i] - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}\\sigma^{-2}Z_i^{T}Z_i\\gamma_i - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492016a4-3abb-4eb1-9520-06a0ecbcefb1",
   "metadata": {},
   "source": [
    "**2. Derive the $Q$ function (E-step).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42b40e-af00-4fdb-96c6-7c92dd33d2bf",
   "metadata": {},
   "source": [
    "- Recall from the first problem: \n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i) = \\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta) = \\mu_{\\gamma \\mid y} \\\\\n",
    "\\mathrm{Var}(\\gamma_i \\mid y_i) =  (\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1} = \\Sigma_{\\gamma \\mid y}$\n",
    "- Recall the following property regarding quadratic forms from 250A: \\\n",
    "If $x \\sim N_q(\\mu, \\Sigma)$ then $\\mathbb{E}(x^{T}Ax) = \\mathrm{tr}(A\\Sigma) + \\mu^{T}A\\mu$ \n",
    "- Putting these two together, we see that: \\\n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) = \\sigma^{-2(t)}(\\sigma^{-2(t)}Z_i^{T}Z_i + \\Sigma^{-1(t)})^{-1}Z_i^{T}(y_i-X_i\\beta^{(t)}) = \\mu^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathrm{Var}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) =  (\\sigma^{-2}Z_i^{T}Z_i + (\\Sigma^{(t)})^{-1})^{-1} = \\Sigma^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathbb{E}(\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i) = \\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y}] + \\mu^{T(t)}_{\\gamma \\mid y}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}$ \n",
    "\n",
    "- Using these results we see that the conditional expectation evaluates to:\n",
    "$$\\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2} \\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[\\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...})]\n",
    "$$\n",
    "\n",
    "- Which leaves us with:\n",
    "$$ Q = \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...})]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325e9f1-1a9f-4e60-8c98-2ccb72be1c9c",
   "metadata": {},
   "source": [
    "**2. Derive the EM (or ECM) update of $\\mathbf{\\beta, \\sigma^2, \\Sigma}$ .**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d1bb8-8c33-49a7-a160-454e5f25b4ab",
   "metadata": {},
   "source": [
    "- **Gradient with respect to $\\beta$:** \n",
    "$\\nabla_{\\beta} = \\frac{d}{d\\beta}[\\sum_{i=1}^{m} -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "=\\frac{d}{d\\beta}[\\sum_{i=1}^{m}-\\frac{1}{2\\sigma^2}(y^{T}_iy_i - 2\\beta^{T}X^{T}_iy_i + \\beta^{T}X^{T}_iX_i\\beta) - 2y_iZ_i\\mu_{\\gamma \\mid y ...} + 2\\beta^{T}X^{T}_iZ_i\\mu_{\\gamma \\mid y ...}]\\\\\n",
    "= \\sum_{i=1}^{m} X^{T}_iy_i - X^{T}_iX_i\\beta - X^{T}_iZ_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i=1}^{m} X_i^{T}(y_i - X_i\\beta) + X_iZ_i\\mu_{\\gamma \\mid y ...}\n",
    "$\n",
    "\n",
    "- **Gradient with respect to $\\sigma^2$:** \\\n",
    "$\\nabla_{\\sigma^2} = -\\frac{n_i}{2} \\log(\\sigma^2) -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) + \\frac{1}{\\sigma^2}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)T}_{\\gamma \\mid y ...})] \\\\\n",
    "=-\\frac{n_i}{\\sigma^2} + \\frac{1}{2\\sigma^4}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - \\frac{1}{\\sigma^4}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2\\sigma^4}\\mathrm{tr}[Z_i^{T}Z_i(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)T}_{\\gamma \\mid y ...})]\n",
    "$\n",
    "\n",
    "- **Gradient with respect to $\\Sigma$:** \\\n",
    "$\\nabla_{\\Sigma} = m - \\sum_{i=1}{m} \\Sigma^{-1}\\Sigma^{(t)}_{\\gamma \\mid y ...} \\Sigma^{-1} - \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)T}_{\\gamma \\mid y ...}\\Sigma^{-1}$\n",
    "\n",
    "- **Next: To get (t+1) iterated value of $\\mathbf{\\beta, \\sigma^2}$ and $\\mathbf{\\Sigma}$ we set all of the gradients equal to zero and solve for the variable of interest. This gives us:**\n",
    " 1. $\\beta^{(t + 1)} = (\\sum_{i=1}^{m} X_i^{T}X_i)^{-1}(\\sum_{i=1}^{m} X_i^{T}y_i - X_i^{T}Z_i\\mu^{(t)}_{\\gamma \\mid y ...})$\n",
    " 2. $\\sigma^{2(t+1)} = \\frac{\\sum_{i=1}^{m}(y_i-X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)Z_i\\mu^{(t)}_{\\gamma \\mid y ...} + \\mathrm{tr}[Z_i^{T}Z_i(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)}_{\\gamma \\mid y}]}{n}$\n",
    " 3. $\\Sigma^{(t+1)} = \\frac{1}{m} \\sum_{i=1}^{m} \\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)T}_{\\gamma \\mid y ...}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec69cc-f4be-4328-8d56-202eeb563678",
   "metadata": {},
   "source": [
    "### **Q3. (20 pts) Objective of a single datum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7110e-1913-4daf-8aef-5ca4f1aff096",
   "metadata": {},
   "source": [
    "We modify the code from HW5 to evaluate the objective, the conditional mean of  ùú∏ , and the conditional variance of  ùú∏ . Start-up code is provided below. You do not have to use this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a8de9f26-ea2e-4793-9058-da6b127752d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # posterior mean and variance of random effects Œ≥\n",
    "    ŒºŒ≥         :: Vector{T} # posterior mean of random effects\n",
    "    ŒΩŒ≥         :: Matrix{T} # posterior variance of random effects\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    rtr        :: Vector{T}\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    ztr        :: Vector{T}\n",
    "    ltztr      :: Vector{T}\n",
    "    xtr        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    ltztzl     :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "    storage_qq3:: Matrix{T}\n",
    "    storage_qq4:: Matrix{T}\n",
    "    storage_qq5:: Matrix{T}\n",
    "    storage_qq6:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "    y::Vector{T}, \n",
    "    X::Matrix{T}, \n",
    "    Z::Matrix{T}) where T <: AbstractFloat\n",
    "    n, p, q = size(X, 1), size(X, 2), size(Z, 2)\n",
    "    ŒºŒ≥         = Vector{T}(undef, q)\n",
    "    ŒΩŒ≥         = Matrix{T}(undef, q, q)\n",
    "    yty        = abs2(norm(y))\n",
    "    rtr        = Vector{T}(undef, 1)\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y\n",
    "    ztr        = similar(zty)\n",
    "    ltztr      = similar(zty)\n",
    "    xtr        = Vector{T}(undef, p)\n",
    "    storage_p  = similar(xtr)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    ltztzl     = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz)\n",
    "    storage_qq3= similar(ztz)\n",
    "    storage_qq4= similar(ztz)\n",
    "    storage_qq5= similar(ztz)\n",
    "    storage_qq6=similar(ztz)\n",
    "    LmmObs(y, X, Z, ŒºŒ≥, ŒΩŒ≥, \n",
    "        yty, rtr, xty, zty, ztr, ltztr, xtr,\n",
    "        storage_p, storage_q, \n",
    "        xtx, ztx, ztz, ltztzl, storage_qq, storage_qq2, storage_qq3, storage_qq4, storage_qq5, storage_qq6)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, Œ≤, Œ£, L, œÉ¬≤, updater = false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `Œ≤`, `Œ£`, \n",
    "and `œÉ¬≤`. The lower triangular Cholesky factor `L` of `Œ£` must be supplied too.\n",
    "The fields `obs.ŒºŒ≥` and `obs.ŒΩŒ≥` are overwritten by the posterior mean and \n",
    "posterior variance of random effects. If `updater==true`, fields `obs.ztr`, \n",
    "`obs.xtr`, and `obs.rtr` are updated according to input parameter values. \n",
    "Otherwise, it assumes these three fields are pre-computed. \n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs     :: LmmObs{T}, \n",
    "        Œ≤       :: Vector{T}, \n",
    "        Œ£       :: Matrix{T},\n",
    "        L       :: Matrix{T},\n",
    "        œÉ¬≤      :: T,\n",
    "        updater :: Bool = false\n",
    "        ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    œÉ¬≤inv   = inv(œÉ¬≤)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################\n",
    "    # form the q-by-q matrix: Lt Zt Z L\n",
    "    copy!(obs.ltztzl, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.ltztzl) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.ltztzl) # O(q^3)        \n",
    "    # form the q-by-q matrix: M = œÉ¬≤ I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ltztzl)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += œÉ¬≤\n",
    "    end\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # Zt * res\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), copy!(obs.ztr, obs.zty)) # O(pq)\n",
    "    # Lt * (Zt * res)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, copy!(obs.ltztr, obs.ztr))    # O(q^2)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, copy!(obs.storage_q, obs.ltztr)) # O(q^3)\n",
    "    # Xt * res = Xt * y - Xt * X * Œ≤\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.xtx, Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "    # l2 norm of residual vector\n",
    "    updater && (obs.rtr[1] = obs.yty - dot(obs.xty, Œ≤) - dot(obs.xtr, Œ≤))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2œÄ) + (n - q) * log(œÉ¬≤) # constant term\n",
    "    @inbounds for j in 1:q # log det term\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (obs.rtr[1] - qf) * œÉ¬≤inv \n",
    "    logl /= -2\n",
    "    ######################################\n",
    "    # TODO: Evaluate posterior mean and variance\n",
    "    \n",
    "    ### posterior variance (ŒΩŒ≥) ###\n",
    "    \n",
    "    copy!(obs.storage_qq2, obs.ztz)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq2) \n",
    "    # ztzL\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "    # L'ztzL\n",
    "    LAPACK.potrs!('U', obs.storage_qq, obs.storage_qq2)\n",
    "    # (V'V)^{-1} L'ztzL\n",
    "    \n",
    "    mul!(obs.storage_qq3, obs.ztz, L) \n",
    "    copy!(obs.storage_qq4, obs.storage_qq3)\n",
    "    BLAS.gemm!('N', 'N', T(1/œÉ¬≤), obs.storage_qq3, obs.storage_qq2, \n",
    "            T(-1/œÉ¬≤), obs.storage_qq4)\n",
    "    # 1/œÉ¬≤*ztzL*(V'V)^{-1} L'ztzL - 1/œÉ¬≤*ztzL \n",
    "        \n",
    "    # // note: (V'V)^{-1} L'ztzL computed previously, \n",
    "    # stored in obs.storage_qq2\n",
    "    \n",
    "    ### all code prior to this (in this section) was\n",
    "    ### taken from my work from HW5 as it was almost the same formula\n",
    "    \n",
    "    mul!(obs.storage_qq5, L, transpose(L))\n",
    "    copy!(obs.storage_qq6, L)\n",
    "    BLAS.gemm!('N', 'N',  T(1), obs.storage_qq5, obs.storage_qq4, T(1), obs.storage_qq6)\n",
    "    mul!(obs.ŒΩŒ≥, obs.storage_qq6, transpose(L))\n",
    "    \n",
    "    \n",
    "    ### posterior mean (ŒºŒ≥) ###\n",
    "    \n",
    "    BLAS.gemm!('N','N', T(1), obs.ŒΩŒ≥, obs.ztr, T(0), obs.ŒºŒ≥)\n",
    "    obs.ŒºŒ≥ ./= œÉ¬≤\n",
    "    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58531ef-68d0-4dda-a7ef-c288c2aa1143",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/posterior mean/var evaluator here. It's the same test datum in HW3 and HW5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "807b7f0d-8be8-4eb4-9d74-1a4ae0f14c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "Z = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Œ£)).L)\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69dba2-b323-45e1-8ead-02d064c723df",
   "metadata": {},
   "source": [
    "#### **3.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55b8ee1f-221c-48e3-a965-daf2c9cd7a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true) = -3256.1793358058258\n",
      "obs.ŒºŒ≥ = [0.10608689298645836, -0.251041906089828, -1.4653979410591285]\n",
      "obs.ŒΩŒ≥ = [0.0007494356395767454 -1.2183420378162024e-6 -2.1767836705487566e-6; -1.21834204662441e-6 0.0007542331466978082 2.1553464636468693e-5; -2.1767836415192976e-6 2.15534646046981e-5 0.0007465271345336]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true)\n",
    "@show obs.ŒºŒ≥\n",
    "@show obs.ŒΩŒ≥;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7253f72-0ddc-4e01-8090-3971c187fe38",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws AssertionError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37920311-d839-46ea-9d73-83a24e540612",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.ŒºŒ≥ - [0.10608689301333621, \n",
    "        -0.25104190602577225, -1.4653979409855415]) < 1e-4\n",
    "@assert norm(obs.ŒΩŒ≥ - [\n",
    "        0.0007494356395909563 -1.2183420093769967e-6 -2.176783643112221e-6; \n",
    "        -1.2183420282298223e-6 0.0007542331467601107 2.1553464632686345e-5; \n",
    "        -2.1767836636008638e-6 2.1553464641863096e-5 0.0007465271342535443\n",
    "        ]) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c4ef2-8f00-46f0-a88b-75cdb18df818",
   "metadata": {},
   "source": [
    "#### **3.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae8d8c-2543-4232-8d90-1ca3e48b44a5",
   "metadata": {},
   "source": [
    "Benchmark for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37873522-e1ae-4a25-88f8-bc411e3c48b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.054 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 18.968 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.197 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.385 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m544.252 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[34m‚ñà\u001b[39m\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[32m \u001b[39m\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñá\u001b[39m\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñá\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m \u001b[39m‚ñà\n",
       "  2.05 Œºs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      4.51 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj = @benchmark logl!($obs, $Œ≤, $Œ£, $L, $œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2733e-5709-4d42-880a-329809bab0df",
   "metadata": {},
   "source": [
    "My median run time is 1.8Œºs. You will get full credit if the median run time is within 10Œºs. The points you will get are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee62b6b5-ecdf-4eac-b52a-82f56b75f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_obj).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24965a1f-a8c3-471a-994c-a2a239d06647",
   "metadata": {},
   "source": [
    "### **Q4. LmmModel type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19faefc-df2d-4600-a600-71a62457d729",
   "metadata": {},
   "source": [
    "We modify the LmmModel type in HW4 to hold all data points, model parameters, and intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06720c97-cb80-4415-8666-eac9bc0832b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmModel"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat}\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    Œ≤      :: Vector{T}\n",
    "    Œ£      :: Matrix{T}\n",
    "    L      :: Matrix{T}\n",
    "    œÉ¬≤     :: Vector{T}    \n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty    :: Vector{T}\n",
    "    xtr    :: Vector{T}\n",
    "    ztr2   :: Vector{T}\n",
    "    xtxinv :: Matrix{T}\n",
    "    ztz2   :: Matrix{T}\n",
    "    storage_p:: Vector{T}\n",
    "    storage_p2:: Vector{T}\n",
    "    storage_p3:: Vector{T}\n",
    "    storage_q:: Vector{T}\n",
    "    storage_q2:: Vector{T}\n",
    "    storage_pq :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    p      = size(obsvec[1].X, 2)\n",
    "    q      = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    Œ≤      = Vector{T}(undef, p)\n",
    "    Œ£      = Matrix{T}(undef, q, q)\n",
    "    L      = Matrix{T}(undef, q, q)\n",
    "    œÉ¬≤     = Vector{T}(undef, 1)    \n",
    "    # intermediate arrays\n",
    "    xty    = zeros(T, p)\n",
    "    xtr    = similar(xty)\n",
    "    ztr2   = Vector{T}(undef, abs2(q))\n",
    "    xtxinv = zeros(T, p, p)\n",
    "    storage_p = zeros(T, p)\n",
    "    storage_p2 = zeros(T, p)\n",
    "    storage_p3 = zeros(T, p)\n",
    "    storage_q = zeros(T, q)\n",
    "    storage_q2 = zeros(T, q)\n",
    "    storage_pq = zeros(T, p, q)\n",
    "    storage_qq = zeros(T, q, q)\n",
    "    storage_qq2 = zeros(T, q, q)\n",
    "    # pre-calculate \\sum_i Xi^T Xi and \\sum_i Xi^T y_i\n",
    "    @inbounds for i in eachindex(obsvec)\n",
    "        obs = obsvec[i]\n",
    "        BLAS.axpy!(T(1), obs.xtx, xtxinv)\n",
    "        BLAS.axpy!(T(1), obs.xty, xty)\n",
    "    end\n",
    "    # invert X'X\n",
    "    LAPACK.potrf!('U', xtxinv)\n",
    "    LAPACK.potri!('U', xtxinv)\n",
    "    LinearAlgebra.copytri!(xtxinv, 'U')\n",
    "    ztz2   = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    LmmModel(obsvec, Œ≤, Œ£, L, œÉ¬≤, xty, xtr, ztr2, xtxinv, ztz2, storage_p, storage_p2, storage_p3, storage_q, \n",
    "        storage_q2, storage_pq, storage_qq, storage_qq2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fb0cc-9479-4f0a-a39d-0c71ef889712",
   "metadata": {},
   "source": [
    "### **Q5. Implement EM update**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc647c4-3f57-438b-a6ba-65c2c502070d",
   "metadata": {},
   "source": [
    "Let's write the key function `update_em!` that performs one iteration of EM update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03d5a347-4bfa-4dd7-bea7-804e87a475b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_em!"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    update_em!(m::LmmModel, updater::Bool = false)\n",
    "\n",
    "Perform one iteration of EM update. It returns the log-likelihood calculated \n",
    "from input `m.Œ≤`, `m.Œ£`, `m.L`, and `m.œÉ¬≤`. These fields are then overwritten \n",
    "by the next EM iterate. The fields `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` are updated according to the resultant `m.Œ≤`. If `updater==true`, \n",
    "the function first updates `m.data[i].xtr`, `m.data[i].ztr`, and \n",
    "`m.data[i].rtr` according to `m.Œ≤`. If `updater==false`, it assumes these fields \n",
    "are pre-computed.\n",
    "\"\"\"\n",
    "function update_em!(m::LmmModel{T}, updater::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    \n",
    "    # Do E step (evaluate conditional likelihood (Q function))\n",
    "    for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.Œ≤, m.Œ£, m.L, m.œÉ¬≤[1], updater)\n",
    "    end\n",
    "    \n",
    "    # TODO: update m.Œ≤\n",
    "    \n",
    "    # summing up xtz*mu_gamma|y...\n",
    "    fill!(m.storage_p2, zero(T))\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_p, transpose(obs.ztx), obs.ŒºŒ≥)\n",
    "        # xtz*mu_gamma|y..\n",
    "        BLAS.axpy!(T(1), m.storage_p, m.storage_p2) \n",
    "        # sum of xtz*mu_gamma|y...\n",
    "    end\n",
    "    \n",
    "    copy!(m.storage_p3, m.xty) \n",
    "    BLAS.axpy!(T(-1), m.storage_p2, m.storage_p3) \n",
    "    # sum xty - xtz*mu_gamma|y..\n",
    "    mul!(m.Œ≤, m.xtxinv, m.storage_p3) \n",
    "    # done updating Œ≤\n",
    "    \n",
    "    # TODO: update m.data[i].ztr, m.data[i].xtr, m.data[i].rtr\n",
    "    \n",
    "    total_n = 0\n",
    "    m.œÉ¬≤[1] = 0\n",
    "    for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        total_n += size(obs.X, 1)\n",
    "        \n",
    "        # copied and pasted from Dr. Zhou\n",
    "        BLAS.gemv!('N', T(-1), obs.ztx, m.Œ≤, T(1), copy!(obs.ztr, obs.zty))\n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, m.Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "        obs.rtr[1] = obs.yty - dot(obs.xty, m.Œ≤) - dot(obs.xtr, m.Œ≤)\n",
    "        \n",
    "    # TODO: update m.œÉ¬≤\n",
    "    \n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_qq, obs.ztz, obs.ŒΩŒ≥)\n",
    "        mul!(m.storage_q2, obs.ztz, obs.ŒºŒ≥)\n",
    "        m.œÉ¬≤[1] += obs.rtr[1] - 2*dot(obs.ŒºŒ≥, obs.ztr) + tr(m.storage_qq) + dot(obs.ŒºŒ≥, m.storage_q2)\n",
    "        # trace invariant under cyclic permuatation so turned last term into scalar\n",
    "        # probably will result in faster computation\n",
    "        # this last line serves as a summation\n",
    "    end \n",
    "    m.œÉ¬≤[1] /= total_n\n",
    "    \n",
    "    # TODO: update m.Œ£\n",
    "    \n",
    "     fill!(m.Œ£, 0)\n",
    "     for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        mul!(m.storage_qq2, obs.ŒºŒ≥, transpose(obs.ŒºŒ≥))\n",
    "        axpy!(T(1), obs.ŒΩŒ≥ , m.storage_qq2)\n",
    "        axpy!(T(1), m.storage_qq2, m.Œ£) # store the m values of m.storage_qq2 into m.Œ£\n",
    "        # basically serves as a loop/summation\n",
    "    end\n",
    "    \n",
    "    m.Œ£ ./= length(m.data)\n",
    "    \n",
    "    # TODO: update m.L\n",
    "    copy!(m.L, m.Œ£)\n",
    "    LAPACK.potrf!('L', m.L)\n",
    "    m.L .= LowerTriangular(m.L)\n",
    "    \n",
    "    # update m.Œ£ and m.L\n",
    "    # return log-likelihood at input parameter values\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301509f-f360-4959-83e3-c5961c3264ef",
   "metadata": {},
   "source": [
    "### **Q6. (30 pts) Test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbc074-9a40-406c-98d5-055bf28fe6e7",
   "metadata": {},
   "source": [
    "Let's generate a fake longitudinal data set (same as HW3) to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7cc1acbf-5077-486a-88be-88d966d78b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "Œ≤true  = [0.1; 6.5; -3.5; 1.0; 5]\n",
    "œÉ¬≤true = 1.5\n",
    "œÉtrue  = sqrt(œÉ¬≤true)\n",
    "Œ£true  = Matrix(Diagonal([2.0; 1.2; 1.0]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Œ£true)).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * Œ≤true .+ Z * (Ltrue * randn(q)) .+ œÉtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7aeb5c-bce8-4390-8b4d-bf02eb1e169e",
   "metadata": {},
   "source": [
    "#### **6.1  Correctness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ed5c0-65a7-490c-a83b-920d00987948",
   "metadata": {},
   "source": [
    "Evaluate log-likelihood and gradient at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "969eef81-d9b3-4705-8a08-73356c3b1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj1 = update_em!(lmm, true) = -2.840068438369969e6\n",
      "lmm.Œ≤ = [0.10003613677198955, 6.500382871080708, -3.499864634212745, 0.999712465761216, 4.9992308514638095]\n",
      "lmm.Œ£ = [1.9903882756209161 0.06862095706500466 0.05347290178448214; 0.06862095706500496 1.2813220460869357 -0.09044913325236677; 0.05347290178448159 -0.09044913325236685 0.9435400745494044]\n",
      "lmm.L = [1.4108112118993512 0.0 0.0; 0.04863936186941818 1.130909482922427 0.0; 0.03790223761582666 -0.08160924927866609 0.9671832429096827]\n",
      "lmm.œÉ¬≤ = [1.4987367279245443]\n",
      "\n",
      "obj2 = update_em!(lmm, false) = -2.840060460542052e6\n",
      "lmm.Œ≤ = [0.10007136579939484, 6.5003835506298255, -3.499864298042971, 0.9997119269509729, 4.999229480978238]\n",
      "lmm.Œ£ = [1.9903775377604382 0.0687010767817089 0.05354351748307733; 0.06870107678171015 1.2814409212658784 -0.09059223998821613; 0.053543517483077084 -0.09059223998821533 0.9434431688151598]\n",
      "lmm.L = [1.410807406331721 0.0 0.0; 0.04869628304570763 1.1309595895890403 0.0; 0.03795239324855619 -0.08173623648719344 0.9671204538767527]\n",
      "lmm.œÉ¬≤ = [1.4987345544162016]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 1.4987345544162016"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy!(lmm.Œ≤, Œ≤true)\n",
    "copy!(lmm.Œ£, Œ£true)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.œÉ¬≤[1] = œÉ¬≤true\n",
    "@show obj1 = update_em!(lmm, true)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.Œ£\n",
    "@show lmm.L\n",
    "@show lmm.œÉ¬≤\n",
    "println()\n",
    "@show obj2 = update_em!(lmm, false)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.Œ£\n",
    "@show lmm.L\n",
    "@show lmm.œÉ¬≤ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac032f8-52a8-4541-9558-db273c25d679",
   "metadata": {},
   "source": [
    "Test correctness. You will loss all 30 points if following code throws AssertError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1878167f-fff4-47e1-8591-52c2093a98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(obj1 - (-2.840068438369969e6)) < 1e-4\n",
    "@assert abs(obj2 - (-2.84006046054206e6)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a22838-f4bd-4ff5-92c9-6cfc61502d52",
   "metadata": {},
   "source": [
    "#### **6.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387071bf-57ff-402f-a542-ee9a99e2f829",
   "metadata": {},
   "source": [
    "Test efficiency of EM update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed5999b0-4827-41cc-b1f0-8aed4f7c91e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 717 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m3.212 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m45.469 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m4.950 ms              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m6.951 ms\u001b[22m\u001b[39m ¬± \u001b[32m 5.715 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñÜ\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[32m‚ñÇ\u001b[39m\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÅ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m \u001b[39m‚ñà\n",
       "  3.21 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       35 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_emupdate = @benchmark update_em!($lmm, true) setup=(\n",
    "    copy!(lmm.Œ≤, Œ≤true);\n",
    "    copy!(lmm.Œ£, Œ£true);\n",
    "    copy!(lmm.L, Ltrue);\n",
    "    lmm.œÉ¬≤[1] = œÉ¬≤true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83eee0-73c5-4968-ace0-87c175e7fba7",
   "metadata": {},
   "source": [
    "My median run time is 2.4ms. You will get full credit if your median run time is within 10ms. The points you will get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8578bbf0-46bd-49d0-9576-181650528497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_emupdate).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7adcc-d4db-4a9a-967f-80be39e94c43",
   "metadata": {},
   "source": [
    "#### **6.3  Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22324c-2ec5-4a37-a9eb-3f480e26b584",
   "metadata": {},
   "source": [
    "You will lose 1 point for each 100 bytes memory allocation. So the points you will get is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "def4bac4-56cb-493e-b8f7-583bf7aad772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_emupdate).memory / 100, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7819d-37f0-4960-a989-5d5955ee7c3f",
   "metadata": {},
   "source": [
    "### **Q7. Starting point**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbda9d-4586-4032-b99e-f7d49787d5e7",
   "metadata": {},
   "source": [
    "We use the same least squares estimates as in HW4 as starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d31bedc5-7ca2-4b98-af1d-3e5e41507226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kron_axpy!"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    init_ls!(m::LmmModel)\n",
    "\n",
    "Initialize parameters of a `LmmModel` object from the least squares estimate. \n",
    "`m.Œ≤`, `m.L`, and `m.œÉ¬≤` are overwritten with the least squares estimates.\n",
    "\"\"\"\n",
    "function init_ls!(m::LmmModel{T}) where T <: AbstractFloat\n",
    "    p, q = size(m.data[1].X, 2), size(m.data[1].Z, 2)\n",
    "    # LS estimate for Œ≤\n",
    "    mul!(m.Œ≤, m.xtxinv, m.xty)\n",
    "    # LS etimate for œÉ2 and Œ£\n",
    "    rss, ntotal = zero(T), 0\n",
    "    fill!(m.ztz2, 0)\n",
    "    fill!(m.ztr2, 0)    \n",
    "    @inbounds for i in eachindex(m.data)\n",
    "        obs = m.data[i]\n",
    "        ntotal += length(obs.y)\n",
    "        # update Xt * res\n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, m.Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "        # rss of i-th individual\n",
    "        rss += obs.yty - dot(obs.xty, m.Œ≤) - dot(obs.xtr, m.Œ≤)\n",
    "        # update Zi' * res\n",
    "        BLAS.gemv!('N', T(-1), obs.ztx, m.Œ≤, T(1), copy!(obs.ztr, obs.zty))\n",
    "        # Zi'Zi ‚äó Zi'Zi\n",
    "        kron_axpy!(obs.ztz, obs.ztz, m.ztz2)\n",
    "        # Zi'res ‚äó Zi'res\n",
    "        kron_axpy!(obs.ztr, obs.ztr, m.ztr2)\n",
    "    end\n",
    "    m.œÉ¬≤[1] = rss / ntotal\n",
    "    # LS estimate for Œ£ = LLt\n",
    "    LAPACK.potrf!('U', m.ztz2)\n",
    "    BLAS.trsv!('U', 'T', 'N', m.ztz2, m.ztr2)\n",
    "    BLAS.trsv!('U', 'N', 'N', m.ztz2, m.ztr2)\n",
    "    copyto!(m.Œ£, m.ztr2)\n",
    "    copy!(m.L, m.Œ£)\n",
    "    LAPACK.potrf!('L', m.L)\n",
    "    for j in 2:q, i in 1:j-1\n",
    "        m.L[i, j] = 0\n",
    "    end\n",
    "    m\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    kron_axpy!(A, X, Y)\n",
    "\n",
    "Overwrite `Y` with `A ‚äó X + Y`. Same as `Y += kron(A, X)` but\n",
    "more memory efficient.\n",
    "\"\"\"\n",
    "function kron_axpy!(\n",
    "        A::AbstractVecOrMat{T},\n",
    "        X::AbstractVecOrMat{T},\n",
    "        Y::AbstractVecOrMat{T}\n",
    "        ) where T <: Real\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    p, q = size(X, 1), size(X, 2)\n",
    "    @assert size(Y, 1) == m * p\n",
    "    @assert size(Y, 2) == n * q\n",
    "    @inbounds for j in 1:n\n",
    "        coffset = (j - 1) * q\n",
    "        for i in 1:m\n",
    "            a = A[i, j]\n",
    "            roffset = (i - 1) * p            \n",
    "            for l in 1:q\n",
    "                r = roffset + 1\n",
    "                c = coffset + l\n",
    "                for k in 1:p                \n",
    "                    Y[r, c] += a * X[k, l]\n",
    "                    r += 1\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    Y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33fc2008-c851-4c19-b132-e7195b8138be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmm.Œ≤ = [0.18207934611476334, 6.500480700993723, -3.4979107842091604, 1.001113296229796, 5.0002519857919285]\n",
      "lmm.Œ£ = [1.979430283668505 0.0725846100391669 0.05717147035274013; 0.07258461003916691 1.2840385734767714 -0.0770794276897856; 0.05717147035274013 -0.0770794276897856 0.9509885905046902]\n",
      "lmm.L = [1.4069222734993234 0.0 0.0; 0.05159105901325531 1.1319792118703693 0.0; 0.04063584138912108 -0.06994463586493141 0.9718256360134829]\n",
      "lmm.œÉ¬≤ = [5.709004733413663]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 5.709004733413663"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ls!(lmm)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.Œ£\n",
    "@show lmm.L\n",
    "@show lmm.œÉ¬≤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f13a8-b340-420e-aa7b-e862eda6fd9f",
   "metadata": {},
   "source": [
    "### **Q8. Estimation by EM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8f3a6-32c2-47cd-821f-7a4f8e75e63d",
   "metadata": {},
   "source": [
    "We write a function fit! that implements the EM algorithm for estimating LMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "134fbbcd-28b0-44e0-bafb-27fce73e7740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit!"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    fit!(m::LmmModel)\n",
    "\n",
    "Fit an `LmmModel` object by MLE using a EM algorithm. Start point \n",
    "should be provided in `m.Œ≤`, `m.œÉ¬≤`, `m.L`.\n",
    "\"\"\"\n",
    "function fit!(\n",
    "        m       :: LmmModel;\n",
    "        maxiter :: Integer       = 10_000,\n",
    "        ftolrel :: AbstractFloat = 1e-12,\n",
    "        prtfreq :: Integer       = 0\n",
    "    )\n",
    "    obj = update_em!(m, true)\n",
    "    for iter in 0:maxiter\n",
    "        obj_old = obj\n",
    "        # EM update\n",
    "        obj = update_em!(m, false)\n",
    "        # print obj\n",
    "        prtfreq > 0 && rem(iter, prtfreq) == 0 && println(\"iter=$iter, obj=$obj\")\n",
    "        # check monotonicity\n",
    "        obj < obj_old && (@warn \"monotoniciy violated\")\n",
    "        # check convergence criterion\n",
    "        (obj - obj_old) < ftolrel * (abs(obj_old) + 1) && break\n",
    "        # warning about non-convergence\n",
    "        iter == maxiter && (@warn \"maximum iterations reached\")\n",
    "    end\n",
    "    m\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d22d1-609c-43c2-9619-252f60c7931a",
   "metadata": {},
   "source": [
    "### **Q9. (20 pts) Test drive**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e8b4e-7ce7-47ba-accc-9d5767349a18",
   "metadata": {},
   "source": [
    "Now we can run our EM algorithm to compute the MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f8524b86-78a2-4849-8097-a15f6db5b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=0, obj=-2.840068882178377e6\n",
      "iter=1, obj=-2.840058786755683e6\n",
      "iter=2, obj=-2.840058786725547e6\n",
      "iter=3, obj=-2.8400587867254745e6\n",
      "  0.215029 seconds (129.40 k allocations: 6.794 MiB, 81.02% compilation time)\n",
      "objective value at solution: -2.8400587867254107e6\n",
      "\n",
      "solution values:\n",
      "lmm.Œ≤ = [0.18207855826609343, 6.5003835473916585, -3.4998642962256814, 0.9997119252305023, 4.999229481211592]\n",
      "lmm.œÉ¬≤ = [1.4987345519190163]\n",
      "lmm.L * transpose(lmm.L) = [1.9836319855126596 0.06575202044787296 0.05528837691380524; 0.06575202044787296 1.281440988361751 -0.09059254195882695; 0.05528837691380524 -0.09059254195882695 0.9434430471596223]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3√ó3 Matrix{Float64}:\n",
       " 1.98363     0.065752    0.0552884\n",
       " 0.065752    1.28144    -0.0905925\n",
       " 0.0552884  -0.0905925   0.943443"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize from least squares\n",
    "init_ls!(lmm)\n",
    "\n",
    "@time fit!(lmm, prtfreq = 1);\n",
    "\n",
    "println(\"objective value at solution: \", update_em!(lmm)); println()\n",
    "println(\"solution values:\")\n",
    "@show lmm.Œ≤\n",
    "@show lmm.œÉ¬≤\n",
    "@show lmm.L * transpose(lmm.L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52720c46-e4a8-44ee-bfd9-0f1670a33479",
   "metadata": {},
   "source": [
    "You get 10 points if the following code does not throw AssertError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "98b92caa-468f-4137-9a25-4f65fc258683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective at solution should be close enough to the optimal\n",
    "@assert update_em!(lmm) > -2.840059e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5d84d-be1f-4553-82f1-ac5e09932b65",
   "metadata": {},
   "source": [
    "#### **9.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08e449-e670-4ac6-9fbf-a07af154e8bb",
   "metadata": {},
   "source": [
    "My median run time 12ms. You get 10 points if your median run time is within 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5b1b12e-e63c-49c5-b64e-fa25bf88a2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 202 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m18.652 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m44.892 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m22.793 ms              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m24.032 ms\u001b[22m\u001b[39m ¬± \u001b[32m 4.475 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[34m‚ñÉ\u001b[39m\u001b[39m‚ñÉ\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[32m‚ñá\u001b[39m\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m \u001b[39m‚ñÉ\n",
       "  18.7 ms\u001b[90m         Histogram: frequency by time\u001b[39m        43.5 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_em = @benchmark fit!($lmm) setup = (init_ls!(lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "567bda67-11b5-4daf-ad20-207b15690819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "clamp(1 / (median(bm_em).time / 1e9) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdde8a-384b-4834-9d02-848d3ed500d4",
   "metadata": {},
   "source": [
    "### **Q10. (10 pts) EM vs Newton type algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84f320-057d-42da-98e8-378918808f27",
   "metadata": {},
   "source": [
    "Contrast EM algorithm to the Newton type algorithms (gradient free, gradient based, using Hessian) in HW5, in terms of the stability, convergence rate (how fast the algorithm is converging), final objective value, total run time, derivation, and implementation efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd7e3c-41b5-442c-9481-0cd90f49fcac",
   "metadata": {},
   "source": [
    "The EM algorithm appears to be slower than the Newton algorithm, and that Newton converges faster and is more accurate. I have never taken a matrix calculus class, but both algorithms involved some knowledge of those topics, so they were similiar in that respect, at least for me. The EM algorithm is more difficult for me to understand conceptually than Newton. Finally, in terms of implementation, both were quite tediousm but I understood the mechanics of the Newton algorithm more easily than EM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
