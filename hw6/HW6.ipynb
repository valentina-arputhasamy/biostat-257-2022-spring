{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f9c170-c4be-4289-a160-7d89a697e248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Biostat 257 Homework 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3779796-3128-41fc-8d0d-a5b278925a7e",
   "metadata": {},
   "source": [
    "**Due June 10 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60b03c9-bda8-4969-a1d1-b8e7fcece384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, Distributions, LinearAlgebra, Random, Revise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617f4fc-b328-4dfb-a4e1-10f38816c9c4",
   "metadata": {},
   "source": [
    "### **Q1. (10 pts) Refresher on normal-normal model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032f870-670f-4abb-bc4c-b44f54def65c",
   "metadata": {},
   "source": [
    "$$f(\\gamma \\vert y) \\propto f(y \\vert \\gamma) \\times f(\\gamma) \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big(y - ( X\\beta + Z\\gamma)\\big)^{T}\\sigma^{-2}I \\big(y - (X\\beta + Z\\gamma)\\big)\\big\\} \n",
    "\\times \\exp \\{-\\frac{1}{2} \\gamma^{T} \\Sigma^{-1} \\gamma \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big [ (y-(X\\beta + Z\\gamma))^{T} \\sigma^{-2}I(y-(X\\beta + Z\\gamma)) + \\gamma^{T}\\Sigma^{-1}\\big ]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big [ (y^{T}\\sigma^{-2}I - \\beta^{T}X^{T}\\sigma^{-2}I - \\gamma^{T}Z^{T}\\sigma^{-2}I) \\times (y-X\\beta-Z\\gamma) + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big \\}\\\\\n",
    "\\propto \\exp \\big \\{-\\frac{1}{2} \\big [-y^{T}\\sigma^{-2}Z\\gamma + \\beta^{T}X^{T}Z\\gamma - \\gamma Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "\\exp \\big \\{-\\frac{1}{2} \\big [ -\\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta - \\gamma^{T}Z^{T}\\sigma^{-2}y + \\gamma^{T}Z^{T}\\sigma^{-2}X\\beta + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big]\\big\\} \\\\\n",
    "= \\exp \\big \\{-\\frac{1}{2} \\big (-\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) - \\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}Z^{T}\\sigma^{-2}Z\\gamma + \\gamma^{T}\\Sigma^{-1}\\gamma \\big) \\big\\} \\\\\n",
    "= \\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\}\n",
    "$$ \n",
    "\n",
    "By multivariate completion of square, we know that:\n",
    "\n",
    "$$ \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma -2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) \\propto \\\\\n",
    "(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1} \\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\sigma^{-2}Z^{T}(y-X\\beta))$$\n",
    "\n",
    "Which means:\n",
    "\n",
    "$$\\exp \\big \\{ -\\frac{1}{2} \\big (-2\\sigma^{-2}\\gamma^{T}Z^{T}(y-X\\beta) + \\gamma^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})\\gamma \\big)\\big\\} \\propto \\\\\n",
    "\\exp \\big \\{ -\\frac{1}{2} \\big [ (\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))^{T}(\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})(\\gamma - (\\sigma^{-2}Z^{T}Z + \\Sigma^{-1})^{-1}\\sigma^{-2}Z^{T}(y-X\\beta))\\big]\\big\\}$$\n",
    "\n",
    "Which is the kernel of a Multivariate Normal Density with:\n",
    "\n",
    "- **Mean** : $\\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta)$\n",
    "- **Covariance**: $(\\sigma^{-2}Z_i^{T}Z + \\Sigma^{-1})^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc25a92-3b48-4d6e-8814-e0e924cfacb4",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Derive EM algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4e18-de6e-49b4-a2af-03a7754b13d0",
   "metadata": {},
   "source": [
    "**1. Write Down the Complete Log-Likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d81e232-5e5e-4387-adf4-42eae6d405c3",
   "metadata": {},
   "source": [
    "$$ \\ell(\\beta, \\Sigma, \\sigma^2) = \\sum_{i = 1}^{m}-\\frac{1}{2}\\log \\det(2\\pi\\sigma^2I) - \\frac{1}{2}(y_i - (X_i\\beta + Z\\gamma_i))^{T}(\\sigma^2I)(y_i - (X_i\\beta + Z\\gamma_i)) - \\frac{1}{2} \\log \\det(2\\pi\\Sigma) -\\frac{1}{2} \\gamma_i\\Sigma^{-1}\\gamma_i\\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i + \\gamma_i^{T}Z_i^{T}Z_i\\gamma_i] - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}\\sigma^{-2}Z_i^{T}Z_i\\gamma_i - \\frac{1}{2}\\gamma_i^{T}\\Sigma^{-1}\\gamma_i \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log\\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\gamma_i) -\\frac{1}{2}\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492016a4-3abb-4eb1-9520-06a0ecbcefb1",
   "metadata": {},
   "source": [
    "**2. Derive the $Q$ function (E-step).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42b40e-af00-4fdb-96c6-7c92dd33d2bf",
   "metadata": {},
   "source": [
    "- Recall from the first problem: \n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i) = \\sigma^{-2}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1}Z_i^{T}(y_i-X_i\\beta) = \\mu_{\\gamma \\mid y} \\\\\n",
    "\\mathrm{Var}(\\gamma_i \\mid y_i) =  (\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})^{-1} = \\Sigma_{\\gamma \\mid y}$\n",
    "- Recall the following property regarding quadratic forms from 250A: \\\n",
    "If $x \\sim N_q(\\mu, \\Sigma)$ then $\\mathbb{E}(x^{T}Ax) = \\mathrm{tr}(A\\Sigma) + \\mu^{T}A\\mu$ \n",
    "- Putting these two together, we see that: \\\n",
    "$\\mathbb{E}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) = \\sigma^{-2(t)}(\\sigma^{-2(t)}Z_i^{T}Z_i + \\Sigma^{-1(t)})^{-1}Z_i^{T}(y_i-X_i\\beta^{(t)}) = \\mu^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathrm{Var}(\\gamma_i \\mid y_i, \\beta^{(t)}, \\Sigma^{(t)}, \\sigma^{2(t)}) =  (\\sigma^{-2}Z_i^{T}Z_i + (\\Sigma^{(t)})^{-1})^{-1} = \\Sigma^{(t)}_{\\gamma \\mid y ...}$ \\\n",
    "$\\mathbb{E}(\\gamma_i^{T}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\gamma_i) = \\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y}] + \\mu^{T(t)}_{\\gamma \\mid y}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}$ \n",
    "\n",
    "- Using these results we see that the conditional expectation evaluates to:\n",
    "$$\\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2} \\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[\\mu^{T(t)}_{\\gamma \\mid y ...}(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\Sigma^{(t)}_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})\\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...}] \\\\\n",
    "= \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...}]\n",
    "$$\n",
    "\n",
    "- Which leaves us with:\n",
    "$$ Q = \\sum_{i = 1}^{m} -\\frac{(n_i + q)}{2}\\log(2\\pi) - \\frac{n_i}{2}\\log(\\sigma^2)-\\frac{1}{2}\\log \\det(\\Sigma) - \\frac{1}{2\\sigma^2}[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...}] - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{T(t)}_{\\gamma \\mid y ...}]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325e9f1-1a9f-4e60-8c98-2ccb72be1c9c",
   "metadata": {},
   "source": [
    "**2. Derive the EM (or ECM) update of $\\mathbf{\\beta, \\Sigma, \\sigma^2}$ .**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d1bb8-8c33-49a7-a160-454e5f25b4ab",
   "metadata": {},
   "source": [
    "- **Gradient with respect to $\\beta$:** \n",
    "$\\nabla_{\\beta} = \\frac{d}{d\\beta}[\\sum_{i=1}^{m} -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "=\\frac{d}{d\\beta}[\\sum_{i=1}^{m}-\\frac{1}{2\\sigma^2}(y^{T}_iy_i - 2\\beta^{T}X^{T}_iy_i + \\beta^{T}X^{T}_iX_i\\beta) - 2y_iZ_i\\mu_{\\gamma \\mid y ...} + 2\\beta^{T}X^{T}_iZ_i\\mu_{\\gamma \\mid y ...}]\\\\\n",
    "= \\sum_{i=1}^{m} X^{T}_iy_i - X^{T}_iX_i\\beta - X^{T}_iZ_i\\mu_{\\gamma \\mid y ...} \\\\\n",
    "= \\sum_{i=1}^{m} X_i^{T}(y_i - X_i\\beta) + X_iZ_i\\mu_{\\gamma \\mid y ...}\n",
    "$\n",
    "\n",
    "- **Gradient with respect to $\\sigma^2$:** \\\n",
    "$\\nabla_{\\sigma^2} = -\\frac{n_i}{2} \\log(\\sigma^2) -\\frac{1}{2\\sigma^2}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) + \\frac{1}{\\sigma^2}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2}\\mathrm{tr}[(\\sigma^{-2}Z_i^{T}Z_i + \\Sigma^{-1})(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...}\\mu^{(t)T}_{\\gamma \\mid y ...})] \\\\\n",
    "=-\\frac{n_i}{\\sigma^2} + \\frac{1}{2\\sigma^4}(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - \\frac{1}{\\sigma^4}(y_i - X_i\\beta)^{T}Z_i\\mu_{\\gamma \\mid y ...} - \\frac{1}{2\\sigma^4}\\mathrm{tr}[Z_i^{T}Z_i(\\Sigma^{(t)}_{\\gamma \\mid y ...} + \\mu^{(t)}_{\\gamma \\mid y ...} \\mu^{(t)T}_{\\gamma \\mid y ...})]\n",
    "$\n",
    "\n",
    "\n",
    "- **Next: To get (t+1) iterated value of $\\mathbf{\\beta, \\sigma^2}$ and $\\mathbf{\\Sigma}$ we set all of the gradients equal to zero and solve for the variable of interest. This gives us:**\n",
    " 1. $\\beta^{(t + 1)} = (\\sum_{i=1}^{m} X_i^{T}X_i)^{-1}(\\sum_{i=1}^{m} X_i^{T}y_i - X_i^{T}Z_i\\mu_{\\gamma \\mid y ...})$\n",
    " 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec69cc-f4be-4328-8d56-202eeb563678",
   "metadata": {},
   "source": [
    "### Q3. (20 pts) Objective of a single datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7110e-1913-4daf-8aef-5ca4f1aff096",
   "metadata": {},
   "source": [
    "We modify the code from HW5 to evaluate the objective, the conditional mean of  ùú∏ , and the conditional variance of  ùú∏ . Start-up code is provided below. You do not have to use this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de9f26-ea2e-4793-9058-da6b127752d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # posterior mean and variance of random effects Œ≥\n",
    "    ŒºŒ≥         :: Vector{T} # posterior mean of random effects\n",
    "    ŒΩŒ≥         :: Matrix{T} # posterior variance of random effects\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    rtr        :: Vector{T}\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    ztr        :: Vector{T}\n",
    "    ltztr      :: Vector{T}\n",
    "    xtr        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    ltztzl     :: Matrix{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T}\n",
    "    storage_qq3:: Matrix{T}\n",
    "    storage_qq4:: Matrix{T}\n",
    "    storage_qq5:: Matrix{T}\n",
    "    storage_qq6:: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "    y::Vector{T}, \n",
    "    X::Matrix{T}, \n",
    "    Z::Matrix{T}) where T <: AbstractFloat\n",
    "    n, p, q = size(X, 1), size(X, 2), size(Z, 2)\n",
    "    ŒºŒ≥         = Vector{T}(undef, q)\n",
    "    ŒΩŒ≥         = Matrix{T}(undef, q, q)\n",
    "    yty        = abs2(norm(y))\n",
    "    rtr        = Vector{T}(undef, 1)\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y\n",
    "    ztr        = similar(zty)\n",
    "    ltztr      = similar(zty)\n",
    "    xtr        = Vector{T}(undef, p)\n",
    "    storage_p  = similar(xtr)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    ltztzl     = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz)\n",
    "    storage_qq3= similar(ztz)\n",
    "    storage_qq4= similar(ztz)\n",
    "    storage_qq5= similar(ztz)\n",
    "    storage_qq6=similar(ztz)\n",
    "    LmmObs(y, X, Z, ŒºŒ≥, ŒΩŒ≥, \n",
    "        yty, rtr, xty, zty, ztr, ltztr, xtr,\n",
    "        storage_p, storage_q, \n",
    "        xtx, ztx, ztz, ltztzl, storage_qq, storage_qq2, storage_qq3, storage_qq4, storage_qq5, storage_qq6)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, Œ≤, Œ£, L, œÉ¬≤, updater = false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `Œ≤`, `Œ£`, \n",
    "and `œÉ¬≤`. The lower triangular Cholesky factor `L` of `Œ£` must be supplied too.\n",
    "The fields `obs.ŒºŒ≥` and `obs.ŒΩŒ≥` are overwritten by the posterior mean and \n",
    "posterior variance of random effects. If `updater==true`, fields `obs.ztr`, \n",
    "`obs.xtr`, and `obs.rtr` are updated according to input parameter values. \n",
    "Otherwise, it assumes these three fields are pre-computed. \n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs     :: LmmObs{T}, \n",
    "        Œ≤       :: Vector{T}, \n",
    "        Œ£       :: Matrix{T},\n",
    "        L       :: Matrix{T},\n",
    "        œÉ¬≤      :: T,\n",
    "        updater :: Bool = false\n",
    "        ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    œÉ¬≤inv   = inv(œÉ¬≤)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################\n",
    "    # form the q-by-q matrix: Lt Zt Z L\n",
    "    copy!(obs.ltztzl, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.ltztzl) # O(q^3)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.ltztzl) # O(q^3)        \n",
    "    # form the q-by-q matrix: M = œÉ¬≤ I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ltztzl)\n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += œÉ¬≤\n",
    "    end\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # O(q^3)\n",
    "    # Zt * res\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), copy!(obs.ztr, obs.zty)) # O(pq)\n",
    "    # Lt * (Zt * res)\n",
    "    BLAS.trmv!('L', 'T', 'N', L, copy!(obs.ltztr, obs.ztr))    # O(q^2)\n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, copy!(obs.storage_q, obs.ltztr)) # O(q^3)\n",
    "    # Xt * res = Xt * y - Xt * X * Œ≤\n",
    "    updater && BLAS.gemv!('N', T(-1), obs.xtx, Œ≤, T(1), copy!(obs.xtr, obs.xty))\n",
    "    # l2 norm of residual vector\n",
    "    updater && (obs.rtr[1] = obs.yty - dot(obs.xty, Œ≤) - dot(obs.xtr, Œ≤))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2œÄ) + (n - q) * log(œÉ¬≤) # constant term\n",
    "    @inbounds for j in 1:q # log det term\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (obs.rtr[1] - qf) * œÉ¬≤inv \n",
    "    logl /= -2\n",
    "    ######################################\n",
    "    # TODO: Evaluate posterior mean and variance\n",
    "    \n",
    "    ### posterior variance (ŒΩŒ≥) ###\n",
    "    \n",
    "    copy!(obs.storage_qq2, obs.ztz)\n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq2) \n",
    "    # ztzL\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "    # L'ztzL\n",
    "    LAPACK.potrs!('U', obs.storage_qq, obs.storage_qq2)\n",
    "    # (V'V)^{-1} L'ztzL\n",
    "    \n",
    "    mul!(obs.storage_qq3, obs.ztz, L) \n",
    "    copy!(obs.storage_qq4, obs.storage_qq3)\n",
    "    BLAS.gemm!('N', 'N', T(1/œÉ¬≤), obs.storage_qq3, obs.storage_qq2, \n",
    "            T(-1/œÉ¬≤), obs.storage_qq4)\n",
    "    # 1/œÉ¬≤*ztzL*(V'V)^{-1} L'ztzL - 1/œÉ¬≤*ztzL \n",
    "        \n",
    "    # // note: (V'V)^{-1} L'ztzL computed previously, \n",
    "    # stored in obs.storage_qq2\n",
    "    \n",
    "    mul!(obs.storage_qq5, L, transpose(L))\n",
    "    copy!(obs.storage_qq6, L)\n",
    "    BLAS.gemm!('N', 'N',  T(1), obs.storage_qq5, obs.storage_qq4, T(1), obs.storage_qq6)\n",
    "    mul!(obs.ŒΩŒ≥, obs.storage_qq6, transpose(L))\n",
    "    \n",
    "    \n",
    "    ### posterior mean (ŒºŒ≥) ###\n",
    "    \n",
    "    BLAS.gemm!('N','N', T(1), obs.ŒΩŒ≥, obs.ztr, T(0), obs.ŒºŒ≥)\n",
    "    obs.ŒºŒ≥ ./= œÉ¬≤\n",
    "    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58531ef-68d0-4dda-a7ef-c288c2aa1143",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/posterior mean/var evaluator here. It's the same test datum in HW3 and HW5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b7f0d-8be8-4eb4-9d74-1a4ae0f14c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "Z = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Œ£)).L)\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa111f6b-724c-485f-899a-3a6ad973f078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó3 Matrix{Float64}:\n",
       " -0.999236     0.100354    0.0916096\n",
       " -7.04315e-5  -1.00426     0.0916357\n",
       " -7.14965e-5  -4.0826e-5  -1.00844"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obs.storage_qq4 # S # -Z'*inv(œÉ¬≤*I + Z*L*L'*Z')*Z*L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a0e6b0-192e-4cf8-b890-b305de44262b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó3 Matrix{Float64}:\n",
       " -0.999236     0.100354    0.0916096\n",
       " -7.04315e-5  -1.00426     0.0916357\n",
       " -7.14965e-5  -4.0826e-5  -1.00844"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S = -Z'*inv(œÉ¬≤*I + Z*L*L'*Z')*Z*L # obs.storage_qq4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a92afe2-5be5-4bb2-8f0e-9c9e61aa4092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó3 Matrix{Float64}:\n",
       "  0.000749436  -1.21834e-6   -2.17678e-6\n",
       " -1.21834e-6    0.000754233   2.15535e-5\n",
       " -2.17678e-6    2.15535e-5    0.000746527"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(L + L*L'S)L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c1ca58-17c6-45cd-8260-ed80f3bb7423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3√ó3 Matrix{Float64}:\n",
       "  0.000749436  -1.21834e-6   -2.17678e-6\n",
       " -1.21834e-6    0.000754233   2.15535e-5\n",
       " -2.17678e-6    2.15535e-5    0.000746527"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B = L*L'-L*L'*Z'*inv(œÉ¬≤*I + Z*L*L'*Z')*Z*L*L' # L*L' - L*L' S L'   (L - L*L'S)L'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69dba2-b323-45e1-8ead-02d064c723df",
   "metadata": {},
   "source": [
    "#### **3.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b8ee1f-221c-48e3-a965-daf2c9cd7a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true) = -3256.1793358058258\n",
      "obs.ŒºŒ≥ = [0.10608689298645836, -0.251041906089828, -1.4653979410591285]\n",
      "obs.ŒΩŒ≥ = [0.0007494356395767454 -1.2183420378162024e-6 -2.1767836705487566e-6; -1.21834204662441e-6 0.0007542331466978082 2.1553464636468693e-5; -2.1767836415192976e-6 2.15534646046981e-5 0.0007465271345336]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, Œ≤, Œ£, L, œÉ¬≤, true)\n",
    "@show obs.ŒºŒ≥\n",
    "@show obs.ŒΩŒ≥;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7253f72-0ddc-4e01-8090-3971c187fe38",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws AssertionError."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37920311-d839-46ea-9d73-83a24e540612",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.ŒºŒ≥ - [0.10608689301333621, \n",
    "        -0.25104190602577225, -1.4653979409855415]) < 1e-4\n",
    "@assert norm(obs.ŒΩŒ≥ - [\n",
    "        0.0007494356395909563 -1.2183420093769967e-6 -2.176783643112221e-6; \n",
    "        -1.2183420282298223e-6 0.0007542331467601107 2.1553464632686345e-5; \n",
    "        -2.1767836636008638e-6 2.1553464641863096e-5 0.0007465271342535443\n",
    "        ]) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c4ef2-8f00-46f0-a88b-75cdb18df818",
   "metadata": {},
   "source": [
    "#### **3.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae8d8c-2543-4232-8d90-1ca3e48b44a5",
   "metadata": {},
   "source": [
    "Benchmark for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37873522-e1ae-4a25-88f8-bc411e3c48b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.034 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m587.205 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.158 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.884 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m  6.659 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñà\u001b[34m‚ñÜ\u001b[39m\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[32m‚ñÇ\u001b[39m\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÇ\n",
       "  \u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m \u001b[39m‚ñà\n",
       "  2.03 Œºs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      8.89 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_obj = @benchmark logl!($obs, $Œ≤, $Œ£, $L, $œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2733e-5709-4d42-880a-329809bab0df",
   "metadata": {},
   "source": [
    "My median run time is 1.8Œºs. You will get full credit if the median run time is within 10Œºs. The points you will get are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee62b6b5-ecdf-4eac-b52a-82f56b75f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_obj).time / 1e3) * 10, 0, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
