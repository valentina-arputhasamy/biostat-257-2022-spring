{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd79d47-ac07-485a-9ceb-dff0705abe4d",
   "metadata": {},
   "source": [
    "### BIOSTAT 257: HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109394f-81cd-412a-a71c-c1f3d45664de",
   "metadata": {},
   "source": [
    "#### Q1: Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850161b9-7136-476c-a796-77d43e46db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "using BenchmarkTools, DelimitedFiles, Images, LinearAlgebra, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224aed5a-c9d3-426b-8a6a-55b86c5d97a2",
   "metadata": {},
   "source": [
    "Consider a linear mixed effects model,\n",
    "        $$\\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma} + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n $$\n",
    " where,\n",
    " - $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,\n",
    " - $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of $i$-th individual,\n",
    " - $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of $i$-th individuaL,\n",
    " - $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$, \n",
    " - $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and\n",
    " - $\\boldsymbol{\\gamma} \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dae2e-ab8e-49a5-91e8-20d4cccb2639",
   "metadata": {},
   "source": [
    "#### Q1: Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c85ff-328e-47f9-8424-bd5e4a87984b",
   "metadata": {},
   "source": [
    "Write down the log-likelihood of the  ùëñ -th datum  (ùê≤ùëñ,ùêóùëñ,ùêôùëñ)  given parameters  (ùú∑,ùö∫,ùúé2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24906b-79ac-463b-96f2-9b8ff01903c8",
   "metadata": {},
   "source": [
    "Start by finding the distribution of $Y_i$: \n",
    "\n",
    "- $E(Y_i) = X_i\\beta$ \n",
    "- $Var(Y_i) = Z_i\\Sigma Z_i^{T} + \\sigma^2 I$\n",
    "- Therefore, $Y_i \\sim MVN(X_i\\beta, Z_i\\Sigma Z_i^{T} + \\sigma^2 I)$\n",
    "\n",
    "We use the pdf of the multivariate normal distribution with the above parameters to derive the log-likelihood function. Below is the derivation:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert Z_i\\Sigma Z_i^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(Z_i\\Sigma Z_i^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "We can use a Cholesky Decomposition to rewrite $\\Sigma$ as $LL'$ where $L$ is a lower triangular matrix.\n",
    "\n",
    "This gives us:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert Z_i LL^{T} Z_i^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(Z_i\\ LL^{T} Z_i^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "Now let $Z_iL = M$. This gives us:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert MM^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(MM^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "We can take advantage of the easy + low rank properties to evaluate $(MM^{T} + \\sigma^2 I)^{-1}$ using the Sherman-Woodbury formula, and $\\vert MM^{T} + \\sigma^2 I \\vert$ using the matrix determinant lemma.\n",
    "\n",
    "Starting with the Sherman-Woodbury formula, we evaluate $(MM^{T} + \\sigma^2 I)^{-1}$ to be:\n",
    "\n",
    "\\begin{align}\n",
    "(MM^{T} + \\sigma^2 I)^{-1} \n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)^{-1}M^{T}\n",
    "\\end{align}\n",
    "\n",
    "It can be proved that $\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)$ is positive semi-definite, and if we assume M is full rank, then it is positive-definite, which would allow us to apply another Cholesky Decomposition to this matrix. \n",
    "Let this Cholesky Decomposition be: $\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big) = AA^{T}$, where $A$ is a lower triangular matrix. This gives us:\n",
    "\\begin{align}\n",
    "(MM^{T} + \\sigma^2 I)^{-1} \n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)^{-1}M^{T} \\\\\n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M(AA^{T})^{-1}M^{T}\n",
    "\\end{align}\n",
    "\n",
    "Next we move onto the matrix determinant lemma and we evaluate $\\vert MM^{T} + \\sigma^2 I \\vert$:\n",
    "\\begin{align}\n",
    "\\vert MM^{T} + \\sigma^2 I \\vert &= \\sigma^{2n_i} \\vert \\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big) \\vert \\\\\n",
    "&=  \\sigma^{2n_i} \\vert AA^{T} \\vert\n",
    "\\end{align}\n",
    "\n",
    "Putting these together, we evaluate the log-likelihood to be:\n",
    "\\begin{align}\n",
    "&\\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i - X_i \\beta)^{T}(Y_i - X_i \\beta) + \\frac{1}{2 \\sigma^4}(Y_i - X_i \\beta)^{T}M(AA^{T})^{-1}M^{T}(Y_i - X_i \\beta) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) + \\frac{1}{2 \\sigma^4}(Y_i - X_i \\beta)^{T}M(AA^{T})^{-1}M^{T}(Y_i - X_i \\beta) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) + \\frac{1}{2 \\sigma^4}(A^{-1}L^{T}Z_i^T{}(Y_i - X \\beta))^{T}(A^{-1}L^{T}Z_i^T{}(Y_i - X \\beta)) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) \\\\\n",
    "&+ \\frac{1}{2 \\sigma^4}(Z_i^{T}Y_i - Z_i^{T}X \\beta)^{T}(A^{-1}L^{T})^{T}(A^{-1}L^{T})(Z_i^{T}Y_i - Z_i^{T}X \\beta) \\\\\n",
    "&= ((Z_i^{T}Y_i - Z_i^{T}X \\beta)^{T}L)A^{T}A^{-1}L^{T}(Z_i^{T}Y_i - Z_i{T}Y_i - Z_i^{T}X \\beta)\n",
    "\\end{align}\n",
    "\n",
    "Which leaves us with the final form we will utilize to write an efficient function designed to calculate this value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef7d25-cacd-4cfc-8a28-e0db0d05ecc1",
   "metadata": {},
   "source": [
    "#### Q2: Start-up code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094f126-e30d-4a66-8ed7-de06be468ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use the following template to define a type LmmObs that holds an LMM datum  (ùê≤ùëñ,ùêóùëñ,ùêôùëñ) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77731b28-6def-485a-8d0b-f7517b3601e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "# data\n",
    "    y :: Vector{T}\n",
    "    X :: Matrix{T}\n",
    "    Z :: Matrix{T}\n",
    "    # working arrays\n",
    "    # whatever intermediate arrays you may want to pre-allocate\n",
    "    #storage_n :: Vector{T}\n",
    "    storage_qq1 :: Matrix{T}\n",
    "    storage_qq2 :: Matrix{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    ztz :: Matrix{T}\n",
    "    yty :: T\n",
    "    xty :: Vector{T}\n",
    "    xtx :: Matrix{T}\n",
    "    ztx :: Matrix{T}\n",
    "    zty :: Vector{T}\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}) where T <: AbstractFloat\n",
    "    #storage_n = similar(y)\n",
    "    ztz = transpose(Z) * Z\n",
    "    det = similar(ztz)\n",
    "    storage_qq1 = similar(ztz)\n",
    "    storage_qq2 = similar(ztz)\n",
    "    storage_p  = Vector{T}(undef, size(X, 2))\n",
    "    storage_q  = Vector{T}(undef, size(Z, 2))\n",
    "    yty = transpose(y) * y\n",
    "    xty = transpose(X) * y\n",
    "    xtx = transpose(X) * X\n",
    "    ztx = transpose(Z) * X\n",
    "    zty = transpose(Z) * y\n",
    "    \n",
    "    LmmObs(y, X, Z, storage_qq1, storage_qq2, storage_p, storage_q, ztz, yty, xty, xtx, ztx, zty)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae08963-9b32-4505-9617-8c3dd3d1423b",
   "metadata": {},
   "source": [
    "Write a function, with interface:\n",
    "\n",
    "`logl!(obs, Œ≤, L, œÉ¬≤)`\n",
    "\n",
    "that evaluates the log-likelihood of the  $i$ -th datum. Here `L` is the lower triangular Cholesky factor from the Cholesky decomposition $\\Sigma$=LL'. Make your code efficient in the $n_i >> q$  case. Think the intensive longitudinal measurement setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03d05a10-8bae-46c6-ac14-03522f9b233a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl! (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logl!(\n",
    "        obs :: LmmObs{T}, \n",
    "        Œ≤   :: Vector{T}, \n",
    "        L   :: Matrix{T}, \n",
    "        œÉ¬≤  :: T) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)    \n",
    "    # TODO: compute and return the log-likelihood\n",
    "\n",
    "    #sleep(1e-3) # wait 1 ms as if your code takes 1ms\n",
    "    \n",
    "    obs.storage_qq1 .= Matrix(I, q, q)\n",
    "    \n",
    "    mul!(obs.storage_qq2, transpose(L), obs.ztz) \n",
    "    # calculating L'Z'Z (making use of ztz which was precacluated)\n",
    "    \n",
    "    obs.storage_qq2 .= obs.storage_qq2 .* L # L'Z'Z L \n",
    "    #rmul!(obs.storage_qq2, LowerTriangular(L)) \n",
    "    # turns out rmul! is not more efficient ;_;\n",
    "    \n",
    "    axpy!(1/œÉ¬≤, obs.storage_qq2, obs.storage_qq1) # a*X + Y \n",
    "    # where a = 1/œÉ¬≤, X = M'M, \n",
    "    #Y = I, stores in third argument\n",
    "    \n",
    "    aat = cholesky!(Symmetric(obs.storage_qq1)) # AA'\n",
    "    #a = potrf!(uplo = L, Symmetric(obs.storage_qq1))\n",
    "    \n",
    "    mul!(obs.storage_q, obs.ztx, Œ≤) \n",
    "    # Z'XŒ≤\n",
    "    \n",
    "    axpby!(1, obs.zty, -1, obs.storage_q) \n",
    "    #Z'Y - Z'XŒ≤ from expansion of last term in log-likelihood\n",
    "    \n",
    "    mul!(obs.storage_p, obs.xtx, Œ≤) \n",
    "    # X'XŒ≤ for faster multiplication in part of last term\n",
    "\n",
    "    return -n//2 * log(2œÄ) - n//2 * log(œÉ¬≤) - 1//2 * logdet(aat) -\n",
    "    1/(2 * (œÉ¬≤)) * (obs.yty - 2 * transpose(Œ≤) * obs.xty +  transpose(Œ≤) * obs.storage_p) +\n",
    "    1/(2 * (œÉ¬≤)^2) * (dot(transpose(L) * obs.storage_q, aat \\ transpose(L) * obs.storage_q)) \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf5456-8ded-4142-8347-e840371bb472",
   "metadata": {},
   "source": [
    "#### Q3: Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295aa6f0-fce2-4c06-bcff-a3afff883ad2",
   "metadata": {},
   "source": [
    "Compare your result (both accuracy and timing) to the Distributions.jl package using following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bce4eebb-f7db-4202-b0e6-d4a1f84cc5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs{Float64}([-1.450910909560209, 1.5185224894450862, 5.265021705624027, 4.485272594164557, 0.6949699666429332, 1.7723256696372407, 1.1065838446466518, 3.7291668118296073, 4.288899999400642, 2.8241842645202406  ‚Ä¶  4.058027151891635, 1.0909724390970443, 0.026692243086209766, -0.8927757653299448, 6.94725248926293, 3.519302085567343, 4.914007299083773, 2.1610206566690797, 1.857389542694909, 6.513818951020866], [1.0 0.6790633442371218 ‚Ä¶ 0.5400611947971554 -0.632040682052606; 1.0 1.2456776800889142 ‚Ä¶ -0.4818455756130373 0.6467830314674976; ‚Ä¶ ; 1.0 0.0733124748775436 ‚Ä¶ 0.6125080259511859 0.4181258283983667; 1.0 -1.336609049786048 ‚Ä¶ -0.18567490803712938 1.0745977099307227], [1.0 -1.0193326822839996 -0.15855601254314888; 1.0 1.7462667837699666 -0.4584376230657152; ‚Ä¶ ; 1.0 1.4843185594903878 0.42458303115266854; 1.0 0.3791714762820068 0.25150666970865837], [2.5057700244e-314 2.270241927e-314 5.0e-324; 2.544906727e-314 2.202366758e-314 NaN; 2.202366758e-314 2.202366758e-314 0.0007526874542236607], [2.0e-323 2.5449024583e-314 2.5449025847e-314; 3.0e-323 3.5e-323 2.5449026164e-314; 2.544902395e-314 5.0e-323 1991.1003959884654], [0.0, 0.0, 0.0, 0.0, 0.0], [0.15214400622533533, -0.33127402255062627, -2.192163852797872], [2000.0 3.207786785008377 5.8864999631191735; 3.207786785008377 1988.894096853326 -57.3189115446946; 5.8864999631191735 -57.3189115446946 2009.451939652711], 20378.320552515157, [4209.066417097508, -1849.2613478849603, 1339.1230193223864, 396.4337131159359, 1659.0630888170554], [2000.0 -16.870943820386746 ‚Ä¶ -4.678756487678486 -33.01394193208299; -16.870943820386746 1972.1480562703996 ‚Ä¶ 42.18373658967013 -18.842752802403005; ‚Ä¶ ; -4.678756487678486 42.18373658967013 ‚Ä¶ 1962.031706211974 31.9476748423444; -33.01394193208299 -18.842752802403005 ‚Ä¶ 31.9476748423444 1952.6108146037136], [2000.0 -16.870943820386746 ‚Ä¶ -4.678756487678486 -33.01394193208297; 3.207786785008377 51.535093570134116 ‚Ä¶ -5.599636592147196 -25.64263779027383; 5.8864999631191735 -108.82214158453627 ‚Ä¶ 84.16510226928119 -24.939700580608633], [4209.066417097506, -447.62664690981126, -2763.9856125358633])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Distributions, LinearAlgebra, Random\n",
    "\n",
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form an LmmObs object\n",
    "obs = LmmObs(y, X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc190807-b8b0-4aad-923c-d5d625eaf045",
   "metadata": {},
   "source": [
    "This is the standard way to evaluate log-density of a multivariate normal, using the Distributions.jl package. Let's evaluate the log-likelihood of this datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41456ad0-2f51-4457-b2a3-72a72599ee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.179335805832"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Œº  = X * Œ≤\n",
    "Œ©  = Z * Œ£ * transpose(Z) +  œÉ¬≤ * I\n",
    "mvn = MvNormal(Œº, Symmetric(Œ©)) # MVN(Œº, Œ£)\n",
    "logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c5704-6a9c-4d7a-8703-ab725a7ab5b4",
   "metadata": {},
   "source": [
    "Check that your answer matches that from Distributions.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a40cce74-861a-4845-85bc-6b2f75b0c8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3224.5007490251974"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Matrix(cholesky(Œ£).L)\n",
    "logl!(obs, Œ≤, L, œÉ¬≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39700581-4cd0-495c-9e13-7312f7906acb",
   "metadata": {},
   "source": [
    "You will lose all 15 + 30 + 30 = 75 points if the following statement throws `AssertionError.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9985557f-5096-4519-9312-4cbffa74518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert logl!(obs, Œ≤, Matrix(cholesky(Œ£).L), œÉ¬≤) ‚âà logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafe95a-94bc-4a70-9d41-88096b772150",
   "metadata": {},
   "source": [
    "#### Q4: Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763cbfe-c1ba-494d-bece-2d5c0a083879",
   "metadata": {},
   "source": [
    "Benchmarking your code and compare to the Distributions.jl function logpdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0478ec4-d65a-40e7-b316-f2f81e7e49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 4148 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.055 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 11.497 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 89.43%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.127 ms               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.189 ms\u001b[22m\u001b[39m ¬± \u001b[32m235.524 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.21% ¬±  1.39%\n",
       "\n",
       "  \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[34m‚ñÜ\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[32m‚ñÉ\u001b[39m\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m \u001b[39m‚ñà\n",
       "  1.05 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      1.92 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m31.52 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3\u001b[39m."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark the `logpdf` function in Distribution.jl\n",
    "bm1 = @benchmark logpdf($mvn, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50dee9af-c36e-444f-b8fb-968d99b523d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 10 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.442 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 16.804 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.508 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.631 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m360.549 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[34m‚ñÜ\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[32m‚ñÅ\u001b[39m\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÇ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m \u001b[39m‚ñà\n",
       "  1.44 Œºs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      2.85 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m400 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark your implementation\n",
    "L = Matrix(cholesky(Œ£).L)\n",
    "bm2 = @benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51bb3210-ee1b-4c3e-b0fa-f07b54cef27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.414986403130595"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you'll get\n",
    "clamp(median(bm1).time / median(bm2).time / 1000 * 30, 0, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9717e67-7d1c-4ce3-a393-bb076c2915ae",
   "metadata": {},
   "source": [
    "#### Q5: Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fec7e8-c08a-4f67-9fa3-72ec9bf24747",
   "metadata": {},
   "source": [
    "You want to avoid memory allocation in the \"hot\" function logl!. You will lose 1 point for each 1 KiB = 1024 bytes memory allocation. In other words, the points you get for this question is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1bd896f-a110-443a-b384-ea120711c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.609375"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(30 - median(bm2).memory / 1024, 0, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
