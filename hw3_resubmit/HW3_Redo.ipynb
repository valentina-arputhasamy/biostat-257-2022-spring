{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd79d47-ac07-485a-9ceb-dff0705abe4d",
   "metadata": {},
   "source": [
    "### BIOSTAT 257: HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109394f-81cd-412a-a71c-c1f3d45664de",
   "metadata": {},
   "source": [
    "#### Q1: Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850161b9-7136-476c-a796-77d43e46db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "using BenchmarkTools, DelimitedFiles, Images, LinearAlgebra, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224aed5a-c9d3-426b-8a6a-55b86c5d97a2",
   "metadata": {},
   "source": [
    "Consider a linear mixed effects model,\n",
    "        $$\\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma} + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n $$\n",
    " where,\n",
    " - $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,\n",
    " - $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of $i$-th individual,\n",
    " - $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of $i$-th individuaL,\n",
    " - $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$, \n",
    " - $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and\n",
    " - $\\boldsymbol{\\gamma} \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dae2e-ab8e-49a5-91e8-20d4cccb2639",
   "metadata": {},
   "source": [
    "#### Q1: Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c85ff-328e-47f9-8424-bd5e4a87984b",
   "metadata": {},
   "source": [
    "Write down the log-likelihood of the  ùëñ -th datum  (ùê≤ùëñ,ùêóùëñ,ùêôùëñ)  given parameters  (ùú∑,ùö∫,ùúé2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24906b-79ac-463b-96f2-9b8ff01903c8",
   "metadata": {},
   "source": [
    "Start by finding the distribution of $Y_i$: \n",
    "\n",
    "- $E(Y_i) = X_i\\beta$ \n",
    "- $Var(Y_i) = Z_i\\Sigma Z_i^{T} + \\sigma^2 I$\n",
    "- Therefore, $Y_i \\sim MVN(X_i\\beta, Z_i\\Sigma Z_i^{T} + \\sigma^2 I)$\n",
    "\n",
    "We use the pdf of the multivariate normal distribution with the above parameters to derive the log-likelihood function. Below is the derivation:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert Z_i\\Sigma Z_i^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(Z_i\\Sigma Z_i^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "We can use a Cholesky Decomposition to rewrite $\\Sigma$ as $LL'$ where $L$ is a lower triangular matrix.\n",
    "\n",
    "This gives us:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert Z_i LL^{T} Z_i^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(Z_i\\ LL^{T} Z_i^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "Now let $Z_iL = M$. This gives us:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{n_i}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\vert MM^{T} + \\sigma^2 I \\vert - \\frac{1}{2}(Y_i -X_i \\beta)^{T}(MM^{T} + \\sigma^2 I)^{-1}(Y_i - X_i \\beta)\n",
    "\\end{align}\n",
    "\n",
    "We can take advantage of the easy + low rank properties to evaluate $(MM^{T} + \\sigma^2 I)^{-1}$ using the Sherman-Woodbury formula, and $\\vert MM^{T} + \\sigma^2 I \\vert$ using the matrix determinant lemma.\n",
    "\n",
    "Starting with the Sherman-Woodbury formula, we evaluate $(MM^{T} + \\sigma^2 I)^{-1}$ to be:\n",
    "\n",
    "\\begin{align}\n",
    "(MM^{T} + \\sigma^2 I)^{-1} \n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)^{-1}M^{T}\n",
    "\\end{align}\n",
    "\n",
    "It can be proved that $\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)$ is positive semi-definite, and if we assume M is full rank, then it is positive-definite, which would allow us to apply another Cholesky Decomposition to this matrix. \n",
    "Let this Cholesky Decomposition be: $\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big) = AA^{T}$, where $A$ is a lower triangular matrix. This gives us:\n",
    "\\begin{align}\n",
    "(MM^{T} + \\sigma^2 I)^{-1} \n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M\\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big)^{-1}M^{T} \\\\\n",
    "&= \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^4} M(AA^{T})^{-1}M^{T}\n",
    "\\end{align}\n",
    "\n",
    "Next we move onto the matrix determinant lemma and we evaluate $\\vert MM^{T} + \\sigma^2 I \\vert$:\n",
    "\\begin{align}\n",
    "\\vert MM^{T} + \\sigma^2 I \\vert &= \\sigma^{2n_i} \\vert \\big(I + \\frac{1}{\\sigma^2}M^{T}M\\big) \\vert \\\\\n",
    "&=  \\sigma^{2n_i} \\vert AA^{T} \\vert\n",
    "\\end{align}\n",
    "\n",
    "Putting these together, we evaluate the log-likelihood to be:\n",
    "\\begin{align}\n",
    "&\\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i - X_i \\beta)^{T}(Y_i - X_i \\beta) + \\frac{1}{2 \\sigma^4}(Y_i - X_i \\beta)^{T}M(AA^{T})^{-1}M^{T}(Y_i - X_i \\beta) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) + \\frac{1}{2 \\sigma^4}(Y_i - X_i \\beta)^{T}M(AA^{T})^{-1}M^{T}(Y_i - X_i \\beta) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) + \\frac{1}{2 \\sigma^4}(A^{-1}L^{T}Z_i^T{}(Y_i - X \\beta))^{T}(A^{-1}L^{T}Z_i^T{}(Y_i - X \\beta)) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) \\\\\n",
    "&+ \\frac{1}{2 \\sigma^4}(Z_i^{T}Y_i - Z_i^{T}X \\beta)^{T}(A^{-1}L^{T})^{T}(A^{-1}L^{T})(Z_i^{T}Y_i - Z_i^{T}X \\beta) \\\\\n",
    "&= \\frac{n_i}{2} \\log(2\\pi) - \\frac{n_i}{2} \\log(\\sigma^2) - \\frac{1}{2}\\log \\vert AA^{T} \\vert - \\frac{1}{2 \\sigma^2}(Y_i^{T}Y_i - 2Y_i^{T}X_i \\beta + \\beta^{T}X_i^{T}X_i \\beta) \\\\ &+ ((Z_i^{T}Y_i - Z_i^{T}X \\beta)^{T}L)(A^{T})^{-1}A^{-1}L^{T}(Z_i^{T}Y_i - Z_i^{T}X \\beta)\n",
    "\\end{align}\n",
    "\n",
    "Which leaves us with the final form we will utilize to write an efficient function designed to calculate this value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef7d25-cacd-4cfc-8a28-e0db0d05ecc1",
   "metadata": {},
   "source": [
    "#### Q2: Start-up code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094f126-e30d-4a66-8ed7-de06be468ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use the following template to define a type LmmObs that holds an LMM datum  (ùê≤ùëñ,ùêóùëñ,ùêôùëñ) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77731b28-6def-485a-8d0b-f7517b3601e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "# data\n",
    "    y :: Vector{T}\n",
    "    X :: Matrix{T}\n",
    "    Z :: Matrix{T}\n",
    "    # working arrays\n",
    "    # whatever intermediate arrays you may want to pre-allocate\n",
    "    #storage_n :: Vector{T}\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2 :: Matrix{T}\n",
    "    storage_qq3 :: Matrix{T}\n",
    "    storage_nq :: Matrix{T}\n",
    "    storage_nq2 :: Matrix{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    storage_q2  :: Vector{T}\n",
    "    ztz :: Matrix{T}\n",
    "    yty :: T\n",
    "    xty :: Vector{T}\n",
    "    xtx :: Matrix{T}\n",
    "    ztx :: Matrix{T}\n",
    "    zty :: Vector{T}\n",
    "end\n",
    "\n",
    "# constructor\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}) where T <: AbstractFloat\n",
    "    #storage_n = similar(y)\n",
    "    ztz = transpose(Z) * Z\n",
    "    det = similar(ztz)\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2 = similar(ztz)\n",
    "    storage_qq3 = similar(ztz)\n",
    "    storage_nq = Matrix{T}(undef, n, q)\n",
    "    storage_nq2 = Matrix{T}(undef, n, q)\n",
    "    storage_p  = Vector{T}(undef, size(X, 2))\n",
    "    storage_q  = Vector{T}(undef, size(Z, 2))\n",
    "    storage_q2  = Vector{T}(undef, size(Z, 2))\n",
    "    yty = transpose(y) * y\n",
    "    xty = transpose(X) * y\n",
    "    xtx = transpose(X) * X\n",
    "    ztx = transpose(Z) * X\n",
    "    zty = transpose(Z) * y\n",
    "    \n",
    "    LmmObs(y, X, Z, storage_qq, storage_qq2, storage_qq3, storage_nq, \n",
    "        storage_nq2, storage_p, storage_q, storage_q2,\n",
    "        ztz, yty, xty, xtx, ztx, zty)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae08963-9b32-4505-9617-8c3dd3d1423b",
   "metadata": {},
   "source": [
    "Write a function, with interface:\n",
    "\n",
    "`logl!(obs, Œ≤, L, œÉ¬≤)`\n",
    "\n",
    "that evaluates the log-likelihood of the  $i$ -th datum. Here `L` is the lower triangular Cholesky factor from the Cholesky decomposition $\\Sigma$=LL'. Make your code efficient in the $n_i >> q$  case. Think the intensive longitudinal measurement setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d05a10-8bae-46c6-ac14-03522f9b233a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl! (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logl!(\n",
    "        obs :: LmmObs{T}, \n",
    "        Œ≤   :: Vector{T}, \n",
    "        L   :: Matrix{T}, \n",
    "        œÉ¬≤  :: T) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)    \n",
    "    # TODO: compute and return the log-likelihood\n",
    "\n",
    "    #sleep(1e-3) # wait 1 ms as if your code takes 1ms\n",
    "    \n",
    "    mul!(obs.storage_qq, obs.ztz, L) \n",
    "    #ztzL\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', AbstractFloat(1), L, obs.storage_qq) \n",
    "    #L'ztzL\n",
    "    BLAS.axpy!(AbstractFloat(œÉ¬≤), Matrix(I, q, q), obs.storage_qq) \n",
    "    # seems good but seems to be an issue with using float64 here\n",
    "    # L'Z'ZL + œÉ¬≤I \n",
    "    copy!(obs.storage_qq3, obs.storage_qq)\n",
    "    LAPACK.potrf!('U', obs.storage_qq) \n",
    "    # extract A' = V from cholesky on M \n",
    "    \n",
    "    ## term 3 ##\n",
    "    \n",
    "    mul!(obs.storage_qq2, transpose(obs.storage_qq), obs.storage_qq) \n",
    "    # V'V # cannot estimate this because it leads to a one point \n",
    "    # difference in true and computed values \n",
    "\n",
    "    \n",
    "    # term 4\n",
    "    mul!(obs.storage_p, obs.xtx, Œ≤) \n",
    "    (obs.yty - 2 * transpose(Œ≤) * obs.xty +  transpose(Œ≤) * obs.storage_p) \n",
    "    \n",
    "    # term 5\n",
    "    \n",
    "    copy!(obs.storage_q, obs.zty)\n",
    "    BLAS.gemv!('N', AbstractFloat(-1), obs.ztx, Œ≤, T(1), obs.storage_q)  \n",
    "    # z'y - z'xŒ≤ \n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q) \n",
    "    # L'(z'y - z'xŒ≤)\n",
    "    \n",
    "    \n",
    "    copy!(obs.storage_q2, obs.storage_q)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q2) \n",
    "    # # V'^{-1} L'(z'y - z'xŒ≤)\n",
    "    \n",
    "    BLAS.trsv!('U', 'N', 'N', obs.storage_qq, obs.storage_q2) \n",
    "    # V^{-1}V'^{-1} L'(zty - ztxŒ≤)\n",
    "    \n",
    "    #scalar = dot(obs.storage_q, obs.storage_q2)\n",
    "    # (y'z - Œ≤'x'z)L*V^{-1}V'^{-1} L'(zty - ztxŒ≤) \n",
    "    \n",
    "\n",
    "    return -0.5 * n * log(2œÄ) - 0.5 * n * log(œÉ¬≤) - \n",
    "    .5 * logdet(I + (1/œÉ¬≤) * transpose(L) * obs.ztz * L) - \n",
    "    0.5 * (1/œÉ¬≤) * (obs.yty - 2 * transpose(Œ≤) * obs.xty +  transpose(Œ≤) \n",
    "        * obs.storage_p) + \n",
    "    .5 * (1/œÉ¬≤) * dot(obs.storage_q, obs.storage_q2) \n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf5456-8ded-4142-8347-e840371bb472",
   "metadata": {},
   "source": [
    "#### Q3: Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295aa6f0-fce2-4c06-bcff-a3afff883ad2",
   "metadata": {},
   "source": [
    "Compare your result (both accuracy and timing) to the Distributions.jl package using following data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce4eebb-f7db-4202-b0e6-d4a1f84cc5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LmmObs{Float64}([-1.450910909560209, 1.5185224894450862, 5.265021705624027, 4.485272594164557, 0.6949699666429332, 1.7723256696372407, 1.1065838446466518, 3.7291668118296073, 4.288899999400642, 2.8241842645202406  ‚Ä¶  4.058027151891635, 1.0909724390970443, 0.026692243086209766, -0.8927757653299448, 6.94725248926293, 3.519302085567343, 4.914007299083773, 2.1610206566690797, 1.857389542694909, 6.513818951020866], [1.0 0.6790633442371218 ‚Ä¶ 0.5400611947971554 -0.632040682052606; 1.0 1.2456776800889142 ‚Ä¶ -0.4818455756130373 0.6467830314674976; ‚Ä¶ ; 1.0 0.0733124748775436 ‚Ä¶ 0.6125080259511859 0.4181258283983667; 1.0 -1.336609049786048 ‚Ä¶ -0.18567490803712938 1.0745977099307227], [1.0 -1.0193326822839996 -0.15855601254314888; 1.0 1.7462667837699666 -0.4584376230657152; ‚Ä¶ ; 1.0 1.4843185594903878 0.42458303115266854; 1.0 0.3791714762820068 0.25150666970865837], [1361.4372929891945 142.38078230100288 132.84215761688665; 0.10458122679186291 1302.862124596768 68.50124271390091; 0.09757493665038086 0.05257750718258223 1299.7139435324555], [2000.9094286748127 196.36530531587152 201.09980277392083; 3.7241615076210746 1973.739949477704 124.73016996112848; 5.832740846530681 -56.79544020047261 1991.1003959884654], [1360.4372929891945 142.38078230100288 132.84215761688665; 142.38078230100285 1316.752481481392 82.39403852715293; 132.84215761688665 82.39403852715293 1315.277633227229], [6.93843530853337e-310 0.0 0.0; 0.0 3.187e-321 0.0; ‚Ä¶ ; 0.0 NaN 0.0; 0.0 0.0 NaN], [2.6204927867e-314 2.620713314e-314 2.621821776e-314; 2.6204928104e-314 2.6207133376e-314 2.6218235545e-314; ‚Ä¶ ; 2.6207132664e-314 2.6218217047e-314 1.6070584418482046e-270; 2.62071329e-314 2.6218217284e-314 2.126527038009773e232], [1.5e-323, 4.0e-323, 4.4e-323, 5.4e-323, 6.0e-323], [5.0e-324, 1.0e-323, 1.5e-323], [5.0e-324, 1.0e-323, 1.5e-323], [2000.0 3.207786785008377 5.8864999631191735; 3.207786785008377 1988.894096853326 -57.3189115446946; 5.8864999631191735 -57.3189115446946 2009.451939652711], 20378.320552515157, [4209.066417097508, -1849.2613478849603, 1339.1230193223864, 396.4337131159359, 1659.0630888170554], [2000.0 -16.870943820386746 ‚Ä¶ -4.678756487678486 -33.01394193208299; -16.870943820386746 1972.1480562703996 ‚Ä¶ 42.18373658967013 -18.842752802403005; ‚Ä¶ ; -4.678756487678486 42.18373658967013 ‚Ä¶ 1962.031706211974 31.9476748423444; -33.01394193208299 -18.842752802403005 ‚Ä¶ 31.9476748423444 1952.6108146037136], [2000.0 -16.870943820386746 ‚Ä¶ -4.678756487678486 -33.01394193208297; 3.207786785008377 51.535093570134116 ‚Ä¶ -5.599636592147196 -25.64263779027383; 5.8864999631191735 -108.82214158453627 ‚Ä¶ 84.16510226928119 -24.939700580608633], [4209.066417097506, -447.62664690981126, -2763.9856125358633])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Distributions, LinearAlgebra, Random\n",
    "\n",
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form an LmmObs object\n",
    "obs = LmmObs(y, X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc190807-b8b0-4aad-923c-d5d625eaf045",
   "metadata": {},
   "source": [
    "This is the standard way to evaluate log-density of a multivariate normal, using the Distributions.jl package. Let's evaluate the log-likelihood of this datum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41456ad0-2f51-4457-b2a3-72a72599ee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.179335805832"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Œº  = X * Œ≤\n",
    "Œ©  = Z * Œ£ * transpose(Z) +  œÉ¬≤ * I\n",
    "mvn = MvNormal(Œº, Symmetric(Œ©)) # MVN(Œº, Œ£)\n",
    "logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c5704-6a9c-4d7a-8703-ab725a7ab5b4",
   "metadata": {},
   "source": [
    "Check that your answer matches that from Distributions.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40cce74-861a-4845-85bc-6b2f75b0c8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.1793358058267"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Matrix(cholesky(Œ£).L)\n",
    "logl!(obs, Œ≤, L, œÉ¬≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39700581-4cd0-495c-9e13-7312f7906acb",
   "metadata": {},
   "source": [
    "You will lose all 15 + 30 + 30 = 75 points if the following statement throws `AssertionError.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9985557f-5096-4519-9312-4cbffa74518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert logl!(obs, Œ≤, Matrix(cholesky(Œ£).L), œÉ¬≤) ‚âà logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafe95a-94bc-4a70-9d41-88096b772150",
   "metadata": {},
   "source": [
    "#### Q4: Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763cbfe-c1ba-494d-bece-2d5c0a083879",
   "metadata": {},
   "source": [
    "Benchmarking your code and compare to the Distributions.jl function logpdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0478ec4-d65a-40e7-b316-f2f81e7e49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 337 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m937.169 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m822.393 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m  1.777 ms               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m 14.481 ms\u001b[22m\u001b[39m ¬± \u001b[32m 62.964 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[34m‚ñà\u001b[39m\u001b[39m‚ñÅ\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñá\u001b[32m‚ñÖ\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m \u001b[39m‚ñÖ\n",
       "  937 Œºs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        295 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m31.52 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3\u001b[39m."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark the `logpdf` function in Distribution.jl\n",
    "bm1 = @benchmark logpdf($mvn, $y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50dee9af-c36e-444f-b8fb-968d99b523d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 10 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.598 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m180.595 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.300 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.516 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m  4.727 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m‚ñá\u001b[39m\u001b[39m‚ñÖ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÉ\n",
       "  1.6 Œºs\u001b[90m          Histogram: frequency by time\u001b[39m        19.5 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m656 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark your implementation\n",
    "L = Matrix(cholesky(Œ£).L)\n",
    "bm2 = @benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51bb3210-ee1b-4c3e-b0fa-f07b54cef27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.15336292974136"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you'll get\n",
    "clamp(median(bm1).time / median(bm2).time / 1000 * 30, 0, 30)\n",
    "\n",
    "# when I previously checked this I got 24 points (I think due to the speed of my computer)\n",
    "# moved to a place with worse wifi and maybe that's why the score went down (?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9717e67-7d1c-4ce3-a393-bb076c2915ae",
   "metadata": {},
   "source": [
    "#### Q5: Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fec7e8-c08a-4f67-9fa3-72ec9bf24747",
   "metadata": {},
   "source": [
    "You want to avoid memory allocation in the \"hot\" function logl!. You will lose 1 point for each 1 KiB = 1024 bytes memory allocation. In other words, the points you get for this question is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1bd896f-a110-443a-b384-ea120711c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.359375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(30 - median(bm2).memory / 1024, 0, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
