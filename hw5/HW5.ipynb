{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cffcc901-c1a7-4557-bf18-1d6eb9454d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptInterface"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, CSV, DataFrames, DelimitedFiles, Distributions\n",
    "using Ipopt, LinearAlgebra, MathOptInterface, MixedModels, NLopt\n",
    "using PrettyTables, Random, RCall\n",
    "\n",
    "const MOI = MathOptInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc0674b3-e73f-4569-be7a-8f651cc6aebd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalArrays ─ v0.10.6\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Project.toml`\n",
      " \u001b[90m [6f49c342] \u001b[39m\u001b[92m+ RCall v0.13.13\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.7/Manifest.toml`\n",
      " \u001b[90m [324d7699] \u001b[39m\u001b[92m+ CategoricalArrays v0.10.6\u001b[39m\n",
      " \u001b[90m [6f49c342] \u001b[39m\u001b[92m+ RCall v0.13.13\u001b[39m\n",
      " \u001b[90m [1b915085] \u001b[39m\u001b[92m+ WinReg v0.3.1\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mWinReg\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalArrays\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mRCall\n",
      "  3 dependencies successfully precompiled in 7 seconds (308 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "#import Pkg; Pkg.add(\"RCall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c0d9a-eae8-4905-9bcf-f8e03036f827",
   "metadata": {},
   "source": [
    "### **Q1. (Optional, 30 bonus pts) Derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fb961-8b22-47ff-8a76-12cd61564e7d",
   "metadata": {},
   "source": [
    "1. Prove the following derivatives:\n",
    "\n",
    "- $\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$,\n",
    "- $\\nabla_{\\sigma^2} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = -\\frac{1}{2} tr(\\mathbf{\\Omega_i}^{-1}) + \\frac{1}{2}\\mathbf{r_i^{T}\\Omega_i^{-2}r_i}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a774a3-4435-42ca-b3e2-381f850f8ae8",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Objective and gradient evaluator for a single datum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8961-aaf0-4e48-ab0e-77c62821c20e",
   "metadata": {},
   "source": [
    "We expand the code from HW3 to evaluate both objective and gradient. I provide my code for HW3 below as a starting point. You do not have to use this code. If your come up faster code, that's even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75fd01-fd8f-477c-a5f8-9af1a0891b64",
   "metadata": {},
   "source": [
    "#### **Simplification of:** \n",
    "$\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$ \n",
    "\n",
    "We can use the Sherman Woodbury formula and a Cholesky decomposition to simply $M = (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}$, resulting in: $M^{-1} = \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(AA^{T})^{-1}L^{T}Z_i^{T}$\n",
    "\n",
    "$(AA^{T})^{-1}$ is the result of the Cholesky decomposition. A is a lower triangular matrix, and A' is an upper triangular matrix. However, in the code below, we extract the upper triangular matrix and store it as 'V' (not explicitly stored in the code as V, but I will write is as such in the math below so the results in the code are more clear). \n",
    "\n",
    "\\begin{align}\n",
    "X_i^{T} \\Omega_i r_i &= X_i^{T} (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}(y_i - X_i\\beta) \\\\\n",
    "&= X_i^{T}\\Big(\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T}\\Big)(y_i - X_i\\beta) \\\\\n",
    "&= \\frac{1}{\\sigma^2} (X_i^{T}y_i - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}y_i - X_i^{T}X_i\\beta + X_i^{T}Z_iV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}X_i\\beta) \\\\\n",
    "&= \\frac{1}{\\sigma^2} (X_i^{T}y_i - X_i{T}X_i\\beta - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}(Z_i^{T}y_i - Z_i^{T}X_i\\beta))\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134dcf6d-25fb-49e5-a557-1e5e4bc6e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # arrays for holding gradient\n",
    "    ∇β         :: Vector{T}\n",
    "    ∇σ²        :: Vector{T}\n",
    "    ∇Σ         :: Matrix{T}    \n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    storage_q2 :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    xtz        :: Matrix{T} # added by me\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qp :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q    = size(X, 1), size(X, 2), size(Z, 2)    \n",
    "    ∇β         = Vector{T}(undef, p)\n",
    "    ∇σ²        = Vector{T}(undef, 1)\n",
    "    ∇Σ         = Matrix{T}(undef, q, q)    \n",
    "    yty        = abs2(norm(y))\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y    \n",
    "    storage_p  = Vector{T}(undef, p)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    storage_q2 = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    xtz        = transpose(X) * Z # added by me\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qp = similar(ztx)\n",
    "    LmmObs(y, X, Z, ∇β, ∇σ², ∇Σ, \n",
    "        yty, xty, zty, storage_p, storage_q,\n",
    "        storage_q2, xtx, ztx, ztz, xtz, storage_qq, storage_qp)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, β, L, σ², needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `β`, `L`, \n",
    "and `σ²`. If `needgrad==true`, then `obs.∇β`, `obs.∇Σ`, and `obs.σ² are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs      :: LmmObs{T}, \n",
    "        β        :: Vector{T}, \n",
    "        L        :: Matrix{T}, \n",
    "        σ²       :: T,\n",
    "        needgrad :: Bool = true\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################    \n",
    "    # form the q-by-q matrix: M = σ² * I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq) \n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq) \n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += σ²\n",
    "    end\n",
    "    # cholesky on M = σ² * I + Lt Zt Z L\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # extract A' = V from cholesky on M \n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), copy!(obs.storage_q, obs.zty)) # z'y - z'xβ\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q)    # L'(z'y - z'xβ)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q) # V'^{-1} L'(z'y - z'xβ)\n",
    "    # l2 norm of residual vector\n",
    "    copy!(obs.storage_p, obs.xty)\n",
    "    rtr  = obs.yty +\n",
    "        dot(β, BLAS.gemv!('N', T(1), obs.xtx, β, T(-2), obs.storage_p))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2π) + (n - q) * log(σ²) # constant term\n",
    "    @inbounds for j in 1:q\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (rtr - qf) / σ² \n",
    "    logl /= -2\n",
    "    ###################\n",
    "    # Evaluate gradient\n",
    "    ###################    \n",
    "    if needgrad\n",
    "        # TODO: fill ∇β, ∇L, ∇σ² by gradients\n",
    "        #sleep(1e-3) # pretend this step takes 1ms\n",
    "        \n",
    "        ####### gradient wrt β #######\n",
    "        \n",
    "        # term 1 xty - xtxβ\n",
    "        \n",
    "        copy!(obs.∇β, obs.xty) # ∇β now contains xty\n",
    "        BLAS.gemv!('N', AbstractFloat(-1), obs.xtx, β, AbstractFloat(1), obs.∇β) # overwriting ∇β with x'y - x'x β\n",
    "        \n",
    "        # term 2 xtzL(AA')^{-1}L'(zty - ztxβ) \n",
    "        \n",
    "        BLAS.trsv!('U', 'N', 'N', obs.storage_qq, obs.storage_q) \n",
    "        # cholesky extracted for M was upper \n",
    "        # this gets us A^{-1} L'(zty - ztxβ)\n",
    "        \n",
    "        BLAS.trmv!('L', 'N', 'N', L, obs.storage_q)\n",
    "        # this gets us (A')^{-1}A^{-1} L'(zty - ztxβ)\n",
    "        \n",
    "        # combine the two terms\n",
    "        \n",
    "        BLAS.gemv!('N', AbstractFloat(-1)/σ², obs.xtz, obs.storage_q, AbstractFloat(1)/σ², obs.∇β)\n",
    "        # subtracting terms 1 and 2 and dividing by σ²\n",
    "        \n",
    "        ####### gradient wrt σ² #######\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    end    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15825b5-c463-4c8c-8eb8-87abc926f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Σ)).L)\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777ba63-b362-45f9-88f8-06361b8fb3d8",
   "metadata": {},
   "source": [
    "### **2.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d657160-b55a-4738-add2-67e506d0c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, β, L, σ², true) = -3256.179335805826\n",
      "obs.∇β = [0.2669810805714521, 41.61418337067322, -34.34664962312688, 36.108985107075306, 27.913948208793148]\n",
      "obs.∇σ² = [2.5353974416e-314]\n",
      "obs.∇Σ = [2.5271783236e-314 2.1792481733e-314 2.5271792643e-314; 2.5271783315e-314 2.1792489955e-314 2.2828103643e-314; 2.179249786e-314 2.2828103643e-314 2.2828103643e-314]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, β, L, σ², true)\n",
    "@show obs.∇β\n",
    "@show obs.∇σ²\n",
    "@show obs.∇Σ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0a4d65-aa80-4a6c-b86c-dd0b8deffa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.∇β - [0.26698108057144054, 41.61418337067327, \n",
    "        -34.34664962312689, 36.10898510707527, 27.913948208793144]) < 1e-4\n",
    "# @assert norm(obs.∇Σ - \n",
    "#     [-0.9464482950697888 0.057792444809492895 -0.30244127639188767; \n",
    "#         0.057792444809492895 -1.00087164917123 0.2845116557144694; \n",
    "#         -0.30244127639188767 0.2845116557144694 1.170040927259726]) < 1e-4\n",
    "#@assert abs(obs.∇σ²[1] - (1.6283715138412163)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f94e45-6075-485c-af3f-544978f96ce5",
   "metadata": {},
   "source": [
    "### **2.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97442590-ddad-41b2-9765-7d2d5735701a",
   "metadata": {},
   "source": [
    "Benchmark for evaluating the objective function only. This is what we did in HW3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7959d9a7-a246-440f-b9a6-e1714b743028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 74 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m806.419 ns\u001b[22m\u001b[39m … \u001b[35m  3.819 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m836.858 ns               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m974.620 ns\u001b[22m\u001b[39m ± \u001b[32m267.583 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▅\u001b[32m▃\u001b[39m\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  806 ns\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m          2 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logl!($obs, $β, $L, $σ², false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fba19-bfb4-4a29-b373-8797a74d17c4",
   "metadata": {},
   "source": [
    "Benchmark for objective + gradient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6ca82392-3cf8-49c8-bf80-e426509cb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 10 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.177 μs\u001b[22m\u001b[39m … \u001b[35m 14.162 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.229 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.464 μs\u001b[22m\u001b[39m ± \u001b[32m569.190 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[32m▃\u001b[39m\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m▃\u001b[39m \u001b[39m▃\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m▃\u001b[39m \u001b[39m█\n",
       "  1.18 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      3.78 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_objgrad = @benchmark logl!($obs, $β, $L, $σ², true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f4409300-7dc0-44a5-bed4-f72607944eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The points you will get are\n",
    "clamp(10 / (median(bm_objgrad).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67011b5e-6dd4-45d3-8cdb-2a2f62e1d08e",
   "metadata": {},
   "source": [
    "# **Testing my Code Line by Line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58ac044a-b5e5-484c-b72b-f13b80bc5b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  45.1902    4.72605   4.40943\n",
       " 213.571    44.2074    2.32431\n",
       " 199.263   123.591    44.1539"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
