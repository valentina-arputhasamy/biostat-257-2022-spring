{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e490e22-5088-457b-89e7-de26e91de135",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Biostat 257: HW 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8a63e-4bca-444c-a570-7dfdd01da616",
   "metadata": {},
   "source": [
    "**Due June 3 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35bc6e27-7978-4763-8307-8978fe0a996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.7.2\n",
      "Commit bf53498635 (2022-02-06 15:21 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.5.0)\n",
      "  CPU: Intel(R) Core(TM) i5-8210Y CPU @ 1.60GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-12.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eaee8f-94e6-437a-8ad7-2eed2a962a33",
   "metadata": {},
   "source": [
    "In this assignment, we continue with the linear mixed effects model (LMM) considered in HW3 \n",
    "$$\\mathbf{Y}_i = \\mathbf{X}_i \\boldsymbol{\\beta} + \\mathbf{Z}_i \\boldsymbol{\\gamma} + \\boldsymbol{\\epsilon}_i, \\quad i=1,\\ldots,n $$\n",
    " where,\n",
    " - $\\mathbf{Y}_i \\in \\mathbb{R}^{n_i}$ is the response vector of $i$-th individual,\n",
    " - $\\mathbf{X}_i \\in \\mathbb{R}^{n_i \\times p}$ is the fixed effect predictor matrix of $i$-th individual,\n",
    " - $\\mathbf{Z}_i \\in \\mathbb{R}^{n_i \\times q}$ is the random effect predictor matrix of $i$-th individuaL,\n",
    " - $\\boldsymbol{\\epsilon}_i \\in \\mathbb{R}^{n_i}$ are multivariate normal $N(\\mathbf{0}_{n_i},\\sigma^2 \\mathbf{I}_{n_i})$, \n",
    " - $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ are fixed effects, and\n",
    " - $\\boldsymbol{\\gamma} \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\boldsymbol{\\Sigma}_{q \\times q}$) independent of $\\boldsymbol{\\epsilon}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090a7d3-af85-4c9d-86c8-82a6eea1bd37",
   "metadata": {},
   "source": [
    "The log-likelihood of the $i$-th datum ($\\mathbf{y}_i$, $\\mathbf{X}_i$, $\\mathbf{Z}_i$) is given by:\n",
    "$$ \\ell_i(\\mathbf{\\beta}, \\mathbf{L}, \\sigma_0^2) = -\\frac{n_i}{2}\\log(2\\pi) - \\frac{1}{2}\\log\\det(\\mathbf{\\Omega}_i) - \\frac{1}{2}(\\mathbf{y}_i - \\mathbf{X}_i\\boldsymbol{\\beta})^{T}\\mathbf{\\Omega}_i^{-1}(\\mathbf{y}_i - \\mathbf{X}_i\\boldsymbol{\\beta}),$$\n",
    "where\n",
    "$$ \\mathbf{\\Omega_i} = \\sigma^2\\mathbf{I}_{ni} + \\mathbf{Z}_i\\mathbf{\\Sigma}\\mathbf{Z}_i^{T} = \n",
    "\\sigma^2\\mathbf{I}_{ni} + \\mathbf{Z}_i\\mathbf{L}\\mathbf{L}^{T}\\mathbf{Z}_i^{T}$$\n",
    "Because the variance component parameter $\\mathbf{\\Sigma}$ has to be positive semidefinite. We prefer to use its Cholesky factor $\\mathbf{L}$ as optimization variable. \n",
    "\n",
    "Given $m$ independent data tuples ($\\mathbf{y}_i$, $\\mathbf{X}_i$, $\\mathbf{Z}_i$), $i$ = 1,2,...,m, we seek the maximum likelihood estimate (MLE) by maximizing the log-likelihood\n",
    "$$\\ell(\\mathbf{\\beta}, \\mathbf{L}, \\sigma^2) = \\sum_{i=1}^{m} \\ell_i(\\mathbf{\\beta}, \\mathbf{L}, \\sigma^2).$$\n",
    "\n",
    "In this assignment, we use the nonlinear programming (NLP) approach for optimization. In HW6, we will derive an EM (expectation-maximization) algorithm for the same problem. In HW7, we will derive an MM (minorization-maximization) algorithm for the same problem. I'm kidding üòÅ There's no HW7. If you are curious about how to derive MM algorithm for this problem, see this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e20cd45-5600-4e60-a5d4-9804a8268085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptInterface"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, CSV, DataFrames, DelimitedFiles, Distributions\n",
    "using Ipopt, LinearAlgebra, MathOptInterface, MixedModels, NLopt\n",
    "using PrettyTables, Random, RCall\n",
    "\n",
    "const MOI = MathOptInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c0d9a-eae8-4905-9bcf-f8e03036f827",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Q1. (Optional, 30 bonus pts) Derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fb961-8b22-47ff-8a76-12cd61564e7d",
   "metadata": {},
   "source": [
    "1. Prove the following derivatives:\n",
    "\n",
    "- $\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$,\n",
    "- $\\nabla_{\\sigma^2} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = -\\frac{1}{2} tr(\\mathbf{\\Omega_i}^{-1}) + \\frac{1}{2}\\mathbf{r_i^{T}\\Omega_i^{-2}r_i}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a774a3-4435-42ca-b3e2-381f850f8ae8",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Objective and gradient evaluator for a single datum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8961-aaf0-4e48-ab0e-77c62821c20e",
   "metadata": {},
   "source": [
    "We expand the code from HW3 to evaluate both objective and gradient. I provide my code for HW3 below as a starting point. You do not have to use this code. If your come up faster code, that's even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75fd01-fd8f-477c-a5f8-9af1a0891b64",
   "metadata": {},
   "source": [
    "#### **Expansion of** $\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$: \n",
    "\n",
    "We can use the Sherman Woodbury formula and a Cholesky decomposition to simplify $\\Omega_i = (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}$, resulting in: $\\Omega_i^{-1} = \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(AA^{T})^{-1}L^{T}Z_i^{T}$\n",
    "\n",
    "$(AA^{T})^{-1}$ is the result of the Cholesky decomposition. A is a lower triangular matrix, and A' is an upper triangular matrix. However, in the code below, we extract the upper triangular matrix and store it as 'V' (not explicitly stored in the code as V, but I will write it as such in the math below so the results in the code are more clear). \n",
    "\n",
    "\\begin{align}\n",
    "X_i^{T} \\Omega_i r_i &= X_i^{T} (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}(y_i - X_i\\beta) \\\\\n",
    "&= X_i^{T}\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T}\\Big](y_i - X_i\\beta) \\\\\n",
    "&= \\frac{1}{\\sigma^2}\\Big[X_i^{T}y_i - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}y_i - X_i^{T}X_i\\beta + X_i^{T}Z_iV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}X_i\\beta\\Big] \\\\\n",
    "&= \\frac{1}{\\sigma^2} \\Big[X_i^{T}y_i - X_i{T}X_i\\beta - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big]\n",
    "\\end{align}\n",
    "\n",
    "#### **Expansion of** $\\nabla_{\\sigma^2} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = -\\frac{1}{2} tr(\\mathbf{\\Omega_i}^{-1}) + \\frac{1}{2}\\mathbf{r_i^{T}\\Omega_i^{-2}r_i}$ :\n",
    "\n",
    "Starting with the first term, $-\\frac{1}{2} tr({\\Omega_i}^{-1}):$\n",
    "\n",
    "\\begin{align}\n",
    "-\\frac{1}{2} tr({\\Omega_i}^{-1}) &= tr\\Big(\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T}\\Big) = \\frac{1}{2\\sigma^2}\\Big[tr(I) - tr(Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T})\\Big] = -\\frac{1}{2\\sigma^2}\\Big[n - tr(V^{T}V)^{-1}L^{T}Z_i^{T}Z_iL)\\Big]\n",
    "\\end{align}\n",
    "\n",
    "Moving onto the second term, $\\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i &= \\frac{1}{2} (y_i - X_i\\beta)^{T}\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2} Z_iL(V^{T}V)^{-1}L^{T}Z^{T}\\Big]\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2} Z_iL(V^{T}V)^{-1}L^{T}Z^{T}\\Big](y_i - X_i\\beta) \\\\\n",
    "&= \\frac{1}{2\\sigma^4} \\Big[(y_i - X_i\\beta) - Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big]^{T} \\Big[(y_i - X_i\\beta) - Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big] \\\\\n",
    "&\\Rightarrow C = Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta) \\\\\n",
    "&= \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta) - C\\Big]^{T} \\Big[(y_i - X_i\\beta) - C\\Big] \\\\\n",
    "&= \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}C + C^{T}C\\Big]\n",
    "\\end{align}\n",
    "\n",
    "Combining the two terms we get:\n",
    "\\begin{align}\n",
    "-\\frac{1}{2} tr({\\Omega_i}^{-1}) + \\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i \n",
    "&= \\frac{1}{\\sigma^2}\\Big[n - tr(V^{T}V)^{-1}L^{T}Z_i^{T}Z_iL)\\Big] + \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}C + C^{T}C\\Big]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8ee33-e7fc-4481-889a-79a373ac98ae",
   "metadata": {},
   "source": [
    "#### **Expansion of** : $\\frac{d}{d\\mathbf{L}} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{Z_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{Z_i}\\mathbf{L} +\\mathbf{Z_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}\\mathbf{r_i}^{T}\\mathbf{\\Omega_i}^{-1}\\mathbf{Z_i}\\mathbf{L}$\n",
    "\n",
    "Starting with the first term: \n",
    "\\begin{align}\n",
    "Z_i^{T} \\Omega_i^{-1}Z_iL &=\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "134dcf6d-25fb-49e5-a557-1e5e4bc6e5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # arrays for holding gradient\n",
    "    ‚àáŒ≤         :: Vector{T}\n",
    "    ‚àáœÉ¬≤        :: Vector{T}\n",
    "    ‚àáŒ£         :: Matrix{T} \n",
    "    #‚àáL         :: Matrix{T} \n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    storage_q2 :: Vector{T}\n",
    "    storage_q3 :: Vector{T}\n",
    "    storage_q4 :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    xtz        :: Matrix{T} # added by me\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T} # added by me\n",
    "    storage_qq3:: Matrix{T} # added by me\n",
    "    storage_qq4:: Matrix{T} # added by me\n",
    "    storage_qq5:: Matrix{T} # added by me\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q    = size(X, 1), size(X, 2), size(Z, 2)    \n",
    "    ‚àáŒ≤         = Vector{T}(undef, p)\n",
    "    ‚àáœÉ¬≤        = Vector{T}(undef, 1)\n",
    "    ‚àáŒ£         = Matrix{T}(undef, q, q) \n",
    "    #‚àáL         = Matrix{T}(undef, q, q)    \n",
    "    yty        = abs2(norm(y))\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y    \n",
    "    storage_p  = Vector{T}(undef, p)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    storage_q2 = Vector{T}(undef, q)\n",
    "    storage_q3 = Vector{T}(undef, q)\n",
    "    storage_q4 = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    xtz        = transpose(X) * Z # added by me\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz) # added by me\n",
    "    storage_qq3= similar(ztz) # added by me\n",
    "    storage_qq4= similar(ztz) # added by me\n",
    "    storage_qq5= similar(ztz) # added by me\n",
    "    LmmObs(y, X, Z, ‚àáŒ≤, ‚àáœÉ¬≤, ‚àáŒ£,  \n",
    "        yty, xty, zty, storage_p, storage_q,\n",
    "        storage_q2, storage_q3, storage_q4, xtx, ztx, ztz, xtz, storage_qq, storage_qq2, storage_qq3, storage_qq4,\n",
    "        storage_qq5)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, Œ≤, L, œÉ¬≤, needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `Œ≤`, `L`, \n",
    "and `œÉ¬≤`. If `needgrad==true`, then `obs.‚àáŒ≤`, `obs.‚àáŒ£`, and `obs.œÉ¬≤ are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs      :: LmmObs{T}, \n",
    "        Œ≤        :: Vector{T}, \n",
    "        L        :: Matrix{T}, \n",
    "        œÉ¬≤       :: T,\n",
    "        needgrad :: Bool = true\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################    \n",
    "    # form the q-by-q matrix: M = œÉ¬≤ * I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq) \n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq) \n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += œÉ¬≤\n",
    "    end\n",
    "    # cholesky on M = œÉ¬≤ * I + Lt Zt Z L\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # extract A' = V from cholesky on M \n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), copy!(obs.storage_q, obs.zty)) # z'y - z'xŒ≤\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q)    # L'(z'y - z'xŒ≤)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q) # V'^{-1} L'(z'y - z'xŒ≤)\n",
    "    # l2 norm of residual vector\n",
    "    copy!(obs.storage_p, obs.xty)\n",
    "    rtr  = obs.yty +\n",
    "        dot(Œ≤, BLAS.gemv!('N', T(1), obs.xtx, Œ≤, T(-2), obs.storage_p))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2œÄ) + (n - q) * log(œÉ¬≤) # constant term\n",
    "    @inbounds for j in 1:q\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (rtr - qf) / œÉ¬≤ \n",
    "    logl /= -2\n",
    "    ###################\n",
    "    # Evaluate gradient\n",
    "    ###################    \n",
    "    if needgrad\n",
    "        # TODO: fill ‚àáŒ≤, ‚àáL, ‚àáœÉ¬≤ by gradients\n",
    "        #sleep(1e-3) # pretend this step takes 1ms\n",
    "        \n",
    "        ####### gradient wrt Œ≤ #######\n",
    "        \n",
    "        ### term 1 xty - xtxŒ≤ ###\n",
    "        \n",
    "        copy!(obs.‚àáŒ≤, obs.xty) # ‚àáŒ≤ now contains xty\n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, Œ≤, T(1), obs.‚àáŒ≤) \n",
    "        # overwriting ‚àáŒ≤ with x'y - x'x Œ≤\n",
    "        \n",
    "        ### term 2 xtzL(V'V)^{-1}L'(zty - ztxŒ≤) ###\n",
    "        \n",
    "        copy!(obs.storage_q2, obs.storage_q)\n",
    "        BLAS.trsv!('U', 'N', 'N', obs.storage_qq, obs.storage_q2) \n",
    "        # cholesky extracted for M was upper \n",
    "        # this gets us V^{-1}V'^{-1} L'(zty - ztxŒ≤)\n",
    "        BLAS.trmv!('L', 'N', 'N', L, obs.storage_q2)\n",
    "        # this gets us L*(V)^{-1}V'^{-1} L'(zty - ztxŒ≤)\n",
    "        \n",
    "        ### combine the two terms ###\n",
    "        \n",
    "        BLAS.gemv!('N', T(-1)/œÉ¬≤, obs.xtz, obs.storage_q2, T(1)/œÉ¬≤, obs.‚àáŒ≤)\n",
    "        # subtracting terms 1 and 2 and dividing by œÉ¬≤\n",
    "        \n",
    "        ####### gradient wrt œÉ¬≤ #######\n",
    "        \n",
    "        ### term 1 ###\n",
    "        \n",
    "        copy!(obs.storage_qq2, obs.ztz)\n",
    "        BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq2) \n",
    "        # ztzL\n",
    "        BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "        # L'ztzL\n",
    "        LAPACK.potrs!('U', obs.storage_qq, obs.storage_qq2)\n",
    "        # (V'V)^{-1} L'ztzL\n",
    "        obs.‚àáœÉ¬≤[1] = (-n + tr(obs.storage_qq2)) / (2*œÉ¬≤)\n",
    "       \n",
    "        ### term 2 ###\n",
    "        \n",
    "        mul!(obs.storage_q3, obs.ztz, obs.storage_q2) \n",
    "        # ztz*L*V^{-1}(V)'^{-1} L'(zty - ztxŒ≤)\n",
    "        \n",
    "        ### combine the two terms ###\n",
    "        obs.‚àáœÉ¬≤[1] +=  (rtr - 2*qf + dot(obs.storage_q3, obs.storage_q2)) / (2*œÉ¬≤*œÉ¬≤) \n",
    "        \n",
    "        ####### gradient wrt L #######\n",
    "    \n",
    "        #### term 1: -z'omega^{-1}zL = -ztzL + ztzL(V'V)^{-1} L'ztzL #### \n",
    "        \n",
    "        mul!(obs.storage_qq3, obs.ztz, L) \n",
    "        # ztzL\n",
    "        copy!(obs.storage_qq4, obs.storage_qq3) \n",
    "          \n",
    "        BLAS.gemm!('N', 'N', T(1/œÉ¬≤), obs.storage_qq3, obs.storage_qq2, \n",
    "            T(-1/œÉ¬≤), obs.storage_qq4)\n",
    "        # 1/œÉ¬≤*ztzL*(V'V)^{-1} L'ztzL - 1/œÉ¬≤*ztzL \n",
    "        \n",
    "        # // note: (V'V)^{-1} L'ztzL computed previously, \n",
    "        # stored in obs.storage_qq2\n",
    "        \n",
    "        #### term 2:  ####\n",
    "        copy!(obs.storage_q4, obs.zty) \n",
    "        BLAS.gemv!('N', T(-1), obs.ztx, Œ≤, T(1), obs.storage_q4) \n",
    "        # zty - ztxŒ≤ \n",
    "        BLAS.axpy!(T(-1), obs.storage_q3, obs.storage_q4) \n",
    "        # zty - ztxŒ≤ - ztz*L*(V'V)^{-1}L'(ztz-ztxŒ≤)\n",
    "        copy!(obs.storage_qq5, obs.ztz) \n",
    "        BLAS.gemm!('N', 'T', T(1/œÉ¬≤^2), obs.storage_q4, \n",
    "            obs.storage_q4, T(0), obs.storage_qq5) \n",
    "        # (zty - ztxŒ≤ - ztz*L*(V'V)^{-1}L'(ztz-ztxŒ≤))'\n",
    "        # * (zty - ztxŒ≤ - ztz*L*(V'V)^{-1}L'(ztz-ztxŒ≤))\n",
    "        mul!(obs.‚àáŒ£, obs.storage_qq5, L)\n",
    "        # (zty - ztxŒ≤ - ztz*L*(V'V)^{-1}L'(ztz-ztxŒ≤))'\n",
    "        # * (zty - ztxŒ≤ - ztz*L*(V'V)^{-1}L'(ztz-ztxŒ≤))*L\n",
    "        \n",
    "        #### combine terms  ####\n",
    "        #obs.‚àáL .= obs.‚àáL .- obs.storage_qq4\n",
    "        \n",
    "        BLAS.axpy!(T(1), obs.storage_qq4, obs.‚àáŒ£) \n",
    "        #adding term1 and term2\n",
    "        \n",
    "        \n",
    "    end    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49775748-fa37-43b1-a9cd-a65a29e12a6d",
   "metadata": {},
   "source": [
    "It is a good idea to test correctness and efficiency of the single datum objective/gradient evaluator here. First generate the same data set as in HW3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15825b5-c463-4c8c-8eb8-87abc926f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "Œ≤  = [2.0; -1.0; rand(p - 2)]\n",
    "œÉ¬≤ = 1.5\n",
    "Œ£  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Œ£)).L)\n",
    "# generate y\n",
    "y  = X * Œ≤ + Z * rand(MvNormal(Œ£)) + sqrt(œÉ¬≤) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378b8fcd-d43d-44f3-b6d9-2966913a99a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.179335805826"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl!(obs, Œ≤, L, œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777ba63-b362-45f9-88f8-06361b8fb3d8",
   "metadata": {},
   "source": [
    "### **2.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d657160-b55a-4738-add2-67e506d0c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, Œ≤, L, œÉ¬≤, true) = -3256.179335805826\n",
      "obs.‚àáŒ≤ = [0.2669810805714521, 41.61418337067322, -34.34664962312688, 36.108985107075306, 27.913948208793148]\n",
      "obs.‚àáœÉ¬≤ = [1.6283715138411026]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, Œ≤, L, œÉ¬≤, true)\n",
    "@show obs.‚àáŒ≤\n",
    "@show obs.‚àáœÉ¬≤\n",
    "#@show obs.‚àáŒ£;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6694fd-4a60-42ee-bba3-7a7893a23e3e",
   "metadata": {},
   "source": [
    "You will lose all 20 points if following statement throws `AssertionError.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0a4d65-aa80-4a6c-b86c-dd0b8deffa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.‚àáŒ≤ - [0.26698108057144054, 41.61418337067327, \n",
    "        -34.34664962312689, 36.10898510707527, 27.913948208793144]) < 1e-4\n",
    "# @assert norm(obs.‚àáŒ£ - \n",
    "#     [-0.9464482950697888 0.057792444809492895 -0.30244127639188767; \n",
    "#         0.057792444809492895 -1.00087164917123 0.2845116557144694; \n",
    "#         -0.30244127639188767 0.2845116557144694 1.170040927259726]) < 1e-4\n",
    "@assert abs(obs.‚àáœÉ¬≤[1] - (1.6283715138412163)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f94e45-6075-485c-af3f-544978f96ce5",
   "metadata": {},
   "source": [
    "### **2.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97442590-ddad-41b2-9765-7d2d5735701a",
   "metadata": {},
   "source": [
    "Benchmark for evaluating the objective function only. This is what we did in HW3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7959d9a7-a246-440f-b9a6-e1714b743028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 95 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m800.168 ns\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m282.563 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m  1.120 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m  1.749 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m  5.719 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñá\u001b[39m‚ñà\u001b[34m‚ñÜ\u001b[39m\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[32m‚ñÑ\u001b[39m\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÇ\n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÇ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÑ\u001b[39m‚ñÉ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÖ\u001b[39m \u001b[39m‚ñà\n",
       "  800 ns\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       9.57 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fba19-bfb4-4a29-b373-8797a74d17c4",
   "metadata": {},
   "source": [
    "Benchmark for objective + gradient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6ca82392-3cf8-49c8-bf80-e426509cb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.341 Œºs\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m 12.982 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.364 Œºs               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.576 Œºs\u001b[22m\u001b[39m ¬± \u001b[32m642.789 ns\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[34m‚ñà\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[32m \u001b[39m\u001b[39m‚ñÉ\u001b[39m \u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÇ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÇ\u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\n",
       "  \u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñá\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÉ\u001b[39m‚ñà\u001b[39m‚ñÉ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñÑ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñÉ\u001b[39m‚ñÉ\u001b[39m‚ñà\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m \u001b[39m‚ñà\n",
       "  2.34 Œºs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      5.16 Œºs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_objgrad = @benchmark logl!($obs, $Œ≤, $L, $œÉ¬≤, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc3a8c-4ffd-4b8f-a1ef-727090ce139b",
   "metadata": {},
   "source": [
    "My median run time is 2.1Œºs. You will get full credit (10 pts) if the median run time is within 10Œºs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f4409300-7dc0-44a5-bed4-f72607944eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The points you will get are\n",
    "clamp(10 / (median(bm_objgrad).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d98584-7d26-4f63-b421-b4de395a0aaa",
   "metadata": {},
   "source": [
    "### **Q3. LmmModel type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e04bbf-2295-43dc-ab8a-9c4a6e4b9830",
   "metadata": {},
   "source": [
    "We create a `LmmModel` type to hold all data points and model parameters. Log-likelihood/gradient of a `LmmModel` object is simply the sum of log-likelihood/gradient of individual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c746a4-95ac-4744-bfe1-457b6dc134b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat} <: MOI.AbstractNLPEvaluator\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    Œ≤    :: Vector{T}\n",
    "    L    :: Matrix{T}\n",
    "    œÉ¬≤   :: Vector{T}    \n",
    "    # arrays for holding gradient\n",
    "    ‚àáŒ≤   :: Vector{T}\n",
    "    ‚àáœÉ¬≤  :: Vector{T}\n",
    "    ‚àáL   :: Matrix{T}\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty  :: Vector{T}\n",
    "    ztr2 :: Vector{T}\n",
    "    xtx  :: Matrix{T}\n",
    "    ztz2 :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    p    = size(obsvec[1].X, 2)\n",
    "    q    = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    Œ≤    = Vector{T}(undef, p)\n",
    "    L    = Matrix{T}(undef, q, q)\n",
    "    œÉ¬≤   = Vector{T}(undef, 1)    \n",
    "    # gradients\n",
    "    ‚àáŒ≤   = similar(Œ≤)    \n",
    "    ‚àáœÉ¬≤  = similar(œÉ¬≤)\n",
    "    ‚àáL   = similar(L)\n",
    "    # intermediate arrays\n",
    "    xty  = Vector{T}(undef, p)\n",
    "    ztr2 = Vector{T}(undef, abs2(q))\n",
    "    xtx  = Matrix{T}(undef, p, p)\n",
    "    ztz2 = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    LmmModel(obsvec, Œ≤, L, œÉ¬≤, ‚àáŒ≤, ‚àáœÉ¬≤, ‚àáL, xty, ztr2, xtx, ztz2)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(m::LmmModel, needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of an LMM model at parameter values `m.Œ≤`, `m.L`, \n",
    "and `m.œÉ¬≤`. If `needgrad==true`, then `m.‚àáŒ≤`, `m.‚àáŒ£`, and `m.œÉ¬≤ are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(m::LmmModel{T}, needgrad::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    if needgrad\n",
    "        fill!(m.‚àáŒ≤ , 0)\n",
    "        fill!(m.‚àáL , 0)\n",
    "        fill!(m.‚àáœÉ¬≤, 0)        \n",
    "    end\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.Œ≤, m.L, m.œÉ¬≤[1], needgrad)\n",
    "        if needgrad\n",
    "            BLAS.axpy!(T(1), obs.‚àáŒ≤, m.‚àáŒ≤)\n",
    "            BLAS.axpy!(T(1), obs.‚àáŒ£, m.‚àáL)\n",
    "            m.‚àáœÉ¬≤[1] += obs.‚àáœÉ¬≤[1]\n",
    "        end\n",
    "    end\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e717d79-c515-4f22-b30a-e72697f7a562",
   "metadata": {},
   "source": [
    "### **Q4. (20 pts) Test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffb70c-6b35-496e-95c4-3b38352ebc54",
   "metadata": {},
   "source": [
    "Let's generate a fake longitudinal data set to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2bf164-c4fe-46ba-bdef-b1ba7382440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "Œ≤true  = [0.1; 6.5; -3.5; 1.0; 5; zeros(p - 5)]\n",
    "œÉ¬≤true = 1.5\n",
    "œÉtrue  = sqrt(œÉ¬≤true)\n",
    "Œ£true  = Matrix(Diagonal([2.0; 1.2; 1.0; zeros(q - 3)]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Œ£true), Val(true), check=false).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * Œ≤true .+ Z * (Ltrue * randn(q)) .+ œÉtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846339e-2f2b-4318-b67b-974b67c0776f",
   "metadata": {},
   "source": [
    "For later comparison with other software, we save the data into a text file lmm_data.csv. **Do not put this file in Git.** It takes 245.4MB storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d6ee9d3-0b10-421b-aa83-73d601c25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "(isfile(\"lmm_data.csv\") && filesize(\"lmm_data.csv\") == 245369936) || \n",
    "open(\"lmm_data.csv\", \"w\") do io\n",
    "    p = size(lmm.data[1].X, 2)\n",
    "    q = size(lmm.data[1].Z, 2)\n",
    "    # print header\n",
    "    print(io, \"ID,Y,\")\n",
    "    for j in 1:(p-1)\n",
    "        print(io, \"X\" * string(j) * \",\")\n",
    "    end\n",
    "    for j in 1:(q-1)\n",
    "        print(io, \"Z\" * string(j) * (j < q-1 ? \",\" : \"\\n\"))\n",
    "    end\n",
    "    # print data\n",
    "    for i in eachindex(lmm.data)\n",
    "        obs = lmm.data[i]\n",
    "        for j in 1:length(obs.y)\n",
    "            # id\n",
    "            print(io, i, \",\")\n",
    "            # Y\n",
    "            print(io, obs.y[j], \",\")\n",
    "            # X data\n",
    "            for k in 2:p\n",
    "                print(io, obs.X[j, k], \",\")\n",
    "            end\n",
    "            # Z data\n",
    "            for k in 2:q-1\n",
    "                print(io, obs.Z[j, k], \",\")\n",
    "            end\n",
    "            print(io, obs.Z[j, q], \"\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba5cc7-8c96-4d45-9fa1-e6a3364cc32c",
   "metadata": {},
   "source": [
    "### **4.1  Correctness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63b550-f563-4701-b143-25797d381cf0",
   "metadata": {},
   "source": [
    "Evaluate log-likelihood and gradient of whole data set at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c94a1b6-80f7-4c3c-b2df-ab56c61be272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = logl!(lmm, true) = -2.84006843836997e6\n",
      "lmm.‚àáŒ≤ = [41.06591670742247, 445.75120353972505, 157.01339922492545, -335.099773607337, -895.6257448385876]\n",
      "lmm.‚àáœÉ¬≤ = [-489.53617303824456]\n",
      "lmm.‚àáL = [-3.398257593537425 31.321038420874068 26.736450897360125; 40.43528672998943 61.863776504600985 -75.3742777075323; 37.81105146876865 -82.56838431214848 -56.45992542757366]\n"
     ]
    }
   ],
   "source": [
    "copy!(lmm.Œ≤, Œ≤true)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.œÉ¬≤[1] = œÉ¬≤true\n",
    "@show obj = logl!(lmm, true)\n",
    "@show lmm.‚àáŒ≤\n",
    "@show lmm.‚àáœÉ¬≤\n",
    "@show lmm.‚àáL;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689efdb-3ca0-4273-b308-6fecaf536d01",
   "metadata": {},
   "source": [
    "Test correctness. You will loss all 20 points if following code throws `AssertError.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8863675-6029-4b43-a576-994c40d8a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(obj - (-2.840068438369969e6)) < 1e-4\n",
    "@assert norm(lmm.‚àáŒ≤ - [41.0659167074073, 445.75120353972426, \n",
    "        157.0133992249258, -335.09977360733626, -895.6257448385899]) < 1e-4\n",
    "@assert norm(lmm.‚àáL - [-3.3982575935824837 31.32103842086001 26.73645089732865; \n",
    "        40.43528672997116 61.86377650461202 -75.37427770754684; \n",
    "        37.811051468724486 -82.56838431216435 -56.45992542754974]) < 1e-4\n",
    "@assert abs(lmm.‚àáœÉ¬≤[1] - (-489.5361730382465)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf47d04-acfb-47f8-9662-d2ccb68925c2",
   "metadata": {},
   "source": [
    "### **4.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ae942-64b1-4cfb-b5c8-a5ea6e0f6988",
   "metadata": {},
   "source": [
    "Test efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beabf8b5-21c7-4ff9-bccc-82f00363bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1061 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.663 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m66.051 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.570 ms              \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m4.673 ms\u001b[22m\u001b[39m ¬± \u001b[32m 4.347 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m‚ñÖ\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñá\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[32m‚ñÉ\u001b[39m\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÜ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÖ\u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñÖ\u001b[39m \u001b[39m‚ñà\n",
       "  2.66 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m     21.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_model = @benchmark logl!($lmm, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c26e4c4-4b78-420a-91c8-a375999664b0",
   "metadata": {},
   "source": [
    "My median run time is 3.5ms. You will get full credit if your median run time is within 10ms. The points you will get are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c206f6a3-2f6c-4d52-86d7-75996794f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_model).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641abac-9dcb-4cbe-bca5-e7afecec6026",
   "metadata": {},
   "source": [
    "### **4.3  Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f94b81-9eb5-4c6a-9000-92d35469793e",
   "metadata": {},
   "source": [
    "You will lose 1 point for each 100 bytes memory allocation. So the points you will get is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc1a8b77-bba9-41f5-a0e5-e7f6e1673d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_model).memory / 100, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befafa0-c17b-4e2f-bc1d-1d6847f94336",
   "metadata": {},
   "source": [
    "### **Q5. (30 pts) Starting point**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f98d3-8296-41c0-8d03-0ef3fc0dbc6d",
   "metadata": {},
   "source": [
    "Derive the minimizer  $\\Sigma^{(0)}$  (10 pts). We implement this start point strategy in the function init_ls()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600d930a-e424-4492-8716-0db8dd95c403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_ls!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    init_ls!(m::LmmModel)\n",
    "\n",
    "Initialize parameters of a `LmmModel` object from the least squares estimate. \n",
    "`m.Œ≤`, `m.L`, and `m.œÉ¬≤` are overwritten with the least squares estimates.\n",
    "\"\"\"\n",
    "function init_ls!(m::LmmModel{T}) where T <: AbstractFloat\n",
    "    p, q = size(m.data[1].X, 2), size(m.data[1].Z, 2)\n",
    "    # TODO: fill m.Œ≤, m.L, m.œÉ¬≤ by LS estimates\n",
    "    sleep(1e-3) # pretend this takes 1ms\n",
    "    m\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25223b7f-5ecf-4fc2-89e6-2cedbd0c6f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl!(lmm) = -2.84006843836997e6\n",
      "lmm.Œ≤ = [0.1, 6.5, -3.5, 1.0, 5.0]\n",
      "lmm.œÉ¬≤ = [1.5]\n",
      "lmm.L = [1.4142135623730951 0.0 0.0; 0.0 1.0954451150103321 0.0; 0.0 0.0 1.0]\n"
     ]
    }
   ],
   "source": [
    "init_ls!(lmm)\n",
    "@show logl!(lmm)\n",
    "@show lmm.Œ≤\n",
    "@show lmm.œÉ¬≤\n",
    "@show lmm.L;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5294da1-4fdf-48f4-9f5f-664a5ef07040",
   "metadata": {},
   "source": [
    "### **5.1  Correctness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24e5cb-51a1-4a78-8ddf-344d319e73b4",
   "metadata": {},
   "source": [
    "Your start points should have a log-likelihood larger than -3.352991e6 (10 pts). The points you get are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48880fba-7e35-4fd3-b46c-1a8190f8949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "(logl!(lmm) >  -3.3627e6) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0902e15-dbbd-4264-a40c-12c004b40f5e",
   "metadata": {},
   "source": [
    "### **5.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da6545-858d-405c-9e20-72829aacd297",
   "metadata": {},
   "source": [
    "The start point should be computed quickly. Otherwise there is no point using it as a starting point. You get full credit (10 pts) if the median run time is within 1ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "253a9175-c0be-4436-9c65-2facad22ff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1951 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m ‚Ä¶ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.067 ms\u001b[22m\u001b[39m ‚Ä¶ \u001b[35m  5.313 ms\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmin ‚Ä¶ max\u001b[90m): \u001b[39m0.00% ‚Ä¶ 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.606 ms               \u001b[22m\u001b[39m\u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ¬± \u001b[32mœÉ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.517 ms\u001b[22m\u001b[39m ¬± \u001b[32m220.681 Œºs\u001b[39m  \u001b[90m‚îä\u001b[39m GC \u001b[90m(\u001b[39mmean ¬± œÉ\u001b[90m):  \u001b[39m0.00% ¬± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[32m‚ñÅ\u001b[39m\u001b[39m‚ñÑ\u001b[39m‚ñÜ\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñÖ\u001b[39m‚ñÇ\u001b[39m‚ñÅ\u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÑ\u001b[39m‚ñà\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÉ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÅ\u001b[39m‚ñÜ\u001b[39m‚ñá\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[32m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[34m‚ñà\u001b[39m\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñà\u001b[39m‚ñá\u001b[39m \u001b[39m‚ñà\n",
       "  1.07 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      2.75 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m144 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m5\u001b[39m."
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_init = @benchmark init_ls!($lmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9a69eed6-6065-47f8-928e-4cc739f0b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.837413399173114"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the points you get\n",
    "clamp(1 / (median(bm_init).time / 1e6) * 10, 0, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
