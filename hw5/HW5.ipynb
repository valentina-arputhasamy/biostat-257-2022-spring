{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e20cd45-5600-4e60-a5d4-9804a8268085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptInterface"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load necessary packages; make sure install them first\n",
    "using BenchmarkTools, CSV, DataFrames, DelimitedFiles, Distributions\n",
    "using Ipopt, LinearAlgebra, MathOptInterface, MixedModels, NLopt\n",
    "using PrettyTables, Random, RCall\n",
    "\n",
    "const MOI = MathOptInterface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c0d9a-eae8-4905-9bcf-f8e03036f827",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Q1. (Optional, 30 bonus pts) Derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fb961-8b22-47ff-8a76-12cd61564e7d",
   "metadata": {},
   "source": [
    "1. Prove the following derivatives:\n",
    "\n",
    "- $\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$,\n",
    "- $\\nabla_{\\sigma^2} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = -\\frac{1}{2} tr(\\mathbf{\\Omega_i}^{-1}) + \\frac{1}{2}\\mathbf{r_i^{T}\\Omega_i^{-2}r_i}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a774a3-4435-42ca-b3e2-381f850f8ae8",
   "metadata": {},
   "source": [
    "### **Q2. (20 pts) Objective and gradient evaluator for a single datum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c8961-aaf0-4e48-ab0e-77c62821c20e",
   "metadata": {},
   "source": [
    "We expand the code from HW3 to evaluate both objective and gradient. I provide my code for HW3 below as a starting point. You do not have to use this code. If your come up faster code, that's even better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75fd01-fd8f-477c-a5f8-9af1a0891b64",
   "metadata": {},
   "source": [
    "#### **Expansion of** $\\nabla_\\boldsymbol{\\beta} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = \\mathbf{X_i}^{T} \\mathbf{\\Omega_i}^{-1}\\mathbf{r_i}$: \n",
    "\n",
    "We can use the Sherman Woodbury formula and a Cholesky decomposition to simplify $\\Omega_i = (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}$, resulting in: $\\Omega_i^{-1} = \\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(AA^{T})^{-1}L^{T}Z_i^{T}$\n",
    "\n",
    "$(AA^{T})^{-1}$ is the result of the Cholesky decomposition. A is a lower triangular matrix, and A' is an upper triangular matrix. However, in the code below, we extract the upper triangular matrix and store it as 'V' (not explicitly stored in the code as V, but I will write it as such in the math below so the results in the code are more clear). \n",
    "\n",
    "\\begin{align}\n",
    "X_i^{T} \\Omega_i r_i &= X_i^{T} (\\sigma^2I + Z_iLL^{T}Z_i^{T})^{-1}(y_i - X_i\\beta) \\\\\n",
    "&= X_i^{T}\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T}\\Big](y_i - X_i\\beta) \\\\\n",
    "&= \\frac{1}{\\sigma^2}\\Big[X_i^{T}y_i - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}y_i - X_i^{T}X_i\\beta + X_i^{T}Z_iV^{-1}(V^{T})^{-1}L^{T}Z_i^{T}X_i\\beta\\Big] \\\\\n",
    "&= \\frac{1}{\\sigma^2} \\Big[X_i^{T}y_i - X_i{T}X_i\\beta - X_i^{T}Z_iLV^{-1}(V^{T})^{-1}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big]\n",
    "\\end{align}\n",
    "\n",
    "#### **Expansion of** $\\nabla_{\\sigma^2} \\ell_i (\\boldsymbol{\\beta}, \\mathbf{L}, \\sigma^2) = -\\frac{1}{2} tr(\\mathbf{\\Omega_i}^{-1}) + \\frac{1}{2}\\mathbf{r_i^{T}\\Omega_i^{-2}r_i}$ :\n",
    "\n",
    "Starting with the first term, $-\\frac{1}{2} tr({\\Omega_i}^{-1}):$\n",
    "\n",
    "\\begin{align}\n",
    "-\\frac{1}{2} tr({\\Omega_i}^{-1}) &= tr\\Big(\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2}Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T}\\Big) = \\frac{1}{2\\sigma^2}\\Big[tr(I) - tr(Z_iL(V^{T}V)^{-1}L^{T}Z_i^{T})\\Big] = -\\frac{1}{2\\sigma^2}\\Big[n - tr(V^{T}V)^{-1}L^{T}Z_i^{T}Z_iL)\\Big]\n",
    "\\end{align}\n",
    "\n",
    "Moving onto the second term, $\\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i &= \\frac{1}{2} (y_i - X_i\\beta)^{T}\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2} Z_iL(V^{T}V)^{-1}L^{T}Z^{T}\\Big]\\Big[\\frac{1}{\\sigma^2}I - \\frac{1}{\\sigma^2} Z_iL(V^{T}V)^{-1}L^{T}Z^{T}\\Big](y_i - X_i\\beta) \\\\\n",
    "&= \\frac{1}{2\\sigma^4} \\Big[(y_i - X_i\\beta) - Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big]^{T} \\Big[(y_i - X_i\\beta) - Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta)\\Big] \\\\\n",
    "&\\Rightarrow C = Z_iL(V^{T}V)^{-1}L^{T}(Z_i^{T}y_i - Z_i^{T}X_i\\beta) \\\\\n",
    "&= \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta) - C\\Big]^{T} \\Big[(y_i - X_i\\beta) - C\\Big] \\\\\n",
    "&= \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}C + C^{T}C\\Big]\n",
    "\\end{align}\n",
    "\n",
    "Combining the two terms we get:\n",
    "\\begin{align}\n",
    "-\\frac{1}{2} tr({\\Omega_i}^{-1}) + \\frac{1}{2}r_i^{T}\\Omega_i^{-2}r_i \n",
    "&= \\frac{1}{\\sigma^2}\\Big[n - tr(V^{T}V)^{-1}L^{T}Z_i^{T}Z_iL)\\Big] + \\frac{1}{2\\sigma^4}\\Big[(y_i - X_i\\beta)^{T}(y_i - X_i\\beta) - 2(y_i - X_i\\beta)^{T}C + C^{T}C\\Big]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "134dcf6d-25fb-49e5-a557-1e5e4bc6e5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds an LMM datum\n",
    "struct LmmObs{T <: AbstractFloat}\n",
    "    # data\n",
    "    y          :: Vector{T}\n",
    "    X          :: Matrix{T}\n",
    "    Z          :: Matrix{T}\n",
    "    # arrays for holding gradient\n",
    "    ∇β         :: Vector{T}\n",
    "    ∇σ²        :: Vector{T}\n",
    "    ∇Σ         :: Matrix{T} \n",
    "    ∇L         :: Matrix{T} \n",
    "    # working arrays\n",
    "    # TODO: whatever intermediate arrays you may want to pre-allocate\n",
    "    yty        :: T\n",
    "    xty        :: Vector{T}\n",
    "    zty        :: Vector{T}\n",
    "    storage_p  :: Vector{T}\n",
    "    storage_q  :: Vector{T}\n",
    "    storage_q2 :: Vector{T}\n",
    "    storage_q3 :: Vector{T}\n",
    "    storage_q4 :: Vector{T}\n",
    "    xtx        :: Matrix{T}\n",
    "    ztx        :: Matrix{T}\n",
    "    ztz        :: Matrix{T}\n",
    "    xtz        :: Matrix{T} # added by me\n",
    "    storage_qq :: Matrix{T}\n",
    "    storage_qq2:: Matrix{T} # added by me\n",
    "    storage_qq3:: Matrix{T} # added by me\n",
    "    storage_qq4:: Matrix{T} # added by me\n",
    "    storage_qq5:: Matrix{T} # added by me\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmObs(y::Vector, X::Matrix, Z::Matrix)\n",
    "\n",
    "Create an LMM datum of type `LmmObs`.\n",
    "\"\"\"\n",
    "function LmmObs(\n",
    "        y::Vector{T}, \n",
    "        X::Matrix{T}, \n",
    "        Z::Matrix{T}\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q    = size(X, 1), size(X, 2), size(Z, 2)    \n",
    "    ∇β         = Vector{T}(undef, p)\n",
    "    ∇σ²        = Vector{T}(undef, 1)\n",
    "    ∇Σ         = Matrix{T}(undef, q, q) \n",
    "    ∇L         = Matrix{T}(undef, q, q)    \n",
    "    yty        = abs2(norm(y))\n",
    "    xty        = transpose(X) * y\n",
    "    zty        = transpose(Z) * y    \n",
    "    storage_p  = Vector{T}(undef, p)\n",
    "    storage_q  = Vector{T}(undef, q)\n",
    "    storage_q2 = Vector{T}(undef, q)\n",
    "    storage_q3 = Vector{T}(undef, q)\n",
    "    storage_q4 = Vector{T}(undef, q)\n",
    "    xtx        = transpose(X) * X\n",
    "    ztx        = transpose(Z) * X\n",
    "    ztz        = transpose(Z) * Z\n",
    "    xtz        = transpose(X) * Z # added by me\n",
    "    storage_qq = similar(ztz)\n",
    "    storage_qq2= similar(ztz) # added by me\n",
    "    storage_qq3= similar(ztz) # added by me\n",
    "    storage_qq4= similar(ztz) # added by me\n",
    "    storage_qq5= similar(ztz) # added by me\n",
    "    LmmObs(y, X, Z, ∇β, ∇σ², ∇Σ, ∇L, \n",
    "        yty, xty, zty, storage_p, storage_q,\n",
    "        storage_q2, storage_q3, storage_q4, xtx, ztx, ztz, xtz, storage_qq, storage_qq2, storage_qq3, storage_qq4,\n",
    "        storage_qq5)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(obs::LmmObs, β, L, σ², needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of a single LMM datum at parameter values `β`, `L`, \n",
    "and `σ²`. If `needgrad==true`, then `obs.∇β`, `obs.∇Σ`, and `obs.σ² are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(\n",
    "        obs      :: LmmObs{T}, \n",
    "        β        :: Vector{T}, \n",
    "        L        :: Matrix{T}, \n",
    "        σ²       :: T,\n",
    "        needgrad :: Bool = true\n",
    "    ) where T <: AbstractFloat\n",
    "    n, p, q = size(obs.X, 1), size(obs.X, 2), size(obs.Z, 2)\n",
    "    ####################\n",
    "    # Evaluate objective\n",
    "    ####################    \n",
    "    # form the q-by-q matrix: M = σ² * I + Lt Zt Z L\n",
    "    copy!(obs.storage_qq, obs.ztz)\n",
    "    BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq) \n",
    "    BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq) \n",
    "    @inbounds for j in 1:q\n",
    "        obs.storage_qq[j, j] += σ²\n",
    "    end\n",
    "    # cholesky on M = σ² * I + Lt Zt Z L\n",
    "    LAPACK.potrf!('U', obs.storage_qq) # extract A' = V from cholesky on M \n",
    "    # storage_q = (Mchol.U') \\ (Lt * (Zt * res))\n",
    "    BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), copy!(obs.storage_q, obs.zty)) # z'y - z'xβ\n",
    "    BLAS.trmv!('L', 'T', 'N', L, obs.storage_q)    # L'(z'y - z'xβ)\n",
    "    BLAS.trsv!('U', 'T', 'N', obs.storage_qq, obs.storage_q) # V'^{-1} L'(z'y - z'xβ)\n",
    "    # l2 norm of residual vector\n",
    "    copy!(obs.storage_p, obs.xty)\n",
    "    rtr  = obs.yty +\n",
    "        dot(β, BLAS.gemv!('N', T(1), obs.xtx, β, T(-2), obs.storage_p))\n",
    "    # assemble pieces\n",
    "    logl::T = n * log(2π) + (n - q) * log(σ²) # constant term\n",
    "    @inbounds for j in 1:q\n",
    "        logl += 2log(obs.storage_qq[j, j])\n",
    "    end\n",
    "    qf    = abs2(norm(obs.storage_q)) # quadratic form term\n",
    "    logl += (rtr - qf) / σ² \n",
    "    logl /= -2\n",
    "    ###################\n",
    "    # Evaluate gradient\n",
    "    ###################    \n",
    "    if needgrad\n",
    "        # TODO: fill ∇β, ∇L, ∇σ² by gradients\n",
    "        #sleep(1e-3) # pretend this step takes 1ms\n",
    "        \n",
    "        ####### gradient wrt β #######\n",
    "        \n",
    "        ### term 1 xty - xtxβ ###\n",
    "        \n",
    "        copy!(obs.∇β, obs.xty) # ∇β now contains xty\n",
    "        BLAS.gemv!('N', T(-1), obs.xtx, β, T(1), obs.∇β) # overwriting ∇β with x'y - x'x β\n",
    "        \n",
    "        ### term 2 xtzL(V'V)^{-1}L'(zty - ztxβ) ###\n",
    "        \n",
    "        copy!(obs.storage_q2, obs.storage_q)\n",
    "        BLAS.trsv!('U', 'N', 'N', obs.storage_qq, obs.storage_q2) \n",
    "        # cholesky extracted for M was upper \n",
    "        # this gets us V^{-1}V'^{-1} L'(zty - ztxβ)\n",
    "        BLAS.trmv!('L', 'N', 'N', L, obs.storage_q2)\n",
    "        # this gets us L*(V)^{-1}V'^{-1} L'(zty - ztxβ)\n",
    "        \n",
    "        ### combine the two terms ###\n",
    "        \n",
    "        BLAS.gemv!('N', T(-1)/σ², obs.xtz, obs.storage_q2, T(1)/σ², obs.∇β)\n",
    "        # subtracting terms 1 and 2 and dividing by σ²\n",
    "        \n",
    "        ####### gradient wrt σ² #######\n",
    "        \n",
    "        ### term 1 ###\n",
    "        \n",
    "        copy!(obs.storage_qq2, obs.ztz)\n",
    "        BLAS.trmm!('R', 'L', 'N', 'N', T(1), L, obs.storage_qq2) \n",
    "        # ztzL\n",
    "        BLAS.trmm!('L', 'L', 'T', 'N', T(1), L, obs.storage_qq2)\n",
    "        # L'ztzL\n",
    "        LAPACK.potrs!('U', obs.storage_qq, obs.storage_qq2)\n",
    "        # (V'V)^{-1} L'ztzL\n",
    "        obs.∇σ²[1] = (-n + tr(obs.storage_qq2)) / (2*σ²)\n",
    "       \n",
    "        ### term 2 ###\n",
    "        \n",
    "        mul!(obs.storage_q3, obs.ztz, obs.storage_q2) \n",
    "        # ztz*L*V^{-1}(V)'^{-1} L'(zty - ztxβ)\n",
    "        \n",
    "        ### combine the two terms ###\n",
    "        obs.∇σ²[1] +=  (rtr - 2*qf + dot(obs.storage_q3, obs.storage_q2)) / (2*σ²*σ²) \n",
    "        \n",
    "        ####### gradient wrt L #######\n",
    "    \n",
    "        #### term 1: -z'omega^{-1}zL = -ztzL + ztzL(V'V)^{-1} L'ztzL #### !!! CORRECT !!! \n",
    "        \n",
    "        mul!(obs.storage_qq3, obs.ztz, L) \n",
    "        # ztzL\n",
    "        copy!(obs.storage_qq4, obs.storage_qq3) \n",
    "        # need to copy bc gemm! won't work properly if A and C are the same\n",
    "        BLAS.gemm!('N', 'N', T(1/σ²), obs.storage_qq3, obs.storage_qq2, T(-1/σ²), obs.storage_qq4)\n",
    "        # 1/σ²*ztzL*(V'V)^{-1} L'ztzL - 1/σ²*ztzL \n",
    "        # // note: (V'V)^{-1} L'ztzL computed previously, stored in obs.storage_qq2\n",
    "        \n",
    "        #### term 2:  ####\n",
    "        copy!(obs.storage_q4, obs.zty) #GOOD\n",
    "        BLAS.gemv!('N', T(-1), obs.ztx, β, T(1), obs.storage_q4) #zty - ztxβ #GOOD\n",
    "        BLAS.axpy!(T(-1), obs.storage_q3, obs.storage_q4)\n",
    "        #zty - ztxβ - ztzL(V'V)^{-1}L'(ztz-ztxβ)\n",
    "        copy!(obs.storage_qq5, obs.ztz) \n",
    "        BLAS.gemm!('N', 'T', T(1/σ²^2), obs.storage_q4, obs.storage_q4, T(0), obs.storage_qq5) #looks good up to here\n",
    "        mul!(obs.∇L, obs.storage_qq5, L)\n",
    "        \n",
    "         #### combine terms  ####\n",
    "        \n",
    "        BLAS.axpy!(T(1), obs.storage_qq4, obs.∇L)\n",
    "        \n",
    "        \n",
    "        # need to check sigmas\n",
    "        \n",
    "    end    \n",
    "    ###################\n",
    "    # Return\n",
    "    ###################        \n",
    "    return logl \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c15825b5-c463-4c8c-8eb8-87abc926f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "# dimension\n",
    "n, p, q = 2000, 5, 3\n",
    "# predictors\n",
    "X  = [ones(n) randn(n, p - 1)]\n",
    "Z  = [ones(n) randn(n, q - 1)]\n",
    "# parameter values\n",
    "β  = [2.0; -1.0; rand(p - 2)]\n",
    "σ² = 1.5\n",
    "Σ  = fill(0.1, q, q) + 0.9I # compound symmetry \n",
    "L  = Matrix(cholesky(Symmetric(Σ)).L)\n",
    "# generate y\n",
    "y  = X * β + Z * rand(MvNormal(Σ)) + sqrt(σ²) * randn(n)\n",
    "\n",
    "# form the LmmObs object\n",
    "obs = LmmObs(y, X, Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "378b8fcd-d43d-44f3-b6d9-2966913a99a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3256.179335805826"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl!(obs, β, L, σ², true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "857fed8c-d49b-4508-a7f6-606ebcc8427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.970913    0.0301459  -0.299679\n",
       " -0.0138436  -0.97012     0.281913\n",
       " -0.156986    0.38892     1.15936"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.∇L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d30bf82c-3db3-42ea-b647-615b1f0d0618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.999236     0.100354    0.0916096\n",
       " -7.04315e-5  -1.00426     0.0916357\n",
       " -7.14965e-5  -4.0826e-5  -1.00844"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = -Z'*inv(σ²*I + Z*L*L'*Z')*Z*L # first term for gradient wrt L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb18a9d6-933b-47a6-b86b-cf37a4760427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  0.0283232  -0.0702077  -0.391289\n",
       " -0.0137731   0.0341409   0.190278\n",
       " -0.156915    0.388961    2.1678"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = Z'*inv(σ²*I + Z*L*L'*Z')*(y-X*β)*transpose((y-X*β))*inv(σ²*I + Z*L*L'*Z')*Z*L # second term for gradient wrt L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fff01069-eb65-487a-92f5-5a20f4a529da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.970913    0.0301459  -0.299679\n",
       " -0.0138436  -0.97012     0.281913\n",
       " -0.156986    0.38892     1.15936"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "620b5208-0b14-4141-9ad4-0b4f89c6b7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.970913    0.0301459  -0.299679\n",
       " -0.0138436  -0.97012     0.281913\n",
       " -0.156986    0.38892     1.15936"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.∇L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5777ba63-b362-45f9-88f8-06361b8fb3d8",
   "metadata": {},
   "source": [
    "### **2.1  Correctness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d657160-b55a-4738-add2-67e506d0c3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logl = logl!(obs, β, L, σ², true) = -3256.179335805826\n",
      "obs.∇β = [0.2669810805714521, 41.61418337067322, -34.34664962312688, 36.108985107075306, 27.913948208793148]\n",
      "obs.∇σ² = [1.6283715138411026]\n"
     ]
    }
   ],
   "source": [
    "@show logl = logl!(obs, β, L, σ², true)\n",
    "@show obs.∇β\n",
    "@show obs.∇σ²\n",
    "#@show obs.∇Σ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc0a4d65-aa80-4a6c-b86c-dd0b8deffa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert abs(logl - (-3256.1793358058258)) < 1e-4\n",
    "@assert norm(obs.∇β - [0.26698108057144054, 41.61418337067327, \n",
    "        -34.34664962312689, 36.10898510707527, 27.913948208793144]) < 1e-4\n",
    "# @assert norm(obs.∇Σ - \n",
    "#     [-0.9464482950697888 0.057792444809492895 -0.30244127639188767; \n",
    "#         0.057792444809492895 -1.00087164917123 0.2845116557144694; \n",
    "#         -0.30244127639188767 0.2845116557144694 1.170040927259726]) < 1e-4\n",
    "@assert abs(obs.∇σ²[1] - (1.6283715138412163)) < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f94e45-6075-485c-af3f-544978f96ce5",
   "metadata": {},
   "source": [
    "### **2.2  Efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97442590-ddad-41b2-9765-7d2d5735701a",
   "metadata": {},
   "source": [
    "Benchmark for evaluating the objective function only. This is what we did in HW3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7959d9a7-a246-440f-b9a6-e1714b743028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 81 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m800.346 ns\u001b[22m\u001b[39m … \u001b[35m  3.211 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m807.963 ns               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m858.929 ns\u001b[22m\u001b[39m ± \u001b[32m139.396 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[34m \u001b[39m\u001b[39m▆\u001b[39m▁\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[32m█\u001b[39m\u001b[39m▆\u001b[39m█\u001b[39m▄\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▇\u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  800 ns\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       1.45 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logl!($obs, $β, $L, $σ², false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fba19-bfb4-4a29-b373-8797a74d17c4",
   "metadata": {},
   "source": [
    "Benchmark for objective + gradient evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ca82392-3cf8-49c8-bf80-e426509cb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 9 evaluations.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.333 μs\u001b[22m\u001b[39m … \u001b[35m 17.856 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.379 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.548 μs\u001b[22m\u001b[39m ± \u001b[32m509.477 ns\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m \u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m▄\u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▄\u001b[39m▃\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▁\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▅\u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m \u001b[39m█\n",
       "  2.33 μs\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      4.35 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_objgrad = @benchmark logl!($obs, $β, $L, $σ², true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f4409300-7dc0-44a5-bed4-f72607944eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The points you will get are\n",
    "clamp(10 / (median(bm_objgrad).time / 1e3) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d98584-7d26-4f63-b421-b4de395a0aaa",
   "metadata": {},
   "source": [
    "### **Q3. LmmModel type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e04bbf-2295-43dc-ab8a-9c4a6e4b9830",
   "metadata": {},
   "source": [
    "We create a `LmmModel` type to hold all data points and model parameters. Log-likelihood/gradient of a `LmmModel` object is simply the sum of log-likelihood/gradient of individual data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "63c746a4-95ac-4744-bfe1-457b6dc134b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logl!"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a type that holds LMM model (data + parameters)\n",
    "struct LmmModel{T <: AbstractFloat} <: MOI.AbstractNLPEvaluator\n",
    "    # data\n",
    "    data :: Vector{LmmObs{T}}\n",
    "    # parameters\n",
    "    β    :: Vector{T}\n",
    "    L    :: Matrix{T}\n",
    "    σ²   :: Vector{T}    \n",
    "    # arrays for holding gradient\n",
    "    ∇β   :: Vector{T}\n",
    "    ∇σ²  :: Vector{T}\n",
    "    ∇L   :: Matrix{T}\n",
    "    # TODO: add whatever intermediate arrays you may want to pre-allocate\n",
    "    xty  :: Vector{T}\n",
    "    ztr2 :: Vector{T}\n",
    "    xtx  :: Matrix{T}\n",
    "    ztz2 :: Matrix{T}\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LmmModel(data::Vector{LmmObs})\n",
    "\n",
    "Create an LMM model that contains data and parameters.\n",
    "\"\"\"\n",
    "function LmmModel(obsvec::Vector{LmmObs{T}}) where T <: AbstractFloat\n",
    "    # dims\n",
    "    p    = size(obsvec[1].X, 2)\n",
    "    q    = size(obsvec[1].Z, 2)\n",
    "    # parameters\n",
    "    β    = Vector{T}(undef, p)\n",
    "    L    = Matrix{T}(undef, q, q)\n",
    "    σ²   = Vector{T}(undef, 1)    \n",
    "    # gradients\n",
    "    ∇β   = similar(β)    \n",
    "    ∇σ²  = similar(σ²)\n",
    "    ∇L   = similar(L)\n",
    "    # intermediate arrays\n",
    "    xty  = Vector{T}(undef, p)\n",
    "    ztr2 = Vector{T}(undef, abs2(q))\n",
    "    xtx  = Matrix{T}(undef, p, p)\n",
    "    ztz2 = Matrix{T}(undef, abs2(q), abs2(q))\n",
    "    LmmModel(obsvec, β, L, σ², ∇β, ∇σ², ∇L, xty, ztr2, xtx, ztz2)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    logl!(m::LmmModel, needgrad=false)\n",
    "\n",
    "Evaluate the log-likelihood of an LMM model at parameter values `m.β`, `m.L`, \n",
    "and `m.σ²`. If `needgrad==true`, then `m.∇β`, `m.∇Σ`, and `m.σ² are filled \n",
    "with the corresponding gradient.\n",
    "\"\"\"\n",
    "function logl!(m::LmmModel{T}, needgrad::Bool = false) where T <: AbstractFloat\n",
    "    logl = zero(T)\n",
    "    if needgrad\n",
    "        fill!(m.∇β , 0)\n",
    "        fill!(m.∇L , 0)\n",
    "        fill!(m.∇σ², 0)        \n",
    "    end\n",
    "    @inbounds for i in 1:length(m.data)\n",
    "        obs = m.data[i]\n",
    "        logl += logl!(obs, m.β, m.L, m.σ²[1], needgrad)\n",
    "        if needgrad\n",
    "            BLAS.axpy!(T(1), obs.∇β, m.∇β)\n",
    "            BLAS.axpy!(T(1), obs.∇Σ, m.∇L)\n",
    "            m.∇σ²[1] += obs.∇σ²[1]\n",
    "        end\n",
    "    end\n",
    "    logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e717d79-c515-4f22-b30a-e72697f7a562",
   "metadata": {},
   "source": [
    "### **Q4. (20 pts) Test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ffb70c-6b35-496e-95c4-3b38352ebc54",
   "metadata": {},
   "source": [
    "Let's generate a fake longitudinal data set to test our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "af2bf164-c4fe-46ba-bdef-b1ba7382440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(257)\n",
    "\n",
    "# dimension\n",
    "m      = 1000 # number of individuals\n",
    "ns     = rand(1500:2000, m) # numbers of observations per individual\n",
    "p      = 5 # number of fixed effects, including intercept\n",
    "q      = 3 # number of random effects, including intercept\n",
    "obsvec = Vector{LmmObs{Float64}}(undef, m)\n",
    "# true parameter values\n",
    "βtrue  = [0.1; 6.5; -3.5; 1.0; 5; zeros(p - 5)]\n",
    "σ²true = 1.5\n",
    "σtrue  = sqrt(σ²true)\n",
    "Σtrue  = Matrix(Diagonal([2.0; 1.2; 1.0; zeros(q - 3)]))\n",
    "Ltrue  = Matrix(cholesky(Symmetric(Σtrue), Val(true), check=false).L)\n",
    "# generate data\n",
    "for i in 1:m\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    X = Matrix{Float64}(undef, ns[i], p)\n",
    "    X[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), X[:, 2:p])\n",
    "    # first column intercept, remaining entries iid std normal\n",
    "    Z = Matrix{Float64}(undef, ns[i], q)\n",
    "    Z[:, 1] .= 1\n",
    "    @views Distributions.rand!(Normal(), Z[:, 2:q])\n",
    "    # generate y\n",
    "    y = X * βtrue .+ Z * (Ltrue * randn(q)) .+ σtrue * randn(ns[i])\n",
    "    # form a LmmObs instance\n",
    "    obsvec[i] = LmmObs(y, X, Z)\n",
    "end\n",
    "# form a LmmModel instance\n",
    "lmm = LmmModel(obsvec);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846339e-2f2b-4318-b67b-974b67c0776f",
   "metadata": {},
   "source": [
    "For later comparison with other software, we save the data into a text file lmm_data.csv. **Do not put this file in Git.** It takes 245.4MB storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d6ee9d3-0b10-421b-aa83-73d601c25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "(isfile(\"lmm_data.csv\") && filesize(\"lmm_data.csv\") == 245369936) || \n",
    "open(\"lmm_data.csv\", \"w\") do io\n",
    "    p = size(lmm.data[1].X, 2)\n",
    "    q = size(lmm.data[1].Z, 2)\n",
    "    # print header\n",
    "    print(io, \"ID,Y,\")\n",
    "    for j in 1:(p-1)\n",
    "        print(io, \"X\" * string(j) * \",\")\n",
    "    end\n",
    "    for j in 1:(q-1)\n",
    "        print(io, \"Z\" * string(j) * (j < q-1 ? \",\" : \"\\n\"))\n",
    "    end\n",
    "    # print data\n",
    "    for i in eachindex(lmm.data)\n",
    "        obs = lmm.data[i]\n",
    "        for j in 1:length(obs.y)\n",
    "            # id\n",
    "            print(io, i, \",\")\n",
    "            # Y\n",
    "            print(io, obs.y[j], \",\")\n",
    "            # X data\n",
    "            for k in 2:p\n",
    "                print(io, obs.X[j, k], \",\")\n",
    "            end\n",
    "            # Z data\n",
    "            for k in 2:q-1\n",
    "                print(io, obs.Z[j, k], \",\")\n",
    "            end\n",
    "            print(io, obs.Z[j, q], \"\\n\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba5cc7-8c96-4d45-9fa1-e6a3364cc32c",
   "metadata": {},
   "source": [
    "### **4.1  Correctness**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63b550-f563-4701-b143-25797d381cf0",
   "metadata": {},
   "source": [
    "Evaluate log-likelihood and gradient of whole data set at the true parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f363ae46-de27-4c62-986a-7e5fed6ad6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " NaN             -2.73681e191  NaN\n",
       "   2.16124e256  NaN            NaN\n",
       " NaN            NaN            NaN"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmm.∇L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c94a1b6-80f7-4c3c-b2df-ab56c61be272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = logl!(lmm, true) = -2.84006843836997e6\n",
      "lmm.∇β = [41.06591670742247, 445.75120353972505, 157.01339922492545, -335.099773607337, -895.6257448385876]\n",
      "lmm.∇σ² = [-489.53617303824456]\n",
      "lmm.∇L = [NaN -2.736812490423738e191 NaN; 2.1612424389152652e256 NaN NaN; NaN NaN NaN]\n"
     ]
    }
   ],
   "source": [
    "copy!(lmm.β, βtrue)\n",
    "copy!(lmm.L, Ltrue)\n",
    "lmm.σ²[1] = σ²true\n",
    "@show obj = logl!(lmm, true)\n",
    "@show lmm.∇β\n",
    "@show lmm.∇σ²\n",
    "@show lmm.∇L;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a8863675-6029-4b43-a576-994c40d8a9f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: norm(lmm.∇L - [-3.3982575935824837 31.32103842086001 26.73645089732865; 40.43528672997116 61.86377650461202 -75.37427770754684; 37.811051468724486 -82.56838431216435 -56.45992542754974]) < 0.0001",
     "output_type": "error",
     "traceback": [
      "AssertionError: norm(lmm.∇L - [-3.3982575935824837 31.32103842086001 26.73645089732865; 40.43528672997116 61.86377650461202 -75.37427770754684; 37.811051468724486 -82.56838431216435 -56.45992542754974]) < 0.0001",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[122]:4",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "@assert abs(obj - (-2.840068438369969e6)) < 1e-4\n",
    "@assert norm(lmm.∇β - [41.0659167074073, 445.75120353972426, \n",
    "        157.0133992249258, -335.09977360733626, -895.6257448385899]) < 1e-4\n",
    "@assert norm(lmm.∇L - [-3.3982575935824837 31.32103842086001 26.73645089732865; \n",
    "        40.43528672997116 61.86377650461202 -75.37427770754684; \n",
    "        37.811051468724486 -82.56838431216435 -56.45992542754974]) < 1e-4\n",
    "@assert abs(lmm.∇σ²[1] - (-489.5361730382465)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "beabf8b5-21c7-4ff9-bccc-82f00363bac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1418 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.611 ms\u001b[22m\u001b[39m … \u001b[35m 10.742 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.366 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.494 ms\u001b[22m\u001b[39m ± \u001b[32m761.772 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m█\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[34m█\u001b[39m\u001b[39m▄\u001b[32m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▄\n",
       "  2.61 ms\u001b[90m         Histogram: frequency by time\u001b[39m        6.68 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_model = @benchmark logl!($lmm, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c206f6a3-2f6c-4d52-86d7-75996794f40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 / (median(bm_model).time / 1e6) * 10, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc1a8b77-bba9-41f5-a0e5-e7f6e1673d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clamp(10 - median(bm_model).memory / 100, 0, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
